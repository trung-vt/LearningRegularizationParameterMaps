{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_time_importing_torch = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing torch ...\n",
      "Importing torch took 9.568702697753906 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# NOTE: Importing torch the first time will always take a long time!\n",
    "import time\n",
    "# NOTE: Importing torch the first time will always take a long time!\n",
    "if first_time_importing_torch:\n",
    "    print(f\"Importing torch ...\")\n",
    "    import_torch_start_time = time.time() \n",
    "import torch\n",
    "if first_time_importing_torch:\n",
    "    import_torch_end_time = time.time()\n",
    "    print(f\"Importing torch took {import_torch_end_time - import_torch_start_time} seconds\")\n",
    "    first_time_importing_torch = False\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# from torchmetrics.image import StructuralSimilarityIndexMeasure, PeakSignalNoiseRatio\n",
    "\n",
    "from skimage.metrics import structural_similarity\n",
    "# from skimage.metrics import peak_signal_noise_ratio\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Optional\n",
    "from tqdm import tqdm # progress bar\n",
    "\n",
    "import wandb # Optional, for logging\n",
    "\n",
    "import json\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/t/Documents/GIT/DISSERTATION/LearningRegularizationParameterMaps/venv/bin/python\n",
      "Torch version: 2.3.0+cu121\n",
      "Path: /mnt/c/Users/t/Documents/GIT/DISSERTATION/LearningRegularizationParameterMaps/chest_xray\n"
     ]
    }
   ],
   "source": [
    "!which python\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"Path: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISABLING_TESTS = False\n",
    "DISABLING_TESTS = True   # Disable tests for less output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    print(f\"Using {torch.cuda.get_device_name(0)}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "    print(f\"Using {torch.backends.mps.get_device_name(0)} with MPS\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "torch.set_default_device(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIDD_DATA_PATH = \"../data/dyn_img_static/tmp/SIDD_Small_sRGB_Only/Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHEST_XRAY_BASE_DATA_PATH = \"../data/chest_xray\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'project': 'chest_xray', 'dataset': '../data/chest_xray', 'train_data_path': '../data/chest_xray/train/NORMAL', 'val_data_path': '../data/chest_xray/val/NORMAL', 'test_data_path': '../data/chest_xray/test/NORMAL', 'train_num_samples': 200, 'val_num_samples': 8, 'test_num_samples': 1, 'resize_square': 256, 'min_sigma': 0.1, 'max_sigma': 0.5, 'batch_size': 1, 'random_seed': 42, 'architecture': 'UNET-PDHG', 'in_channels': 1, 'out_channels': 2, 'init_filters': 64, 'n_blocks': 3, 'activation': 'LeakyReLU', 'downsampling_kernel': (2, 2, 1), 'downsampling_mode': 'max', 'upsampling_kernel': (2, 2, 1), 'upsampling_mode': 'linear_interpolation', 'optimizer': 'Adam', 'learning_rate': 0.0001, 'loss_function': 'MSELoss', 'up_bound': 0, 'T': 128, 'epochs': 10000, 'device': 'cuda:0', 'wandb_mode': 'online', 'save_epoch_wandb': 10, 'save_epoch_local': 2, 'save_dir': 'tmp_2'}\n"
     ]
    }
   ],
   "source": [
    "def get_config():\n",
    "    CHEST_XRAY_BASE_DATA_PATH = \"../data/chest_xray\"\n",
    "    return {\n",
    "        \"project\": \"chest_xray\",\n",
    "        \"dataset\": CHEST_XRAY_BASE_DATA_PATH,\n",
    "        \"train_data_path\": f\"{CHEST_XRAY_BASE_DATA_PATH}/train/NORMAL\",\n",
    "        \"val_data_path\": f\"{CHEST_XRAY_BASE_DATA_PATH}/val/NORMAL\",\n",
    "        \"test_data_path\": f\"{CHEST_XRAY_BASE_DATA_PATH}/test/NORMAL\",\n",
    "        \"train_num_samples\": 200,\n",
    "        \"val_num_samples\": 8,\n",
    "        \"test_num_samples\": 1,\n",
    "\n",
    "        # \"patch\": 512,\n",
    "        # \"stride\": 512,\n",
    "        \"resize_square\": 256,\n",
    "        \"min_sigma\": 0.1,\n",
    "        \"max_sigma\": 0.5,\n",
    "        \"batch_size\": 1,\n",
    "        \"random_seed\": 42,\n",
    "\n",
    "        \"architecture\": \"UNET-PDHG\",\n",
    "        \"in_channels\": 1,\n",
    "        \"out_channels\": 2,\n",
    "        \"init_filters\": 64,\n",
    "        \"n_blocks\": 3,\n",
    "        \"activation\": \"LeakyReLU\",\n",
    "        \"downsampling_kernel\": (2, 2, 1),\n",
    "        \"downsampling_mode\": \"max\",\n",
    "        \"upsampling_kernel\": (2, 2, 1),\n",
    "        \"upsampling_mode\": \"linear_interpolation\",\n",
    "\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"loss_function\": \"MSELoss\",\n",
    "\n",
    "        # \"up_bound\": 0.5,\n",
    "        \"up_bound\": 0,\n",
    "        \"T\": 128,\n",
    "\n",
    "        \"epochs\": 10_000,\n",
    "        \"device\": \"cuda:0\",\n",
    "\n",
    "        \"wandb_mode\": \"online\",\n",
    "        \"save_epoch_wandb\": 10,\n",
    "        \"save_epoch_local\": 2,\n",
    "        \"save_dir\": \"tmp_2\",\n",
    "    }\n",
    "\n",
    "print(get_config())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "### Import the image and transform the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # REMEMBER TO COMMENT THIS OUT IF THE DATA HAS BEEN DOWNLOADED!\n",
    "# !wget https://competitions.codalab.org/my/datasets/download/a26784fe-cf33-48c2-b61f-94b299dbc0f2\n",
    "# !unzip \"a26784fe-cf33-48c2-b61f-94b299dbc0f2\" -d ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load SIDD images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_npy_file(sample_path: str, scale_factor: float) -> np.ndarray:\t\t\t\n",
    "    scale_factor_str = str(scale_factor).replace('.','_')\n",
    "    xf = np.load(os.path.join(sample_path, f\"xf_scale_factor{scale_factor_str}.npy\"))\n",
    "    xf = torch.tensor(xf, dtype=torch.float)\n",
    "    xf = xf.unsqueeze(0) / 255\n",
    "    return xf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: CHANGE THIS TO YOUR PATH\n",
    "# NOTE: Windows uses \\\\ instead of /\n",
    "def load_images_SIDD(ids: list, take_npy_files: bool) -> list:\n",
    "    data_path = SIDD_DATA_PATH\n",
    "    k = 0\n",
    "\n",
    "    images = []\n",
    "\n",
    "    for folder in os.listdir(data_path):\n",
    "        img_id = folder[:4]\t# The first 4 characters of folder name is the image id (0001, 0002, ..., 0200)\n",
    "        if img_id not in ids:\n",
    "            continue\n",
    "        k += 1\n",
    "        print(f'loading image id {img_id}, {k}/{len(ids)}')\n",
    "\n",
    "        files_path = os.path.join(data_path, folder)\n",
    "\n",
    "        # if take_npy_files:\n",
    "        #     xf = get_npy_file(files_path, scale_factor)\n",
    "        #     images.append(xf)\n",
    "        #     continue\n",
    "\n",
    "        # Use only the ground truth images\n",
    "        file = \"GT_SRGB_010.PNG\"  # GT = Ground Truth\n",
    "\n",
    "        image = Image.open(os.path.join(files_path, file))\n",
    "        assert image.mode == 'RGB', f\"Image mode is not RGB: {image.mode}\" # For now, expect RGB images\n",
    "\n",
    "        images.append(image)\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_load_images_SIDD():\n",
    "    if DISABLING_TESTS: return\n",
    "    for img in load_images_SIDD([\"0065\"], False):\n",
    "        print(img.size)\n",
    "        plt.imshow(img)\n",
    "\n",
    "test_load_images_SIDD()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Chest X-ray images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: CHANGE THIS TO YOUR PATH\n",
    "# NOTE: Windows uses \\\\ instead of /\n",
    "def load_images_chest_xray(data_path: str, ids: list) -> list:\n",
    "    files = os.listdir(data_path)\n",
    "    jpeg_files = [f for f in files if f.endswith(\".jpeg\")]\n",
    "\n",
    "    images = []\n",
    "    for id in tqdm(ids):\n",
    "        if id >= len(jpeg_files): continue\n",
    "        # print(f\"Loading image {id} from {data_path}\")\n",
    "        image = Image.open(os.path.join(data_path, jpeg_files[id]))\n",
    "        images.append(image)\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_load_images_chest_xray(stage=\"train\", label=\"NORMAL\"):\n",
    "    if DISABLING_TESTS: return\n",
    "    for img in load_images_chest_xray(f\"{CHEST_XRAY_BASE_DATA_PATH}/{stage}/{label}\", [0]):\n",
    "        print(img.size)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "    plt.show();\n",
    "\n",
    "test_load_images_chest_xray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "#### Convert image to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_grayscale(image: Image) -> Image:\n",
    "    return image.convert('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_convert_to_grayscale():\n",
    "    if DISABLING_TESTS: return\n",
    "    # for img in load_images_SIDD([\"0065\"], False):\n",
    "    for img in load_images_chest_xray(f\"{CHEST_XRAY_BASE_DATA_PATH}/train/NORMAL\", [0]):\n",
    "        img = convert_to_grayscale(img)\n",
    "        plt.imshow(img, cmap='gray') # cmap='gray' for proper display in black and white. It does not convert the image to grayscale.\n",
    "\n",
    "test_convert_to_grayscale()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_to_square(image: Image) -> Image:\n",
    "    width, height = image.size\n",
    "    new_size = min(width, height)\n",
    "    left = (width - new_size) / 2\n",
    "    top = (height - new_size) / 2\n",
    "    right = (width + new_size) / 2\n",
    "    bottom = (height + new_size) / 2\n",
    "    return image.crop((left, top, right, bottom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_crop_to_square():\n",
    "    if DISABLING_TESTS: return\n",
    "    # for img in load_images_SIDD([\"0083\"], False):\n",
    "    for img in load_images_chest_xray(f\"{CHEST_XRAY_BASE_DATA_PATH}/train/NORMAL\", [0]):\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.show();\n",
    "        img = crop_to_square(img)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.show();\n",
    "\n",
    "test_crop_to_square()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_to_square_and_resize(image: Image, side_len: int) -> Image:\n",
    "    image = crop_to_square(image)\n",
    "    return image.resize(size=(side_len, side_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_crop_to_square_and_resize():\n",
    "    if DISABLING_TESTS: return\n",
    "    # for img in load_images_SIDD([\"0083\"], False):\n",
    "    for img in load_images_chest_xray(f\"{CHEST_XRAY_BASE_DATA_PATH}/train/NORMAL\", [0]):\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.show();\n",
    "        img = crop_to_square_and_resize(img, 120)\n",
    "        print(img.size)\n",
    "        plt.imshow(img, cmap='gray') # cmap='gray' for proper display in black and white. It does not convert the image to grayscale.\n",
    "        plt.show();\n",
    "\n",
    "test_crop_to_square_and_resize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_numpy(image):\n",
    "    image_data = np.asarray(image)\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_convert_to_numpy():\n",
    "    if DISABLING_TESTS: return\n",
    "    # for img in load_images_SIDD([\"0083\"], False):\n",
    "    for img in load_images_chest_xray(f\"{CHEST_XRAY_BASE_DATA_PATH}/train/NORMAL\", [0]):\n",
    "        img = convert_to_grayscale(img)\n",
    "        print(f\"Before conversion: {type(img)}\")\n",
    "        image_data = convert_to_numpy(img)\n",
    "        print(f\"After conversion: {type(image_data)}\")\n",
    "        # plt.imshow still works with numpy array\n",
    "        plt.imshow(image_data, cmap='gray')\n",
    "\n",
    "test_convert_to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to tensor\n",
    "\n",
    "For efficient computation on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tensor_4D(image_numpy):\n",
    "    # xf = []\n",
    "    # xf.append(image_numpy)\n",
    "    # xf = np.stack(xf, axis=-1)\n",
    "    # xf = torch.tensor(xf, dtype=torch.float)\n",
    "    xf = torch.tensor(image_numpy, dtype=torch.float)\n",
    "    xf = xf.unsqueeze(0)\n",
    "    xf = xf.unsqueeze(-1)\n",
    "    xf = xf / 255 # Normalise from [0, 255] to [0, 1]\n",
    "    return xf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_convert_to_tensor():\n",
    "    if DISABLING_TESTS: return\n",
    "    # for image in load_images_SIDD([\"0083\"], False):\n",
    "    for image in load_images_chest_xray(f\"{CHEST_XRAY_BASE_DATA_PATH}/train/NORMAL\", [0]):\n",
    "        image = convert_to_grayscale(image)\n",
    "        image_numpy = convert_to_numpy(image)\n",
    "        image_tensor_4D = convert_to_tensor_4D(image_numpy)\n",
    "        print(image_tensor_4D.size())\n",
    "        plt.imshow(image_tensor_4D.squeeze(0).to(\"cpu\"), cmap='gray')\n",
    "\n",
    "\n",
    "test_convert_to_tensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add synthetic noise\n",
    "\n",
    "<!-- artificial Gaussian noise\n",
    "\n",
    "Noise can occur in reality.\n",
    "\n",
    "It is difficult to obtain a pair of clean and noisy images of one exact same scene.\n",
    "\n",
    "For training, it is common to add synthetic noise to an image that is considered clean and then try to reconstruct it.\n",
    "\n",
    "There are many types of noise and different ways to add noise. We can add salt-and-pepper noise. (?)We can add more noise in some parts and less in others. We can use a combination of noise-adding strategies to build more robust models.\n",
    "\n",
    "For our purpose, we will focus on Gaussian noise. This is sufficient for most cases. \n",
    "\n",
    "(?) We will add noise with the same probability for each pixel (not using the strategies of focusing on certain regions) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variable_noise(sigma_min, sigma_max):\n",
    "    return sigma_min + torch.rand(1) * (sigma_max - sigma_min)\n",
    "\n",
    "def add_noise(xf: torch.tensor, sigma) -> torch.tensor:\n",
    "    std = torch.std(xf)\n",
    "    mu = torch.mean(xf)\n",
    "\n",
    "    x_centred = (xf  - mu) / std\n",
    "\n",
    "    x_centred += sigma * torch.randn(xf.shape, dtype = xf.dtype)\n",
    "\n",
    "    xnoise = std * x_centred + mu\n",
    "\n",
    "    del std, mu, x_centred\n",
    "\n",
    "    return xnoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_add_noise():\n",
    "    if DISABLING_TESTS: return\n",
    "    # for rgb_image in load_images_SIDD([\"0083\"], False):\n",
    "    for rgb_image in load_images_chest_xray(f\"{CHEST_XRAY_BASE_DATA_PATH}/train/NORMAL\", [0]):\n",
    "        grayscale_image = convert_to_grayscale(rgb_image)\n",
    "        grayscale_image = crop_to_square_and_resize(grayscale_image, 120)\n",
    "        print(f\"grayscale_image.size: {grayscale_image.size}\")\n",
    "        image_numpy = convert_to_numpy(grayscale_image)\n",
    "        image_tensor_4D = convert_to_tensor_4D(image_numpy)\n",
    "        constant_noise_img = add_noise(image_tensor_4D, sigma=0.1)\n",
    "        variable_noise_img = add_noise(image_tensor_4D, get_variable_noise(\n",
    "            sigma_min=0.1, sigma_max=0.2))\n",
    "        plt.imshow(grayscale_image, cmap='gray')\n",
    "        plt.show();\n",
    "        plt.imshow(constant_noise_img.squeeze(0).to(\"cpu\"), cmap='gray')\n",
    "        plt.show();\n",
    "        plt.imshow(variable_noise_img.squeeze(0).to(\"cpu\"), cmap='gray')\n",
    "        plt.show();\n",
    "\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "test_add_noise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "### Calculate PSNR\n",
    "\n",
    "PSNR is a common metrics for noisy image.\n",
    "\n",
    "Compare before and after adding synthetic noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(original, compressed): \n",
    "    mse = torch.mean((original - compressed) ** 2) \n",
    "    if(mse == 0): # MSE is zero means no noise is present in the signal. \n",
    "                  # Therefore PSNR have no importance. \n",
    "        return 100\n",
    "    # max_pixel = 255.0\n",
    "    max_pixel = 1.0\n",
    "    psnr = 20 * torch.log10(max_pixel / torch.sqrt(mse)) \n",
    "\n",
    "    del mse\n",
    "\n",
    "    return psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_PSNR():\n",
    "    if DISABLING_TESTS: return\n",
    "    # for rgb_image in load_images_SIDD([\"0083\"], False):\n",
    "    for rgb_image in load_images_chest_xray(f\"{CHEST_XRAY_BASE_DATA_PATH}/train/NORMAL\", [0]):\n",
    "        grayscale_image = convert_to_grayscale(rgb_image)\n",
    "        grayscale_image = crop_to_square_and_resize(grayscale_image, 120)\n",
    "        image_numpy = convert_to_numpy(grayscale_image)\n",
    "        image_tensor_4D = convert_to_tensor_4D(image_numpy)\n",
    "\n",
    "        print(f\"PSNR of original image: {PSNR(image_tensor_4D, image_tensor_4D)} dB\")\n",
    "        plt.imshow(image_tensor_4D.squeeze(0).to(\"cpu\"), cmap='gray')\n",
    "        plt.show();\n",
    "\n",
    "        noisy_image_tensor_4D = add_noise(image_tensor_4D, sigma=0.5)\n",
    "        print(f\"PSNR of constant noise image: {PSNR(noisy_image_tensor_4D, image_tensor_4D):.2f} dB\")\n",
    "        plt.imshow(noisy_image_tensor_4D.squeeze(0).to(\"cpu\"), cmap='gray')\n",
    "        plt.show();\n",
    "\n",
    "\n",
    "test_PSNR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Calculate SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSIM(tensor_2D_a: torch.Tensor, tensor_2D_b: torch.Tensor, data_range: float=1) -> float:\n",
    "    return structural_similarity(\n",
    "        tensor_2D_a.to(\"cpu\").detach().numpy(), \n",
    "        tensor_2D_b.to(\"cpu\").detach().numpy(),\n",
    "        data_range=data_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_SSIM(sigma=0.5):\n",
    "    if DISABLING_TESTS: return\n",
    "    # for rgb_image in load_images_SIDD([\"0083\"], False):\n",
    "    for rgb_image in load_images_chest_xray(f\"{CHEST_XRAY_BASE_DATA_PATH}/train/NORMAL\", [0]):\n",
    "        grayscale_image = convert_to_grayscale(rgb_image)\n",
    "        grayscale_image = crop_to_square_and_resize(grayscale_image, 120)\n",
    "        image_numpy = convert_to_numpy(grayscale_image)\n",
    "        image_tensor_4D = convert_to_tensor_4D(image_numpy)\n",
    "\n",
    "        image_tensor_2D = image_tensor_4D.squeeze(0).squeeze(-1)\n",
    "        print(f\"image_tensor_2D: {image_tensor_2D.size()}\")\n",
    "        print(f\"SSIM of original image: {SSIM(image_tensor_2D, image_tensor_2D)}\")\n",
    "        plt.imshow(image_tensor_2D.cpu(), cmap='gray')\n",
    "        plt.show();\n",
    "\n",
    "        noisy_image_tensor_2D = add_noise(image_tensor_2D, sigma=sigma)\n",
    "        print(f\"noisy_image_tensor_2D: {noisy_image_tensor_2D.size()}\")\n",
    "        print(f\"SSIM of noisy image (sigma={sigma}): {SSIM(noisy_image_tensor_2D, image_tensor_2D):.2f}\")\n",
    "        plt.imshow(noisy_image_tensor_2D.cpu(), cmap='gray')\n",
    "        plt.show();\n",
    "\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "test_SSIM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "### Reconstruct an image with PDHG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the gradient\n",
    "\n",
    "<!-- The gradient is a Laplacian ?\n",
    "\n",
    "There are $x$ gradient and $y$ gradient -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code taken from https://www.github.com/koflera/LearningRegularizationParameterMaps\n",
    "\n",
    "class GradOperators(torch.nn.Module):\n",
    "    @staticmethod\n",
    "    def diff_kernel(ndim, mode):\n",
    "        if mode == \"doublecentral\":\n",
    "            kern = torch.tensor((-1, 0, 1))\n",
    "        elif mode == \"central\":\n",
    "            kern = torch.tensor((-1, 0, 1)) / 2\n",
    "        elif mode == \"forward\":\n",
    "            kern = torch.tensor((0, -1, 1))\n",
    "        elif mode == \"backward\":\n",
    "            kern = torch.tensor((-1, 1, 0))\n",
    "        else:\n",
    "            raise ValueError(f\"mode should be one of (central, forward, backward, doublecentral), not {mode}\")\n",
    "        kernel = torch.zeros(ndim, 1, *(ndim * (3,)))\n",
    "        for i in range(ndim):\n",
    "            idx = tuple([i, 0, *(i * (1,)), slice(None), *((ndim - i - 1) * (1,))])\n",
    "            kernel[idx] = kern\n",
    "        return kernel\n",
    "\n",
    "    def __init__(self, dim:int=2, mode:str=\"doublecentral\", padmode:str = \"circular\"):\n",
    "        \"\"\"\n",
    "        An Operator for finite Differences / Gradients\n",
    "        Implements the forward as apply_G and the adjoint as apply_GH.\n",
    "        \n",
    "        Args:\n",
    "            dim (int, optional): Dimension. Defaults to 2.\n",
    "            mode (str, optional): one of doublecentral, central, forward or backward. Defaults to \"doublecentral\".\n",
    "            padmode (str, optional): one of constant, replicate, circular or refelct. Defaults to \"circular\".\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"kernel\", self.diff_kernel(dim, mode), persistent=False)\n",
    "        self._dim = dim\n",
    "        self._conv = (torch.nn.functional.conv1d, torch.nn.functional.conv2d, torch.nn.functional.conv3d)[dim - 1]\n",
    "        self._convT = (torch.nn.functional.conv_transpose1d, torch.nn.functional.conv_transpose2d, torch.nn.functional.conv_transpose3d)[dim - 1]\n",
    "        self._pad = partial(torch.nn.functional.pad, pad=2 * dim * (1,), mode=padmode)\n",
    "        if mode == 'central':\n",
    "            self._norm = (self.dim) ** (1 / 2)\n",
    "        else:\n",
    "            self._norm = (self.dim * 4) ** (1 / 2)\n",
    "\n",
    "    @property\n",
    "    def dim(self):\n",
    "        return self._dim\n",
    "    \n",
    "    def apply_G(self, x):\n",
    "        \"\"\"\n",
    "        Forward\n",
    "        \"\"\"\n",
    "        if x.is_complex():\n",
    "            xr = torch.view_as_real(x).moveaxis(-1, 0)\n",
    "        else:\n",
    "            xr = x\n",
    "        xr = xr.reshape(-1, 1, *x.shape[-self.dim :])\n",
    "        xp = self._pad(xr)\n",
    "        y = self._conv(xp, weight=self.kernel, bias=None, padding=0)\n",
    "        if x.is_complex():\n",
    "            y = y.reshape(2, *x.shape[: -self.dim], self.dim, *x.shape[-self.dim :])\n",
    "            y = torch.view_as_complex(y.moveaxis(0, -1).contiguous())\n",
    "        else:\n",
    "            y = y.reshape(*x.shape[0 : -self.dim], self.dim, *x.shape[-self.dim :])\n",
    "\n",
    "        del x, xr, xp\n",
    "\n",
    "        return y\n",
    "\n",
    "    def apply_GH(self, x):\n",
    "        \"\"\"\n",
    "        Adjoint\n",
    "        \"\"\"\n",
    "        if x.is_complex():\n",
    "            xr = torch.view_as_real(x).moveaxis(-1, 0)\n",
    "        else:\n",
    "            xr = x\n",
    "        xr = xr.reshape(-1, self.dim, *x.shape[-self.dim :])\n",
    "        xp = self._pad(xr)\n",
    "        y = self._convT(xp, weight=self.kernel, bias=None, padding=2)\n",
    "        if x.is_complex():\n",
    "            y = y.reshape(2, *x.shape[: -self.dim - 1], *x.shape[-self.dim :])\n",
    "            y = torch.view_as_complex(y.moveaxis(0, -1).contiguous())\n",
    "        else:\n",
    "            y = y.reshape(*x.shape[: -self.dim - 1], *x.shape[-self.dim :])\n",
    "\n",
    "        del x, xr, xp\n",
    "\n",
    "        return y\n",
    "    \n",
    "    def apply_GHG(self, x):\n",
    "        if x.is_complex():\n",
    "            xr = torch.view_as_real(x).moveaxis(-1, 0)\n",
    "        else:\n",
    "            xr = x\n",
    "        xr = xr.reshape(-1, 1, *x.shape[-self.dim :])\n",
    "        xp = self._pad(xr)\n",
    "        tmp = self._conv(xp, weight=self.kernel, bias=None, padding=0)\n",
    "        tmp = self._pad(tmp)\n",
    "        y = self._convT(tmp, weight=self.kernel, bias=None, padding=2)\n",
    "        if x.is_complex():\n",
    "            y = y.reshape(2, *x.shape)\n",
    "            y = torch.view_as_complex(y.moveaxis(0, -1).contiguous())\n",
    "        else:\n",
    "            y = y.reshape(*x.shape)\n",
    "\n",
    "        del x, xr, xp, tmp\n",
    "\n",
    "        return y\n",
    "\n",
    "    def forward(self, x, direction=1):\n",
    "        if direction>0:\n",
    "            return self.apply_G(x)\n",
    "        elif direction<0:\n",
    "            return self.apply_GH(x)\n",
    "        else:\n",
    "            return self.apply_GHG(x)\n",
    "\n",
    "    @property\n",
    "    def normGHG(self):\n",
    "        return self._norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper function for PDHG: Clip act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code taken from https://www.github.com/koflera/LearningRegularizationParameterMaps\n",
    "\n",
    "class ClipAct(nn.Module):\n",
    "    def forward(self, x, threshold):\n",
    "        return clipact(x, threshold)\n",
    "\n",
    "\n",
    "def clipact(x, threshold):\n",
    "    is_complex = x.is_complex()\n",
    "    if is_complex:\n",
    "        x = torch.view_as_real(x)\n",
    "        threshold = threshold.unsqueeze(-1)\n",
    "    x = torch.clamp(x, -threshold, threshold)\n",
    "    if is_complex:\n",
    "        x = torch.view_as_complex(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only PDHG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason, running PDHG with T large (many iterations in PDGH) will make GPU memory full?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code taken from https://www.github.com/koflera/LearningRegularizationParameterMaps\n",
    "\n",
    "def reconstruct_with_PDHG(\n",
    "        x_dynamic_image_tensor_5D, lambda_reg, T, \n",
    "        # lambda_reg_container=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Reconstructs the image using the PDHG algorithm.\n",
    "\n",
    "    Parameters:\n",
    "        dynamic_image_tensor_5D: The (noisy) (dynamic) image tensor.\n",
    "        Size of the tensor: (`patches`, `channels`, `Nx`, `Ny`, `Nt`) where\n",
    "        \n",
    "        - `patches`: number of patches\n",
    "        - `channels`: number of (colour) channels\n",
    "        - `Nx`: number of pixels in x\n",
    "        - `Ny`: number of pixels in y\n",
    "        - `Nt`: number of time steps (frames)\n",
    "\n",
    "        lambda_reg: The regularization parameter. Can be a scalar or a tensor of suitable size.\n",
    "        T: Number of iterations.\n",
    "\n",
    "    Returns:\n",
    "        The reconstructed image tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    dim = 3\n",
    "    patches, channels, Nx, Ny, Nt = x_dynamic_image_tensor_5D.shape\n",
    "    \n",
    "    assert channels == 1, \"Only grayscale images are supported.\"\n",
    "\n",
    "    device = x_dynamic_image_tensor_5D.device\n",
    "\n",
    "    # starting values\n",
    "    xbar = x_dynamic_image_tensor_5D.clone()\n",
    "    x0 = x_dynamic_image_tensor_5D.clone()\n",
    "    xnoisy = x_dynamic_image_tensor_5D.clone()\n",
    "\n",
    "    # dual variable\n",
    "    p = x_dynamic_image_tensor_5D.clone()\n",
    "    q = torch.zeros(patches, dim, Nx, Ny, Nt, dtype=x_dynamic_image_tensor_5D.dtype).to(device)\n",
    "\n",
    "    # operator norms\n",
    "    op_norm_AHA = torch.sqrt(torch.tensor(1.0))\n",
    "    op_norm_GHG = torch.sqrt(torch.tensor(12.0))\n",
    "    # operator norm of K = [A, \\nabla]\n",
    "    # https://iopscience.iop.org/article/10.1088/0031-9155/57/10/3065/pdf,\n",
    "    # see page 3083\n",
    "    L = torch.sqrt(op_norm_AHA**2 + op_norm_GHG**2)\n",
    "\n",
    "    tau = nn.Parameter(\n",
    "        torch.tensor(10.0), requires_grad=True\n",
    "    )  # starting value approximately  1/L\n",
    "    sigma = nn.Parameter(\n",
    "        torch.tensor(10.0), requires_grad=True\n",
    "    )  # starting value approximately  1/L\n",
    "\n",
    "    # theta should be in \\in [0,1]\n",
    "    theta = nn.Parameter(\n",
    "        torch.tensor(10.0), requires_grad=True\n",
    "    )  # starting value approximately  1\n",
    "\n",
    "    # sigma, tau, theta\n",
    "    sigma = (1 / L) * torch.sigmoid(sigma)  # \\in (0,1/L)\n",
    "    tau = (1 / L) * torch.sigmoid(tau)  # \\in (0,1/L)\n",
    "    theta = torch.sigmoid(theta)  # \\in (0,1)\n",
    "\n",
    "    GradOps = GradOperators(\n",
    "        dim=dim, \n",
    "        mode=\"forward\", padmode=\"circular\")\n",
    "    clip_act = ClipAct()\n",
    "    # Algorithm 2 - Unrolled PDHG algorithm (page 18)\n",
    "    # TODO: In the paper, L is one of the inputs but not used anywhere in the pseudo code???\n",
    "    for kT in range(T):\n",
    "        # update p\n",
    "        p =  (p + sigma * (xbar - xnoisy) ) / (1. + sigma)\n",
    "        # update q\n",
    "        q = clip_act(q + sigma * GradOps.apply_G(xbar), lambda_reg)\n",
    "\n",
    "        x1 = x0 - tau * p - tau * GradOps.apply_GH(q)\n",
    "\n",
    "        if kT != T - 1:\n",
    "            # update xbar\n",
    "            xbar = x1 + theta * (x1 - x0)\n",
    "            x0 = x1\n",
    "        with torch.no_grad():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    del x_dynamic_image_tensor_5D\n",
    "    del xbar, x0, xnoisy\n",
    "    del p, q\n",
    "    del op_norm_AHA, op_norm_GHG, L\n",
    "    del tau, sigma, theta\n",
    "    del GradOps\n",
    "    del clip_act\n",
    "\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # if lambda_reg_container is not None:\n",
    "    #     assert isinstance(lambda_reg_container, list), f\"lambda_reg_container should be a list, not {type(lambda_reg_container)}\"\n",
    "    #     lambda_reg_container.append(lambda_reg) # For comparison\n",
    "\n",
    "    return x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_reconstruct_with_PDHG():\n",
    "    if DISABLING_TESTS: return\n",
    "    # for rgb_image in load_images_SIDD([\"0083\"], False):\n",
    "    for rgb_image in load_images_chest_xray(f\"{CHEST_XRAY_BASE_DATA_PATH}/train/NORMAL\", [0]):\n",
    "        grayscale_image = convert_to_grayscale(rgb_image)\n",
    "        grayscale_image = crop_to_square_and_resize(grayscale_image, 512)\n",
    "        image_numpy = convert_to_numpy(grayscale_image)\n",
    "\n",
    "        image_tensor_4D = convert_to_tensor_4D(image_numpy)\n",
    "        print(f\"Image tensor size: {image_tensor_4D.size()}\")\n",
    "        assert len(image_tensor_4D.size()) == 4, \"The image should be 4D\"\n",
    "        plt.imshow(image_tensor_4D.squeeze(0).to(\"cpu\"), cmap='gray')\n",
    "        plt.show();\n",
    "\n",
    "        TEST_SIGMA = 0.5  # Relatively high noise\n",
    "        noisy_image_tensor_4D = add_noise(image_tensor_4D, sigma=TEST_SIGMA)\n",
    "        print(f\"PSNR of constant noise image: {PSNR(image_tensor_4D, noisy_image_tensor_4D):.2f} dB\")\n",
    "        print(f\"SSIM of constant noise image: {SSIM(image_tensor_4D.squeeze(0).squeeze(-1), noisy_image_tensor_4D.squeeze(0).squeeze(-1)):.2f}\")\n",
    "        plt.imshow(noisy_image_tensor_4D.squeeze(0).to(\"cpu\"), cmap='gray')\n",
    "        plt.show();\n",
    "\n",
    "        TEST_LAMBDA = 0.04\n",
    "        pdhg_input_tensor_5D = noisy_image_tensor_4D.unsqueeze(0)\n",
    "        print(f\"PDHG input size: {pdhg_input_tensor_5D.size()}\")\n",
    "        assert len(pdhg_input_tensor_5D.size()) == 5, \"The input for PDHG should be 5D\"\n",
    "        denoised_image_tensor_5D = reconstruct_with_PDHG(\n",
    "            pdhg_input_tensor_5D, \n",
    "            lambda_reg=TEST_LAMBDA, \n",
    "            T=128)\n",
    "        \n",
    "        denoised_image_tensor_5D = torch.clamp(denoised_image_tensor_5D, 0, 1) # Clip the values to 0 and 1\n",
    "        psnr_value_denoised = PSNR(image_tensor_4D, denoised_image_tensor_5D.squeeze(0))\n",
    "        print(f\"PSNR of reconstructed image: {psnr_value_denoised:.2f} dB\")\n",
    "        denoised_image_numpy_3D = denoised_image_tensor_5D.squeeze(0).squeeze(0).to(\"cpu\").detach().numpy()\n",
    "        plt.imshow(denoised_image_numpy_3D, cmap='gray')\n",
    "        plt.show();\n",
    "\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"\"\"\n",
    "In this example, a lot of noise has been applied to the original image. The PDHG algorithm tries to reconstruct the image from the noisy image. It did remove some noise and improved the PSNR value. However, the quality has been degraded significantly. We will see whether we can improve this by learning a set of parameters map.\n",
    "\"\"\")\n",
    "    \n",
    "    # The lambda parameter is the regularization parameter. The higher the lambda, the more the regularization. The T parameter is the number of iterations. The higher the T, the more the iterations. The PSNR value is the Peak Signal to Noise Ratio. The higher the PSNR, the better the reconstruction.\n",
    "\n",
    "test_reconstruct_with_PDHG()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "### Full Architecture\n",
    "\n",
    "<!-- UNET to PDHG\n",
    "\n",
    "The whole architecture can be seen as unsupervised: The data only contains (clean) images.\n",
    "\n",
    "The whole model: Input is an image. Output is also an image.\n",
    "\n",
    "The UNET actually only outputs the regularisation parameter map. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code taken from https://www.github.com/koflera/LearningRegularizationParameterMaps\n",
    "\n",
    "class DynamicImageStaticPrimalDualNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        T=128,\n",
    "        cnn_block=None,\n",
    "        mode=\"lambda_cnn\",\n",
    "        up_bound=0,\n",
    "        phase=\"training\",\n",
    "    ):\n",
    "        # print(f\"Running: {DynamicImageStaticPrimalDualNN.__name__}\")\n",
    "        super(DynamicImageStaticPrimalDualNN, self).__init__()\n",
    "\n",
    "        # gradient operators and clipping function\n",
    "        dim = 3\n",
    "        self.GradOps = GradOperators(dim, mode=\"forward\", padmode=\"circular\")\n",
    "\n",
    "        # operator norms\n",
    "        self.op_norm_AHA = torch.sqrt(torch.tensor(1.0))\n",
    "        self.op_norm_GHG = torch.sqrt(torch.tensor(12.0))\n",
    "        # operator norm of K = [A, \\nabla]\n",
    "        # https://iopscience.iop.org/article/10.1088/0031-9155/57/10/3065/pdf,\n",
    "        # see page 3083\n",
    "        self.L = torch.sqrt(self.op_norm_AHA**2 + self.op_norm_GHG**2)\n",
    "\n",
    "        # function for projecting\n",
    "        self.ClipAct = ClipAct()\n",
    "\n",
    "        if mode == \"lambda_xyt\":\n",
    "            # one single lambda for x,y and t\n",
    "            self.lambda_reg = nn.Parameter(torch.tensor([-1.5]), requires_grad=True)\n",
    "\n",
    "        elif mode == \"lambda_xy_t\":\n",
    "            # one (shared) lambda for x,y and one lambda for t\n",
    "            self.lambda_reg = nn.Parameter(\n",
    "                torch.tensor([-4.5, -1.5]), requires_grad=True\n",
    "            )\n",
    "\n",
    "        elif mode == \"lambda_cnn\":\n",
    "            # the CNN-block to estimate the lambda regularization map\n",
    "            # must be a CNN yielding a two-channeld output, i.e.\n",
    "            # one map for lambda_cnn_xy and one map for lambda_cnn_t\n",
    "            self.cnn = cnn_block    # NOTE: This is actually the UNET!!! (At least in this project)\n",
    "            self.up_bound = torch.tensor(up_bound)\n",
    "\n",
    "        # number of terations\n",
    "        self.T = T\n",
    "        self.mode = mode\n",
    "\n",
    "        # constants depending on the operators\n",
    "        self.tau = nn.Parameter(\n",
    "            torch.tensor(10.0), requires_grad=True\n",
    "        )  # starting value approximately  1/L\n",
    "        self.sigma = nn.Parameter(\n",
    "            torch.tensor(10.0), requires_grad=True\n",
    "        )  # starting value approximately  1/L\n",
    "\n",
    "        # theta should be in \\in [0,1]\n",
    "        self.theta = nn.Parameter(\n",
    "            torch.tensor(10.0), requires_grad=True\n",
    "        )  # starting value approximately  1\n",
    "\n",
    "        # distinguish between training and test phase;\n",
    "        # during training, the input is padded using \"reflect\" padding, because\n",
    "        # patches are used by reducing the number of temporal points;\n",
    "        # while testing, \"reflect\" padding is used in x,y- direction, while\n",
    "        # circular padding is used in t-direction\n",
    "        self.phase = phase\n",
    "\n",
    "    def get_lambda_cnn(self, x):\n",
    "        # padding\n",
    "        # arbitrarily chosen, maybe better to choose it depending on the\n",
    "        # receptive field of the CNN or so;\n",
    "        # seems to be important in order not to create \"holes\" in the\n",
    "        # lambda_maps in t-direction\n",
    "        npad_xy = 4\n",
    "        # npad_t = 8\n",
    "        npad_t = 0 # TODO: Time dimension should not be necessary for single image input.\n",
    "        # I changed the npad_t to 0 so that I can run on single image input without change the 3D type config. It seems that the number of frames must be greater than npad_t?\n",
    "\n",
    "        pad = (npad_t, npad_t, npad_xy, npad_xy, npad_xy, npad_xy)\n",
    "\n",
    "        if self.phase == \"training\":\n",
    "            x = F.pad(x, pad, mode=\"reflect\")\n",
    "\n",
    "        elif self.phase == \"testing\":\n",
    "            pad_refl = (0, 0, npad_xy, npad_xy, npad_xy, npad_xy)\n",
    "            pad_circ = (npad_t, npad_t, 0, 0, 0, 0)\n",
    "\n",
    "            x = F.pad(x, pad_refl, mode=\"reflect\")\n",
    "            x = F.pad(x, pad_circ, mode=\"circular\")\n",
    "\n",
    "        # estimate parameter map\n",
    "        lambda_cnn = self.cnn(x) # NOTE: The cnn is actually the UNET block!!! (At least in this project)\n",
    "\n",
    "        # crop\n",
    "        neg_pad = tuple([-pad[k] for k in range(len(pad))])\n",
    "        lambda_cnn = F.pad(lambda_cnn, neg_pad)\n",
    "\n",
    "        # double spatial map and stack\n",
    "        lambda_cnn = torch.cat((lambda_cnn[:, 0, ...].unsqueeze(1), lambda_cnn), dim=1)\n",
    "\n",
    "        # constrain map to be striclty positive; further, bound it from below\n",
    "        if self.up_bound > 0:\n",
    "            # constrain map to be striclty positive; further, bound it from below\n",
    "            lambda_cnn = self.up_bound * self.op_norm_AHA * torch.sigmoid(lambda_cnn)\n",
    "        else:\n",
    "            lambda_cnn = 0.1 * self.op_norm_AHA * F.softplus(lambda_cnn)\n",
    "\n",
    "        del pad\n",
    "        del x\n",
    "        del neg_pad\n",
    "\n",
    "        return lambda_cnn\n",
    "\n",
    "    def forward(\n",
    "            self, x, lambda_map=None, \n",
    "            # lambda_reg_container=None,\n",
    "    ):\n",
    "        if lambda_map is None:\n",
    "            # estimate lambda reg from the image\n",
    "            lambda_reg = self.get_lambda_cnn(x)\n",
    "        else:\n",
    "            lambda_reg = lambda_map\n",
    "\n",
    "        # if lambda_reg_container is not None:\n",
    "        #     assert type(lambda_reg_container) == list, f\"lambda_reg_container should be a list, not {type(lambda_reg_container)}\"\n",
    "        #     lambda_reg_container.append(lambda_reg) # For comparison\n",
    "\n",
    "        x.to(DEVICE)\n",
    "        x1 = reconstruct_with_PDHG(x, lambda_reg, self.T)\n",
    "\n",
    "        del lambda_reg\n",
    "        del x\n",
    "\n",
    "        return x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "### Data loading class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code taken from https://www.github.com/koflera/LearningRegularizationParameterMaps\n",
    "\n",
    "class DynamicImageStaticDenoisingDataset(Dataset):\n",
    "\t\n",
    "\tdef __init__(\n",
    "\t\tself, \n",
    "\t\tdata_path: str, \n",
    "\t\tids: list,\n",
    "\t\t# scale_factor = 0.5, \n",
    "\t\t# patches_size = None,\n",
    "\t\t# strides= None,\n",
    "\t\tresize_square = 120,\n",
    "\t\tsigma = (0.1, 0.5),  \n",
    "\t\tdevice: str = \"cuda\"\n",
    "\t):\n",
    "\t\tself.device = device\n",
    "\t\t# self.scale_factor = scale_factor\n",
    "\t\tself.resize_square = resize_square\n",
    "\n",
    "\t\txray_images = load_images_chest_xray(data_path, ids)\n",
    "\n",
    "\t\txf_list = []\n",
    "\t\tfor image in xray_images:\n",
    "\t\t\timage = crop_to_square_and_resize(image, self.resize_square)\n",
    "\t\t\timage = image.convert('L') #convert to grey_scale\n",
    "\t\t\timage_data = np.asarray(image)\n",
    "\t\t\txf = torch.tensor(image_data, dtype=torch.float)\n",
    "\t\t\t# Assume image is in [0, 255] range\n",
    "\t\t\txf = xf / 255\n",
    "\t\t\tassert len(xf.size()) == 2, f\"Expected 2D tensor, got {xf.size()}\"\n",
    "\t\t\txf = xf.unsqueeze(0) # Add channel dimension\n",
    "\t\t\txf = xf.unsqueeze(-1) # Add time dimension. TODO: For legacy dynamic image code only. Will remove later.\n",
    "\t\t\txf_list.append(xf)\n",
    "\t\txf = torch.stack(xf_list, dim=0) # will have shape (mb, 1, Nx, Ny, Nt), where mb denotes the number of patches\n",
    "\t\tassert len(xf.size()) == 5, f\"Expected 5D tensor, got {xf.size()}\"\n",
    "\t\tassert xf.size(1) == 1, f\"Expected 1 channel, got {xf.size(1)}\"\n",
    "\t\tassert xf.size(2) == self.resize_square, f\"Expected width (Nx) of {self.resize_square}, got {xf.size(-3)}\"\n",
    "\t\tassert xf.size(3) == self.resize_square, f\"Expected height (Ny) of {self.resize_square}, got {xf.size(-2)}\"\n",
    "\t\tassert xf.size(4) == 1, f\"Expected 1 time step, got {xf.size(-1)}\"\n",
    "\n",
    "\t\t#create temporal TV vector to detect which patches contain the most motion\n",
    "\t\txf_patches_tv = (xf[...,1:] - xf[...,:-1]).pow(2).sum(dim=[1,2,3,4]) #contains the TV for all patches\n",
    "\t\t\n",
    "\t\t#normalize to 1 to have a probability vector\n",
    "\t\txf_patches_tv /= torch.sum(xf_patches_tv)\n",
    "\t\t\n",
    "\t\t#sort TV in descending order --> xfp_tv_ids[0] is the index of the patch with the most motion\n",
    "\t\tself.samples_weights = xf_patches_tv\n",
    "\n",
    "\t\t# # TODO: Investigate\n",
    "\t\t# # Change the values in samples_weights to be a range of integers from 0 to len(samples_weights)\n",
    "\t\t# # Unless I do this, when I run on a set of identical images, it will give me an error:\n",
    "\t\t# # RuntimeError: invalid multinomial distribution (encountering probability entry < 0)\n",
    "\t\t# self.samples_weights = torch.arange(len(self.samples_weights))\n",
    "\t\t\n",
    "\t\tself.xf = xf\n",
    "\t\tself.len = xf.shape[0]\n",
    "\t\t\n",
    "\t\tself.sigma_min = sigma[0]\n",
    "\t\tself.sigma_max = sigma[1]\n",
    "\t\t\n",
    "\t\t\t\n",
    "\tdef __getitem__(self, index):\n",
    "\n",
    "\t\tsigma = self.sigma_min + torch.rand(1) * ( self.sigma_max - self.sigma_min )\n",
    "\n",
    "\t\tx_noise = add_noise(self.xf[index], sigma)\n",
    "\n",
    "\t\tdel sigma\n",
    "\n",
    "\t\treturn (\n",
    "\t\t\tx_noise.to(device=self.device),\n",
    "   \t\t\tself.xf[index].to(device=self.device)\n",
    "        )\n",
    "\t\t\n",
    "\tdef __len__(self):\n",
    "\t\treturn self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "### UNET\n",
    "\n",
    "The specific UNET architecture we use has the following parts:\n",
    "\n",
    "...\n",
    "\n",
    "We use Leaky RELU instead of RELU or Sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used https://github.com/milesial/Pytorch-UNet/blob/master/unet/unet_parts.py as a reference\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(\n",
    "            self, in_channels: int, out_channels: int, n_dimensions=3, activation=\"LeakyReLU\"):\n",
    "        super(DoubleConv, self).__init__()\n",
    "\n",
    "        def get_conv(in_channels, out_channels):\n",
    "            # 1-dimensional convolution is not supported\n",
    "            if n_dimensions == 3:\n",
    "                return nn.Conv3d(in_channels, out_channels, kernel_size=(3, 3, 1), padding=(1, 1, 0))\n",
    "            elif n_dimensions == 2:\n",
    "                return nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), padding=(1, 1))\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported number of dimensions: {n_dimensions}\")\n",
    "\n",
    "        def get_activation():\n",
    "            if activation == \"LeakyReLU\":\n",
    "                return nn.LeakyReLU(negative_slope=0.01, inplace=True)\n",
    "            elif activation == \"ReLU\":\n",
    "                return nn.ReLU(inplace=True)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported activation function: {activation}\")\n",
    "\n",
    "        self.conv_block = nn.Sequential(\n",
    "            get_conv(in_channels, out_channels), get_activation(),\n",
    "            get_conv(out_channels, out_channels), get_activation())\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.conv_block(x)\n",
    "        \n",
    "\n",
    "class EncodeBlock3d(nn.Module):\n",
    "    def __init__(\n",
    "            self, in_channels: int, n_dimensions=3,\n",
    "            activation=\"LeakyReLU\",\n",
    "            downsampling_kernel=(2, 2, 1), downsampling_mode=\"max\"):\n",
    "        super(EncodeBlock3d, self).__init__()\n",
    "\n",
    "        len = downsampling_kernel[0] # Assume kernel has shape (len, len, 1)\n",
    "        assert downsampling_kernel == (len, len, 1), f\"Expected a flat square kernel like {(len, len, 1)}, got {downsampling_kernel}\"\n",
    "        stride = (2, 2, 1) # Stride 2x2 to halve each side \n",
    "        padding = ((len-1)//2, (len-1)//2, 0) # Padding (len-1) // 2 to exactly halve each side \n",
    "        if downsampling_mode == \"max\":\n",
    "            self.pool = nn.MaxPool3d(\n",
    "                kernel_size=downsampling_kernel, stride=stride, padding=padding)\n",
    "        elif downsampling_mode == \"avg\":\n",
    "            self.pool = nn.AvgPool3d(\n",
    "                kernel_size=downsampling_kernel, stride=stride, padding=padding)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown pooling method: {downsampling_mode}\")\n",
    "\n",
    "        self.double_conv = DoubleConv(in_channels, in_channels * 2, n_dimensions, activation=activation)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.pool(x)\n",
    "        x = self.double_conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class DecodeBlock3d(nn.Module):\n",
    "    def __init__(\n",
    "            self, in_channels: int, n_dimensions=3, \n",
    "            activation=\"LeakyReLU\",\n",
    "            upsampling_kernel=(2, 2, 1), upsampling_mode=\"linear_interpolation\"):\n",
    "        super(DecodeBlock3d, self).__init__()\n",
    "\n",
    "        if upsampling_mode == \"linear_interpolation\":\n",
    "            self.upsampling = nn.Sequential(\n",
    "                nn.Upsample(\n",
    "                    scale_factor=(2, 2, 1), # Assume the shape is (Nx, Ny, 1) where Nx is the image width and Ny is the image height.\n",
    "                    mode='trilinear', align_corners=True), # What difference does it make in the end if align_corners is True or False? Preserving symmetry?\n",
    "                # 1x1x1 convolution to reduce the number of channels while keeping the size the same\n",
    "                nn.Conv3d(\n",
    "                    in_channels, in_channels // 2, \n",
    "                    kernel_size=(1, 1, 1), stride=(1, 1, 1), padding=(0, 0, 0))\n",
    "            )\n",
    "        elif upsampling_mode == \"transposed_convolution\":  \n",
    "            len = upsampling_kernel[0] # Assume kernel has shape (len, len, 1)\n",
    "            assert upsampling_kernel == (len, len, 1), f\"Expected a flat square kernel like {(len, len, 1)}, got {upsampling_kernel}\"\n",
    "            stride = (2, 2, 1) # Stride 2x2 to double each side \n",
    "            padding = ((len-1)//2, (len-1)//2, 0) # Padding (len-1) // 2 to exactly double each side    \n",
    "            self.upsampling = nn.ConvTranspose3d(\n",
    "                in_channels, in_channels // 2, \n",
    "                kernel_size=upsampling_kernel, stride=stride, padding=padding, \n",
    "                output_padding=padding # TODO: Should this be the same as padding?\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported upsampling method: {upsampling_mode}\")\n",
    "        \n",
    "        self.double_conv = DoubleConv(in_channels, in_channels // 2, n_dimensions, activation=activation)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, x_encoder_output: torch.Tensor):\n",
    "        x = self.upsampling(x)\n",
    "        x = torch.cat([x_encoder_output, x], dim=1)   # skip-connection. No cropping since we ensure that the size is the same.\n",
    "        x = self.double_conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class UNet3d(nn.Module):\n",
    "    def __init__(\n",
    "            self, in_channels=1, out_channels=2, init_filters=32, n_blocks=3,\n",
    "            activation=\"LeakyReLU\",\n",
    "            downsampling_kernel=(2, 2, 1), downsampling_mode=\"max\",\n",
    "            upsampling_kernel=(2, 2, 1), upsampling_mode=\"linear_interpolation\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Assume that input is 5D tensor of shape (batch_size, channels, Nx, Ny, Nt)\n",
    "        where Nx is the image width and Ny is the image height.\n",
    "        Assume that batch_size = 1, channels = 1, Nx = Ny (square image), Nt = 1 (static image).\n",
    "        NOTE: The convention used in pytorch documentation is (batch_size, channels, Nt, Ny, Nx).\n",
    "        \"channels\" is equivalent to the number of filters or features.\n",
    "\n",
    "        Our paper (figure 2):\n",
    "            - in_channels = 1\n",
    "            - out_channels = 2\n",
    "            - init_filters = 32\n",
    "            - n_blocks = 3\n",
    "            - pooling: max pooling 2x2\n",
    "            - pool padding = 1\n",
    "                - 1 padding will keep the size of the \"image\" the same after each convolution. The skip-connection will NOT crop the encoder's output.\n",
    "            - upsampling kernel: 2x2 ?\n",
    "            - up_mode: linear interpolation\n",
    "\n",
    "        U-Net paper (2015, Olaf Ronneberger https://arxiv.org/abs/1505.04597):\n",
    "            - in_channels = 1\n",
    "            - out_channels = 2\n",
    "            - init_filters = 64\n",
    "            - n_blocks = 4\n",
    "            - pooling: max pooling 2x2\n",
    "            - pool padding = 0\n",
    "                - 0 padding will reduce the size of the \"image\" by 2 in each dimension after each convolution. The skip-connection will have to crop the encoder's output to match the decoder's input.\n",
    "            - upsampling kernel: 2x2\n",
    "            - up_mode: ? (linear interpolation or transposed convolution)\n",
    "        \"\"\"\n",
    "        super(UNet3d, self).__init__()\n",
    "        \n",
    "        self.c0x0 = DoubleConv( # TODO: Find a better name\n",
    "            in_channels=in_channels, \n",
    "            out_channels=init_filters,\n",
    "            activation=activation\n",
    "        )\n",
    "        self.encoder = nn.ModuleList([\n",
    "            EncodeBlock3d(\n",
    "                in_channels=init_filters * 2**i,\n",
    "                activation=activation,\n",
    "                downsampling_kernel=downsampling_kernel,\n",
    "                downsampling_mode=downsampling_mode\n",
    "            ) for i in range(n_blocks)\n",
    "        ])\n",
    "        self.decoder = nn.ModuleList([\n",
    "            DecodeBlock3d(\n",
    "                in_channels=init_filters * 2**(n_blocks-i),\n",
    "                activation=activation, \n",
    "                upsampling_kernel=upsampling_kernel,\n",
    "                upsampling_mode=upsampling_mode\n",
    "            ) for i in range(n_blocks)\n",
    "        ])\n",
    "        # 1x1x1 convo\n",
    "        self.c1x1 = nn.Conv3d( # TODO: Find a better name\n",
    "            in_channels=init_filters,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=(1, 1, 1), stride=(1, 1, 1), padding=(0, 0, 0)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # Assume that x is 5D tensor of shape (batch_size, channels, Nx, Ny, Nt)\n",
    "        # where Nx is the image width and Ny is the image height.\n",
    "        # Aslo assume that batch_size = 1, channels = 1, Nx = Ny (square image), Nt = 1 (static image).\n",
    "        # NOTE: The convention used in pytorch documentation is (batch_size, channels, Nt, Ny, Nx).\n",
    "        assert len(x.size()) == 5, f\"Expected 5D tensor, got {x.size()}\"\n",
    "        batch_size, channels, Nx, Ny, Nt = x.size()\n",
    "        assert channels == 1, f\"Expected 1 channel, got {channels}\" # TODO: Allow multiple channels (colour images)\n",
    "        assert Nx == Ny, f\"Expected square image, got ({Nx}, {Ny})\" # TODO: Allow non-square images\n",
    "        assert Nt == 1, f\"Expected 1 time step, got {Nt}\" # TODO: Allow multiple time steps (dynamic images, video)\n",
    "        assert batch_size == 1, f\"Expected batch size 1, got {batch_size}\" # TODO: Might train with larger batch size\n",
    "\n",
    "        n_blocks = len(self.encoder)\n",
    "        assert Nx >= 2**n_blocks, f\"Expected width (Nx) of at least {2**n_blocks}, got {Nx}\"\n",
    "        assert Ny >= 2**n_blocks, f\"Expected height (Ny) of at least {2**n_blocks}, got {Ny}\"\n",
    "\n",
    "        x = self.c0x0(x)\n",
    "\n",
    "        encoder_outputs = []\n",
    "        for i, enc_block in enumerate(self.encoder):\n",
    "            encoder_outputs.append(x)\n",
    "            x = enc_block(x)\n",
    "        for i, dec_block in enumerate(self.decoder):\n",
    "            x = dec_block(x, encoder_outputs[-i-1]) # skip-connection inside\n",
    "            \n",
    "        x = self.c1x1(x)\n",
    "\n",
    "        for enc_output in encoder_outputs:\n",
    "            del enc_output\n",
    "        del encoder_outputs\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_and_clear_cuda(expected, actual):\n",
    "    try:\n",
    "        assert expected == actual\n",
    "    except AssertionError:\n",
    "        print(f\"!!! ERROR !!! Expected: {expected}, got {actual}\")\n",
    "        with torch.no_grad():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "\n",
    "def test_unet_3d():  \n",
    "    if DISABLING_TESTS: return  \n",
    "    input_tensor = torch.randn(1, 1, 512, 512, 1)  # batch size of 1, 1 channel, 512x512x1 volume\n",
    "    \n",
    "    config = get_config()\n",
    "\n",
    "    # Example usage\n",
    "    model = UNet3d(\n",
    "        init_filters=32,\n",
    "        n_blocks=config[\"n_blocks\"],\n",
    "        activation=\"ReLU\",\n",
    "        downsampling_kernel=(2, 2, 1),\n",
    "        downsampling_mode=config[\"downsampling_mode\"],\n",
    "        upsampling_kernel=(2, 2, 1),\n",
    "        upsampling_mode=config[\"upsampling_mode\"],\n",
    "    )\n",
    "    output = model(input_tensor)\n",
    "    print(f\"UNet output shape: {output.shape}\")\n",
    "    assert_and_clear_cuda((1, 2, 512, 512, 1), output.shape)\n",
    "\n",
    "\n",
    "    conv_3d = nn.Conv3d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "    conv_3d_output = conv_3d(input_tensor)\n",
    "    print(f\"Conv3d output shape: {conv_3d_output.shape}\")\n",
    "    assert_and_clear_cuda((1, 64, 512, 512, 1), conv_3d_output.shape)\n",
    "\n",
    "\n",
    "    double_conv_3d = DoubleConv(64, 128)\n",
    "    double_conv_output = double_conv_3d(conv_3d_output)\n",
    "    print(f\"{DoubleConv.__name__} output shape: {double_conv_output.shape}\")\n",
    "    assert_and_clear_cuda((1, 128, 512, 512, 1), double_conv_output.shape)\n",
    "\n",
    "\n",
    "    max_3d = nn.MaxPool3d((3, 3, 1), stride=(2, 2, 1), padding=(1, 1, 0))\n",
    "    max_3d_output_1 = max_3d(input_tensor)\n",
    "    print(f\"MaxPool3d output 1 shape: {max_3d_output_1.shape}\")\n",
    "    assert_and_clear_cuda((1, 1, 256, 256, 1), max_3d_output_1.shape)\n",
    "\n",
    "    max_3d_input = torch.randn(1, 128, 512, 512, 1)\n",
    "    max_3d_output_2 = max_3d(max_3d_input)\n",
    "    print(f\"MaxPool3d output 2 shape: {max_3d_output_2.shape}\")\n",
    "    assert_and_clear_cuda((1, 128, 256, 256, 1), max_3d_output_2.shape)\n",
    "\n",
    "    conv_transpose_3d = nn.ConvTranspose3d(\n",
    "        1024, 512, \n",
    "        kernel_size=(3, 3, 1), \n",
    "        stride=(2, 2, 1), \n",
    "        padding=(1, 1, 0), \n",
    "        output_padding=(1, 1, 0)\n",
    "    )\n",
    "    conv_transpose_3d_input = torch.randn(1, 1024, 32, 32, 1)\n",
    "    conv_transpose_3d_output = conv_transpose_3d(conv_transpose_3d_input)\n",
    "    print(f\"ConvTranspose3d output shape: {conv_transpose_3d_output.shape}\")\n",
    "    assert_and_clear_cuda((1, 512, 64, 64, 1), conv_transpose_3d_output.shape)\n",
    "\n",
    "\n",
    "    up_sample = nn.Upsample(\n",
    "        scale_factor=(2, 2, 1), \n",
    "        mode='trilinear', align_corners=True) # What difference does it make if align_corners is True or False?\n",
    "    up_sample_output = up_sample(input_tensor)\n",
    "    print(f\"Upsample output shape: {up_sample_output.shape}\")\n",
    "    assert_and_clear_cuda((1, 1, 1024, 1024, 1), up_sample_output.shape)\n",
    "                    \n",
    "\n",
    "    # # print(f\"\\n{model}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # # Delete the model and the output tensor\n",
    "    # del model\n",
    "    # del output\n",
    "    # torch.cuda.empty_cache()\n",
    "\n",
    "test_unet_3d()\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "### Create data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted from ...\n",
    "\n",
    "def get_datasets(config):\n",
    "    min_sigma = config[\"min_sigma\"]\n",
    "    max_sigma = config[\"max_sigma\"]\n",
    "    resize_square = config[\"resize_square\"]\n",
    "    device = config[\"device\"]\n",
    "\n",
    "    train_num_samples = config[\"train_num_samples\"]\n",
    "    train_ids = list(range(0, train_num_samples))\n",
    "    dataset_train = DynamicImageStaticDenoisingDataset(\n",
    "        data_path=config[\"train_data_path\"],\n",
    "        ids=train_ids,\n",
    "        sigma=(min_sigma, max_sigma),\n",
    "        resize_square=resize_square,\n",
    "        # strides=[120, 120, 1],\n",
    "        # patches_size=[120, 120, 1],\n",
    "        # strides=[256, 256, 1], # stride < patch will allow overlapping patches, maybe good to blend the patches?\n",
    "        # strides=[512, 512, 1],\n",
    "        # patches_size=[512, 512, 1],\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    val_num_samples = config[\"val_num_samples\"]\n",
    "    val_ids = list(range(0, val_num_samples))\n",
    "    dataset_valid = DynamicImageStaticDenoisingDataset(\n",
    "        data_path=config[\"val_data_path\"],\n",
    "        ids=val_ids,\n",
    "        sigma=(min_sigma, max_sigma),\n",
    "        resize_square=resize_square,\n",
    "        # strides=[120, 120, 1],\n",
    "        # patches_size=[120, 120, 1],\n",
    "        # strides=[256, 256, 1], # stride < patch will allow overlapping patches, maybe good to blend the patches?\n",
    "        # strides=[512, 512, 1],\n",
    "        # patches_size=[512, 512, 1],\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    test_num_samples = config[\"test_num_samples\"]\n",
    "    test_ids = list(range(0, test_num_samples))\n",
    "    dataset_test = DynamicImageStaticDenoisingDataset(\n",
    "        data_path=config[\"test_data_path\"],\n",
    "        ids=test_ids,\n",
    "        sigma=(min_sigma, max_sigma),\n",
    "        resize_square=resize_square,\n",
    "        # strides=[120, 120, 1],\n",
    "        # patches_size=[120, 120, 1],\n",
    "        # strides=[256, 256, 1], # stride < patch will allow overlapping patches, maybe good to blend the patches?\n",
    "        # strides=[512, 512, 1],\n",
    "        # patches_size=[512, 512, 1],\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    print(f\"Number of training samples: {len(dataset_train)}\")\n",
    "    print(f\"Number of validation samples: {len(dataset_valid)}\")\n",
    "    print(f\"Number of test samples: {len(dataset_test)}\")\n",
    "\n",
    "    return dataset_train, dataset_valid, dataset_test\n",
    "\n",
    "\n",
    "\n",
    "def get_dataloaders(config):\n",
    "\n",
    "    dataset_train, dataset_valid, dataset_test = get_datasets(config)\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    device = config[\"device\"]\n",
    "    random_seed = config[\"random_seed\"]\n",
    "\n",
    "    # Create training dataloader\n",
    "    # train_sampler = WeightedRandomSampler(dataset_train.samples_weights, len(dataset_train.samples_weights))\n",
    "    dataloader_train = torch.utils.data.DataLoader(\n",
    "        dataset_train, batch_size=batch_size, \n",
    "        # sampler=train_sampler,\n",
    "        generator=torch.Generator(device=device).manual_seed(random_seed),\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    # Create validation dataloader \n",
    "    # val_sampler = WeightedRandomSampler(dataset_valid.samples_weights, len(dataset_valid.samples_weights))\n",
    "    dataloader_valid = torch.utils.data.DataLoader(\n",
    "        dataset_valid, batch_size=batch_size, \n",
    "        # sampler=val_sampler,\n",
    "        generator=torch.Generator(device=device).manual_seed(random_seed),\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    # Create test dataloader\n",
    "    test_sampler = WeightedRandomSampler(dataset_test.samples_weights, len(dataset_test.samples_weights))\n",
    "    dataloader_test = torch.utils.data.DataLoader(\n",
    "        dataset_test, batch_size=batch_size, \n",
    "        # sampler=test_sampler,\n",
    "        generator=torch.Generator(device=device).manual_seed(random_seed),\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        dataloader_train, \n",
    "        dataloader_valid, \n",
    "        dataloader_test,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dataloader():\n",
    "    if DISABLING_TESTS: return\n",
    "    dataloader_train, dataloader_valid, dataloader_test = get_dataloaders(get_config())\n",
    "    for i, (x, y) in enumerate(dataloader_train):\n",
    "        print(f\"Batch {i+1}\")\n",
    "        print(f\"x size: {x.size()}\")\n",
    "        print(f\"y size: {y.size()}\")\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(x.squeeze(0).squeeze(0).squeeze(-1).to(\"cpu\"), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(y.squeeze(0).squeeze(0).squeeze(-1).to(\"cpu\"), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show();\n",
    "        if i == 5:\n",
    "            break\n",
    "\n",
    "    del dataloader_train\n",
    "    del dataloader_valid\n",
    "    del dataloader_test\n",
    "\n",
    "test_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code for one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code taken from https://www.github.com/koflera/LearningRegularizationParameterMaps\n",
    "\n",
    "# def train_iteration(optimizer, model, loss_func, sample):\n",
    "#     optimizer.zero_grad(set_to_none=True)  # Zero your gradients for every batch!\n",
    "#     noisy_image, clean_image = sample\n",
    "#     denoised_image = model(noisy_image)\n",
    "#     loss = loss_func(denoised_image, clean_image)\n",
    "#     loss.backward()\n",
    "    \n",
    "#     if loss.item() != loss.item():\n",
    "#         raise ValueError(\"NaN returned by loss function...\")\n",
    "\n",
    "#     optimizer.step()\n",
    "\n",
    "#     denoised_image = denoised_image.squeeze(0).squeeze(0).squeeze(-1)\n",
    "#     clean_image = clean_image.squeeze(0).squeeze(0).squeeze(-1)\n",
    "\n",
    "#     psnr = PSNR(denoised_image, clean_image)\n",
    "#     ssim = SSIM(denoised_image, clean_image)\n",
    "\n",
    "#     return loss.item(), psnr, ssim\n",
    "\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, loss_func) -> float:\n",
    "    running_loss = 0.\n",
    "    running_psnr = 0.\n",
    "    running_ssim = 0.\n",
    "    num_batches = len(data_loader)\n",
    "    # for sample in tqdm(data_loader): # tqdm helps show a nice progress bar\n",
    "    for sample in data_loader:\n",
    "        # loss, psnr, ssim = train_iteration(optimizer, model, loss_func, sample)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)  # Zero your gradients for every batch! TODO: Why?\n",
    "        noisy_image_5d, clean_image_5d = sample\n",
    "        denoised_image_5d = model(noisy_image_5d)\n",
    "        loss = loss_func(denoised_image_5d, clean_image_5d)\n",
    "\n",
    "        loss.backward()\n",
    "        if loss.item() != loss.item():\n",
    "            raise ValueError(\"NaN returned by loss function...\")\n",
    "        optimizer.step()\n",
    "\n",
    "        denoised_image_2d = denoised_image_5d.squeeze(0).squeeze(0).squeeze(-1)\n",
    "        clean_image_2d = clean_image_5d.squeeze(0).squeeze(0).squeeze(-1)\n",
    "        psnr = PSNR(denoised_image_2d, clean_image_2d)\n",
    "        ssim = SSIM(denoised_image_2d, clean_image_2d)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_psnr += psnr\n",
    "        running_ssim += ssim\n",
    "\n",
    "        # Free up memory\n",
    "        del loss \n",
    "        del denoised_image_5d # Delete output of model\n",
    "        del denoised_image_2d # Delete auxiliary variable\n",
    "        del clean_image_2d # Delete auxiliary variable\n",
    "        del noisy_image_5d # Noisy image is generated each time so can delete it\n",
    "        del clean_image_5d # TODO: Is this a copy that I can delete or a reference to the original?\n",
    "\n",
    "    avg_loss = running_loss / num_batches\n",
    "    avg_psnr = running_psnr / num_batches\n",
    "    avg_ssim = running_ssim / num_batches\n",
    "\n",
    "    del running_loss\n",
    "    del running_psnr\n",
    "    del running_ssim\n",
    "    del num_batches\n",
    "\n",
    "    return avg_loss, avg_psnr, avg_ssim\n",
    "\n",
    "\n",
    "# def validate_iteration(model, loss_func, sample):\n",
    "#     noisy_image, clean_image = sample\n",
    "#     denoised_image = model(noisy_image)\n",
    "#     loss = loss_func(denoised_image, clean_image)\n",
    "#     denoised_image = denoised_image.squeeze(0).squeeze(0).squeeze(-1)\n",
    "#     clean_image = clean_image.squeeze(0).squeeze(0).squeeze(-1)\n",
    "\n",
    "#     psnr = PSNR(denoised_image, clean_image)\n",
    "#     ssim = SSIM(denoised_image, clean_image)\n",
    "\n",
    "#     return loss.item(), psnr, ssim\n",
    "\n",
    "\n",
    "def validate_epoch(model, data_loader, loss_func) -> float:\n",
    "    running_loss = 0.\n",
    "    running_psnr = 0.\n",
    "    running_ssim = 0.\n",
    "    num_batches = len(data_loader)\n",
    "    # for sample in tqdm(data_loader): # tqdm helps show a nice progress bar\n",
    "    for sample in data_loader:\n",
    "        # loss, psnr, ssim = validate_iteration(model, loss_func, sample)\n",
    "\n",
    "        noisy_image_5d, clean_image_5d = sample\n",
    "        denoised_image_5d = model(noisy_image_5d)\n",
    "        loss = loss_func(denoised_image_5d, clean_image_5d)\n",
    "\n",
    "        denoised_image_2d = denoised_image_5d.squeeze(0).squeeze(0).squeeze(-1)\n",
    "        clean_image_2d = clean_image_5d.squeeze(0).squeeze(0).squeeze(-1)\n",
    "        psnr = PSNR(denoised_image_2d, clean_image_2d)\n",
    "        ssim = SSIM(denoised_image_2d, clean_image_2d)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_psnr += psnr\n",
    "        running_ssim += ssim\n",
    "\n",
    "        # Free up memory\n",
    "        del loss \n",
    "        del denoised_image_5d # Delete output of model\n",
    "        del denoised_image_2d # Delete auxiliary variable\n",
    "        del clean_image_2d # Delete auxiliary variable\n",
    "        del noisy_image_5d # Noisy image is generated each time so can delete it\n",
    "        del clean_image_5d # TODO: Is this a copy that I can delete or a reference to the original?\n",
    "\n",
    "    avg_loss = running_loss / num_batches\n",
    "    avg_psnr = running_psnr / num_batches\n",
    "    avg_ssim = running_ssim / num_batches\n",
    "\n",
    "    del running_loss\n",
    "    del running_psnr\n",
    "    del running_ssim\n",
    "    del num_batches\n",
    "\n",
    "    return avg_loss, avg_psnr, avg_ssim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prep for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(image_tensor_2D, image_name, folder_name):\n",
    "    image_tensor_2D = torch.clamp(image_tensor_2D, 0, 1) # Clip the values to 0 and 1\n",
    "    image_numpy = image_tensor_2D.to(\"cpu\").detach().numpy()\n",
    "    image_numpy_256 = image_numpy * 255\n",
    "    image_numpy_256_uint8 = image_numpy_256.astype(np.uint8)\n",
    "    image_to_save = Image.fromarray(image_numpy_256_uint8)  # TODO: Is there a shorter way to do this, similar to .convert(\"L\")?\n",
    "    image_to_save.save(f\"{folder_name}/{image_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_testcase():\n",
    "    CHEST_XRAY_BASE_DATA_PATH = \"../data/chest_xray\"\n",
    "    image = Image.open(f\"{CHEST_XRAY_BASE_DATA_PATH}/train/NORMAL/IM-0115-0001.jpeg\")\n",
    "    image = crop_to_square_and_resize(image, 512)\n",
    "\n",
    "    folder_name = \"testcases_tmp\"\n",
    "\n",
    "    image_name = \"chest_xray_clean\"\n",
    "    image.save(f\"{folder_name}/{image_name}.png\") \n",
    "\n",
    "    # Add noise to the image\n",
    "    noisy_image_tensor_4D = add_noise(convert_to_tensor_4D(convert_to_numpy(image)), sigma=0.5)\n",
    "    noisy_image_tensor_2D = noisy_image_tensor_4D.squeeze(0).squeeze(-1)\n",
    "    noisy_image_name = \"chest_xray_noisy\"\n",
    "    save_image(noisy_image_tensor_2D, \"chest_xray_noisy\", folder_name)\n",
    "\n",
    "    # Read the saved images\n",
    "    clean_image = Image.open(f\"{folder_name}/{image_name}.png\")\n",
    "    noisy_image = Image.open(f\"{folder_name}/{noisy_image_name}.png\")\n",
    "    \n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(clean_image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Clean Image\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(noisy_image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Noisy Image\")\n",
    "    plt.show();\n",
    "\n",
    "# make_testcase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: Use wandb to log the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Use wandb to log the training process\n",
    "# !wandb login\n",
    "def init_wandb(config):\n",
    "    project_name = config[\"project\"]\n",
    "    os.environ['WANDB_NOTEBOOK_NAME'] = project_name\n",
    "    os.environ['WANDB_MODE'] = config[\"wandb_mode\"] # https://docs.wandb.ai/quickstart\n",
    "    wandb.login()\n",
    "    # start a new wandb run to track this script\n",
    "    wandb.init(\n",
    "        # set the wandb project where this run will be logged\n",
    "        project=project_name,\n",
    "\n",
    "        # track hyperparameters and run metadata\n",
    "        config=get_config(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def temp_log_to_files():\n",
    "#     model_states_dir = \"tmp_2/model-chest_xray-2024_06_06_05_51_27\"\n",
    "#     config = get_config()\n",
    "#     with open(f\"{model_states_dir}/config.json\", \"w\") as f:\n",
    "#         json.dump(config, f, indent=4)\n",
    "#     with open(f\"{model_states_dir}/config.yaml\", \"w\") as f:\n",
    "#         yaml.dump(config, f)\n",
    "#     with open(f\"{model_states_dir}/config.txt\", \"w\") as f:\n",
    "#         f.write(str(config))\n",
    "\n",
    "# def test_temp_log_to_files():\n",
    "#     temp_log_to_files()\n",
    "\n",
    "# test_temp_log_to_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted from https://www.github.com/koflera/LearningRegularizationParameterMaps\n",
    "\n",
    "def start_training(config, pretrained_model_path=None, is_state_dict=False, start_epoch=0):\n",
    "    \n",
    "    dataloader_train, dataloader_valid, dataloader_test = get_dataloaders(config)\n",
    "\n",
    "    del dataloader_test # Not used for now\n",
    "\n",
    "    if pretrained_model_path is None or is_state_dict:\n",
    "        # Define CNN block\n",
    "        unet = UNet3d(\n",
    "            in_channels=config[\"in_channels\"],\n",
    "            out_channels=config[\"out_channels\"],\n",
    "            init_filters=config[\"init_filters\"],\n",
    "            n_blocks=config[\"n_blocks\"],\n",
    "            activation=config[\"activation\"],\n",
    "            downsampling_kernel=config[\"downsampling_kernel\"],\n",
    "            downsampling_mode=config[\"downsampling_mode\"],\n",
    "            upsampling_kernel=config[\"upsampling_kernel\"],\n",
    "            upsampling_mode=config[\"upsampling_mode\"],\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        # Construct primal-dual operator with nn\n",
    "        pdhg = DynamicImageStaticPrimalDualNN(\n",
    "            cnn_block=unet, \n",
    "            T=config[\"T\"],\n",
    "            phase=\"training\",\n",
    "            up_bound=config[\"up_bound\"],\n",
    "        ).to(DEVICE)\n",
    "        if is_state_dict:\n",
    "            pdhg.load_state_dict(torch.load(f\"{model_states_dir}/{pretrained_model_path}.pt\"))\n",
    "    else:\n",
    "        pdhg = torch.load(f\"{model_states_dir}/{pretrained_model_path}.pt\")\n",
    "\n",
    "    pdhg.train(True)\n",
    "\n",
    "    # TODO: Sometimes, creating the optimizer gives this error:\n",
    "    #   AttributeError: partially initialized module 'torch._dynamo' has no attribute 'trace_rules' (most likely due to a circular import)\n",
    "    optimizer = torch.optim.Adam(pdhg.parameters(), lr=config[\"learning_rate\"])\n",
    "    loss_function = torch.nn.MSELoss()\n",
    "\n",
    "    num_epochs = config[\"epochs\"]\n",
    "\n",
    "    save_epoch_local = config[\"save_epoch_local\"]\n",
    "    save_epoch_wandb = config[\"save_epoch_wandb\"]\n",
    "\n",
    "    time = datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    project = config[\"project\"]\n",
    "    model_name = f\"model-{project}-{time}\"\n",
    "\n",
    "    # Prepare to save the model\n",
    "    save_dir = config[\"save_dir\"]\n",
    "    model_states_dir = f\"{save_dir}/{model_name}\"\n",
    "\n",
    "    os.makedirs(model_states_dir, exist_ok=True)\n",
    "\n",
    "    def log_to_files():\n",
    "        with open(f\"{model_states_dir}/config.json\", \"w\") as f:\n",
    "            json.dump(config, f, indent=4)\n",
    "        with open(f\"{model_states_dir}/config.yaml\", \"w\") as f:\n",
    "            yaml.dump(config, f)\n",
    "        with open(f\"{model_states_dir}/config.txt\", \"w\") as f:\n",
    "            f.write(str(config))\n",
    "        with open(f\"{model_states_dir}/unet.txt\", \"w\") as f:\n",
    "            f.write(str(unet))\n",
    "        with open(f\"{model_states_dir}/pdhg_net.txt\", \"w\") as f:\n",
    "            f.write(str(pdhg))\n",
    "\n",
    "        def log_data(dataloader, stage):\n",
    "            dataset = dataloader.dataset\n",
    "            with open(f\"{model_states_dir}/dataloader_{stage}.txt\", \"w\") as f:\n",
    "                f.write(f\"Batch size: {dataloader.batch_size}\\n\\n\")\n",
    "                f.write(f\"Number of batches: {len(dataloader)}\\n\\n\")\n",
    "                f.write(f\"Number of samples: {len(dataset)}\\n\\n\")\n",
    "                f.write(f\"Samples weights:\\n{str(dataset.samples_weights)}\\n\\n\")\n",
    "                f.write(f\"Sample 0 size:\\n{str(len(dataset[0]))}  {str(dataset[0][0].size())}\\n\\n\")\n",
    "                f.write(f\"Sample 0:\\n{str(dataset[0])}\\n\\n\")\n",
    "        log_data(dataloader_train, \"train\")\n",
    "        log_data(dataloader_valid, \"val\")\n",
    "        # log_data(dataloader_test, \"test\")\n",
    "\n",
    "    log_to_files()\n",
    "\n",
    "    # noisy_image_path = \"./testcases/chest_xray_noisy.png\"\n",
    "    # clean_image_path = \"./testcases/chest_xray_clean.png\"\n",
    "\n",
    "    # def get_image(image_path):\n",
    "    #     image = Image.open(image_path)\n",
    "    #     image = image.convert(\"L\")\n",
    "    #     image_data = np.asarray(image)\n",
    "    #     image_data = convert_to_tensor_4D(image_data)\n",
    "    #     image_data = image_data.unsqueeze(0).to(DEVICE)\n",
    "    #     return image_data\n",
    "\n",
    "    # noisy_image_data = get_image(noisy_image_path)\n",
    "    # clean_image_data = get_image(clean_image_path)\n",
    "\n",
    "    # dataset_train = MyDataset(noisy_image_path, clean_image_path)\n",
    "    # dataset_valid = MyDataset(noisy_image_path, clean_image_path)\n",
    "\n",
    "    # dataloader_train = torch.utils.data.DataLoader(\n",
    "    #     dataset_train, batch_size=1, \n",
    "    #     generator=torch.Generator(device=DEVICE),\n",
    "    #     shuffle=True)\n",
    "    # dataloader_valid = torch.utils.data.DataLoader(\n",
    "    #     dataset_valid, batch_size=1, \n",
    "    #     generator=torch.Generator(device=DEVICE),\n",
    "    #     shuffle=False)\n",
    "\n",
    "\n",
    "    init_wandb(config)\n",
    "\n",
    "    # for epoch in range(start_epoch, num_epochs):\n",
    "    for epoch in tqdm(range(start_epoch, num_epochs)):\n",
    "\n",
    "        # Model training\n",
    "        pdhg.train(True)\n",
    "        training_loss, training_psnr, training_ssim = train_epoch(pdhg, dataloader_train, optimizer, loss_function)\n",
    "        # training_loss, training_psnr, training_ssim = train_iteration(optimizer, pdhg, loss_function, sample=(noisy_image_data, clean_image_data))\n",
    "        # print(f\"Epoch {epoch+1} - TRAINING LOSS: {training_loss} - TRAINING PSNR: {training_psnr} - TRAINING SSIM: {training_ssim}\")\n",
    "\n",
    "        # Optional: Use wandb to log training progress\n",
    "        wandb.log({\"training_loss\": training_loss})\n",
    "        wandb.log({\"training PSNR\": training_psnr})\n",
    "        wandb.log({\"training SSIM\": training_ssim})\n",
    "\n",
    "        del training_loss\n",
    "        del training_psnr\n",
    "        del training_ssim\n",
    "\n",
    "        pdhg.train(False)\n",
    "        with torch.no_grad():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            # Model validation\n",
    "            validation_loss, validation_psnr, validation_ssim = validate_epoch(pdhg, dataloader_valid, loss_function)\n",
    "            # validation_loss, validation_psnr, validation_ssim = validate_iteration(pdhg, loss_function, sample=(noisy_image_data, clean_image_data))\n",
    "            # print(f\"Epoch {epoch+1} - VALIDATION LOSS: {validation_loss} - VALIDATION PSNR: {validation_psnr} - VALIDATION SSIM: {validation_ssim}\")\n",
    "            time = datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "            # Optional: Use wandb to log training progress\n",
    "            wandb.log({\"validation_loss\": validation_loss})\n",
    "            wandb.log({\"validation PSNR\": validation_psnr})\n",
    "            wandb.log({\"validation SSIM\": validation_ssim})\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "        if (epoch+1) % save_epoch_local == 0:\n",
    "            current_model_name = f\"model_epoch_{epoch+1}\"\n",
    "            torch.save(pdhg, f\"{model_states_dir}/{current_model_name}.pt\")\n",
    "            \n",
    "            print(f\"Epoch {epoch+1} - VALIDATION LOSS: {validation_loss} - VALIDATION PSNR: {validation_psnr} - VALIDATION SSIM: {validation_ssim}\")\n",
    "\n",
    "        if (epoch+1) % save_epoch_wandb == 0:\n",
    "            wandb.log_model(f\"{model_states_dir}/{current_model_name}.pt\", name=f\"model_epoch_{epoch+1}\")\n",
    "            \n",
    "        del validation_loss\n",
    "        del validation_psnr\n",
    "        del validation_ssim\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "    # Save the entire model\n",
    "    torch.save(pdhg, f\"{model_states_dir}/final_model.pt\")\n",
    "    \n",
    "    wandb.log_model(f\"{model_states_dir}/final_model.pt\", name=f\"final_model\")\n",
    "    wandb.finish()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return pdhg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 531.38it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 422.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 156.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 200\n",
      "Number of validation samples: 8\n",
      "Number of test samples: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find chest_xray.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtrung-vuthanh24\u001b[0m (\u001b[33mwof\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/c/Users/t/Documents/GIT/DISSERTATION/LearningRegularizationParameterMaps/chest_xray/wandb/run-20240614_151852-qd5e1c4p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wof/chest_xray/runs/qd5e1c4p' target=\"_blank\">olive-sound-40</a></strong> to <a href='https://wandb.ai/wof/chest_xray' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wof/chest_xray' target=\"_blank\">https://wandb.ai/wof/chest_xray</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wof/chest_xray/runs/qd5e1c4p' target=\"_blank\">https://wandb.ai/wof/chest_xray/runs/qd5e1c4p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/10000 [02:31<208:38:58, 75.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - VALIDATION LOSS: 0.000529649099917151 - VALIDATION PSNR: 33.54196548461914 - VALIDATION SSIM: 0.8761545017737343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/10000 [04:55<203:00:15, 73.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - VALIDATION LOSS: 0.0005272753405733965 - VALIDATION PSNR: 33.12583923339844 - VALIDATION SSIM: 0.8636786973334103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/10000 [07:16<198:18:08, 71.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - VALIDATION LOSS: 0.0005482014385052025 - VALIDATION PSNR: 32.74043273925781 - VALIDATION SSIM: 0.8676025050788522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/10000 [09:41<200:18:53, 72.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - VALIDATION LOSS: 0.0005328176594048273 - VALIDATION PSNR: 33.14311218261719 - VALIDATION SSIM: 0.8621784463845195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/10000 [10:53<199:34:33, 71.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - VALIDATION LOSS: 0.000640691021544626 - VALIDATION PSNR: 32.56898498535156 - VALIDATION SSIM: 0.8432286367046387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/10000 [14:29<199:39:52, 71.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 - VALIDATION LOSS: 0.0006608612602576613 - VALIDATION PSNR: 32.43912124633789 - VALIDATION SSIM: 0.8413247543117851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 14/10000 [16:54<200:21:55, 72.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 - VALIDATION LOSS: 0.0004593834310071543 - VALIDATION PSNR: 33.759403228759766 - VALIDATION SSIM: 0.8813983966838718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16/10000 [19:13<196:04:15, 70.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 - VALIDATION LOSS: 0.00041007623440236785 - VALIDATION PSNR: 34.25713348388672 - VALIDATION SSIM: 0.8907237733704746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 18/10000 [21:36<197:01:59, 71.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 - VALIDATION LOSS: 0.000559211395739112 - VALIDATION PSNR: 33.036312103271484 - VALIDATION SSIM: 0.8685357870541216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 19/10000 [22:49<198:09:47, 71.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 - VALIDATION LOSS: 0.00045891201807535253 - VALIDATION PSNR: 34.292633056640625 - VALIDATION SSIM: 0.8914911675924136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 22/10000 [26:22<197:18:09, 71.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 - VALIDATION LOSS: 0.00048368175157520454 - VALIDATION PSNR: 33.88203811645508 - VALIDATION SSIM: 0.8823628774550856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 24/10000 [28:47<199:18:07, 71.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 - VALIDATION LOSS: 0.0003871411936415825 - VALIDATION PSNR: 34.71660614013672 - VALIDATION SSIM: 0.899261038973987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 26/10000 [31:12<200:47:32, 72.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 - VALIDATION LOSS: 0.00040500891373085324 - VALIDATION PSNR: 34.7791862487793 - VALIDATION SSIM: 0.8987308402458132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 28/10000 [33:39<202:09:24, 72.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 - VALIDATION LOSS: 0.00035001253309019376 - VALIDATION PSNR: 34.83082580566406 - VALIDATION SSIM: 0.9062612866925299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 29/10000 [34:51<201:11:07, 72.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 - VALIDATION LOSS: 0.00037827111555088777 - VALIDATION PSNR: 34.88362121582031 - VALIDATION SSIM: 0.9053624335483611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 32/10000 [38:26<199:13:18, 71.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 - VALIDATION LOSS: 0.00043932616608799435 - VALIDATION PSNR: 34.39997863769531 - VALIDATION SSIM: 0.8941261506207436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 34/10000 [40:54<201:44:49, 72.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 - VALIDATION LOSS: 0.0002972186866827542 - VALIDATION PSNR: 35.72433853149414 - VALIDATION SSIM: 0.9175557815672457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 36/10000 [43:17<199:09:38, 71.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 - VALIDATION LOSS: 0.00027310905534250196 - VALIDATION PSNR: 36.071781158447266 - VALIDATION SSIM: 0.9248201044979394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 38/10000 [45:41<199:12:27, 71.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 - VALIDATION LOSS: 0.0003665745571197476 - VALIDATION PSNR: 34.615421295166016 - VALIDATION SSIM: 0.906040623887837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 39/10000 [46:50<196:50:38, 71.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 - VALIDATION LOSS: 0.0004912187614536379 - VALIDATION PSNR: 33.435672760009766 - VALIDATION SSIM: 0.8811187613446116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 42/10000 [50:21<193:54:58, 70.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 - VALIDATION LOSS: 0.00038893837700015865 - VALIDATION PSNR: 34.494598388671875 - VALIDATION SSIM: 0.9018046757439078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 44/10000 [52:43<195:29:18, 70.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 - VALIDATION LOSS: 0.00036939786514267325 - VALIDATION PSNR: 34.74403762817383 - VALIDATION SSIM: 0.9039224660063983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 46/10000 [55:05<195:50:50, 70.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 - VALIDATION LOSS: 0.00030232896460802294 - VALIDATION PSNR: 35.81128692626953 - VALIDATION SSIM: 0.9209830250827672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 48/10000 [57:26<195:24:12, 70.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 - VALIDATION LOSS: 0.00034077424788847566 - VALIDATION PSNR: 34.9600830078125 - VALIDATION SSIM: 0.9119537046234012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 49/10000 [58:34<193:04:32, 69.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 - VALIDATION LOSS: 0.00021923283020441886 - VALIDATION PSNR: 37.046287536621094 - VALIDATION SSIM: 0.9386927822607756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 52/10000 [1:02:02<191:53:40, 69.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 - VALIDATION LOSS: 0.0003673026949400082 - VALIDATION PSNR: 35.33648681640625 - VALIDATION SSIM: 0.910733312981695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 54/10000 [1:04:26<195:24:47, 70.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 - VALIDATION LOSS: 0.00029702629217354115 - VALIDATION PSNR: 35.50544357299805 - VALIDATION SSIM: 0.9196727258666456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 56/10000 [1:06:48<196:07:28, 71.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 - VALIDATION LOSS: 0.0002957500983029604 - VALIDATION PSNR: 35.736873626708984 - VALIDATION SSIM: 0.9229258887722791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 58/10000 [1:09:08<194:19:23, 70.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 - VALIDATION LOSS: 0.0002680224788491614 - VALIDATION PSNR: 36.27826690673828 - VALIDATION SSIM: 0.928620468129456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 59/10000 [1:10:16<192:12:16, 69.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 - VALIDATION LOSS: 0.0003491407851470285 - VALIDATION PSNR: 35.05546569824219 - VALIDATION SSIM: 0.9118540765836238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 62/10000 [1:13:49<194:20:04, 70.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 - VALIDATION LOSS: 0.00027957662859989796 - VALIDATION PSNR: 35.796905517578125 - VALIDATION SSIM: 0.9246150663497822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 64/10000 [1:16:13<196:10:23, 71.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 - VALIDATION LOSS: 0.0003529121859173756 - VALIDATION PSNR: 34.927581787109375 - VALIDATION SSIM: 0.9108519602858127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 66/10000 [1:18:32<193:51:35, 70.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 - VALIDATION LOSS: 0.00035089821722067427 - VALIDATION PSNR: 34.998321533203125 - VALIDATION SSIM: 0.9105672003024518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 68/10000 [1:20:51<192:28:45, 69.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 - VALIDATION LOSS: 0.000347106069966685 - VALIDATION PSNR: 34.970523834228516 - VALIDATION SSIM: 0.9122961050192266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 69/10000 [1:22:03<194:27:31, 70.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 - VALIDATION LOSS: 0.00023465396861865884 - VALIDATION PSNR: 36.85015869140625 - VALIDATION SSIM: 0.9356771672672928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 72/10000 [1:25:32<193:45:58, 70.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 - VALIDATION LOSS: 0.00040097639794112183 - VALIDATION PSNR: 34.385955810546875 - VALIDATION SSIM: 0.9022229073853791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 74/10000 [1:27:53<194:32:11, 70.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 - VALIDATION LOSS: 0.00023762480486766435 - VALIDATION PSNR: 36.63970184326172 - VALIDATION SSIM: 0.935305886307925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 76/10000 [1:30:15<194:36:24, 70.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 - VALIDATION LOSS: 0.0003940462302125525 - VALIDATION PSNR: 34.74559783935547 - VALIDATION SSIM: 0.9054066377715915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 78/10000 [1:32:38<196:27:44, 71.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 - VALIDATION LOSS: 0.00034513271566538606 - VALIDATION PSNR: 34.963287353515625 - VALIDATION SSIM: 0.912837093700707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 79/10000 [1:33:49<196:41:55, 71.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 - VALIDATION LOSS: 0.00026064098892675247 - VALIDATION PSNR: 35.9832649230957 - VALIDATION SSIM: 0.9302587318755686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 82/10000 [1:37:25<197:28:28, 71.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 - VALIDATION LOSS: 0.000311141305246565 - VALIDATION PSNR: 35.959598541259766 - VALIDATION SSIM: 0.9215619608459173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 84/10000 [1:39:49<198:51:43, 72.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 - VALIDATION LOSS: 0.00034039319143630564 - VALIDATION PSNR: 35.30596160888672 - VALIDATION SSIM: 0.9150253140468971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 86/10000 [1:42:14<199:05:58, 72.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 - VALIDATION LOSS: 0.00031303641480917577 - VALIDATION PSNR: 35.61842727661133 - VALIDATION SSIM: 0.9201453929680586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 88/10000 [1:44:34<195:47:48, 71.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 - VALIDATION LOSS: 0.00033145905763376504 - VALIDATION PSNR: 34.996612548828125 - VALIDATION SSIM: 0.9152106139618306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 89/10000 [1:45:43<194:07:15, 70.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 - VALIDATION LOSS: 0.0002912766594818095 - VALIDATION PSNR: 35.82451248168945 - VALIDATION SSIM: 0.9247400425116421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 92/10000 [1:49:15<194:31:38, 70.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 - VALIDATION LOSS: 0.0002547591002439731 - VALIDATION PSNR: 36.3867073059082 - VALIDATION SSIM: 0.9316996127523184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 94/10000 [1:51:32<191:48:18, 69.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 - VALIDATION LOSS: 0.0003408956890780246 - VALIDATION PSNR: 35.07303237915039 - VALIDATION SSIM: 0.9142447826727926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 96/10000 [1:53:50<191:08:46, 69.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 - VALIDATION LOSS: 0.00032813549933052855 - VALIDATION PSNR: 35.54044723510742 - VALIDATION SSIM: 0.9184089979340732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 98/10000 [1:56:13<194:07:46, 70.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 - VALIDATION LOSS: 0.0003458922565187095 - VALIDATION PSNR: 35.56175994873047 - VALIDATION SSIM: 0.9153265869057029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 99/10000 [1:57:23<193:22:38, 70.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 - VALIDATION LOSS: 0.0003343791941006202 - VALIDATION PSNR: 34.9278450012207 - VALIDATION SSIM: 0.9154135895027817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 102/10000 [2:00:56<194:38:58, 70.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102 - VALIDATION LOSS: 0.00033844957033579703 - VALIDATION PSNR: 35.00516128540039 - VALIDATION SSIM: 0.9148561459319889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 104/10000 [2:03:21<196:22:30, 71.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104 - VALIDATION LOSS: 0.0003360724585945718 - VALIDATION PSNR: 35.02655792236328 - VALIDATION SSIM: 0.915411765521109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 106/10000 [2:05:50<200:57:38, 73.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106 - VALIDATION LOSS: 0.0003593874935177155 - VALIDATION PSNR: 34.768558502197266 - VALIDATION SSIM: 0.9107075823293624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 108/10000 [2:08:12<198:08:52, 72.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108 - VALIDATION LOSS: 0.00034939427314384375 - VALIDATION PSNR: 35.13239288330078 - VALIDATION SSIM: 0.9133848748758138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 109/10000 [2:09:24<197:39:35, 71.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110 - VALIDATION LOSS: 0.0002870567222998943 - VALIDATION PSNR: 35.59452819824219 - VALIDATION SSIM: 0.9243994943804146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 112/10000 [2:12:55<193:41:56, 70.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112 - VALIDATION LOSS: 0.0003005559501616517 - VALIDATION PSNR: 36.033512115478516 - VALIDATION SSIM: 0.9252033938596547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 114/10000 [2:15:18<195:23:55, 71.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114 - VALIDATION LOSS: 0.00028121394279878587 - VALIDATION PSNR: 36.472042083740234 - VALIDATION SSIM: 0.9278268400105536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 116/10000 [2:17:36<192:31:51, 70.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116 - VALIDATION LOSS: 0.000359990015567746 - VALIDATION PSNR: 35.04943084716797 - VALIDATION SSIM: 0.9123132260185536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 118/10000 [2:19:59<194:16:33, 70.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118 - VALIDATION LOSS: 0.00029601975438708905 - VALIDATION PSNR: 35.634117126464844 - VALIDATION SSIM: 0.9244800361987352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 119/10000 [2:21:06<190:42:18, 69.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120 - VALIDATION LOSS: 0.0002469412029313389 - VALIDATION PSNR: 36.44025802612305 - VALIDATION SSIM: 0.9339513930444867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 122/10000 [2:24:37<191:33:39, 69.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122 - VALIDATION LOSS: 0.0002518455794415786 - VALIDATION PSNR: 36.671024322509766 - VALIDATION SSIM: 0.9335212541900874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 124/10000 [2:26:54<190:02:21, 69.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124 - VALIDATION LOSS: 0.0002763662678262335 - VALIDATION PSNR: 36.289215087890625 - VALIDATION SSIM: 0.928150092772156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 126/10000 [2:29:14<190:27:59, 69.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126 - VALIDATION LOSS: 0.00033188222369062714 - VALIDATION PSNR: 35.02590560913086 - VALIDATION SSIM: 0.9153557106952369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 128/10000 [2:31:34<191:52:43, 69.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128 - VALIDATION LOSS: 0.00030083262390689924 - VALIDATION PSNR: 35.61758804321289 - VALIDATION SSIM: 0.9228709043703414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 129/10000 [2:32:44<191:40:52, 69.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130 - VALIDATION LOSS: 0.0003105562182099675 - VALIDATION PSNR: 35.66880416870117 - VALIDATION SSIM: 0.9211706869410873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 132/10000 [2:36:15<192:57:36, 70.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132 - VALIDATION LOSS: 0.00035625053715193644 - VALIDATION PSNR: 34.889183044433594 - VALIDATION SSIM: 0.9122425550304055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 134/10000 [2:38:29<188:43:06, 68.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134 - VALIDATION LOSS: 0.00033243604593735654 - VALIDATION PSNR: 35.61548614501953 - VALIDATION SSIM: 0.9169084310282171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 136/10000 [2:40:47<188:25:14, 68.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136 - VALIDATION LOSS: 0.000248892754825647 - VALIDATION PSNR: 36.21527862548828 - VALIDATION SSIM: 0.9331591341245176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 138/10000 [2:43:04<188:08:07, 68.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138 - VALIDATION LOSS: 0.00031843715623836033 - VALIDATION PSNR: 35.555931091308594 - VALIDATION SSIM: 0.9198114882367254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 139/10000 [2:44:15<190:30:19, 69.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140 - VALIDATION LOSS: 0.00033345598967571277 - VALIDATION PSNR: 35.36564254760742 - VALIDATION SSIM: 0.9173023254754842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 142/10000 [2:47:38<186:57:22, 68.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142 - VALIDATION LOSS: 0.00036535420986183453 - VALIDATION PSNR: 34.74984359741211 - VALIDATION SSIM: 0.9095958930162191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 144/10000 [2:49:54<186:06:54, 67.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144 - VALIDATION LOSS: 0.00027643107023322955 - VALIDATION PSNR: 35.88651657104492 - VALIDATION SSIM: 0.9268287914208174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 146/10000 [2:52:09<186:11:36, 68.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146 - VALIDATION LOSS: 0.0002766620837064693 - VALIDATION PSNR: 36.26758575439453 - VALIDATION SSIM: 0.9290746532284617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 148/10000 [2:54:25<185:07:58, 67.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148 - VALIDATION LOSS: 0.0002946799013443524 - VALIDATION PSNR: 35.946510314941406 - VALIDATION SSIM: 0.925978309684217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 149/10000 [2:55:31<183:44:23, 67.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150 - VALIDATION LOSS: 0.00034150109422625974 - VALIDATION PSNR: 35.085445404052734 - VALIDATION SSIM: 0.9137340226638614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 152/10000 [2:58:53<183:05:15, 66.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152 - VALIDATION LOSS: 0.000309484592435183 - VALIDATION PSNR: 35.80126953125 - VALIDATION SSIM: 0.9222302638097704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 154/10000 [3:01:14<188:45:15, 69.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154 - VALIDATION LOSS: 0.0003561236408131663 - VALIDATION PSNR: 34.63604736328125 - VALIDATION SSIM: 0.9102271287562549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 156/10000 [3:03:29<186:10:07, 68.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156 - VALIDATION LOSS: 0.0002564784472269821 - VALIDATION PSNR: 36.45441436767578 - VALIDATION SSIM: 0.9328806550278663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 158/10000 [3:05:45<186:00:01, 68.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158 - VALIDATION LOSS: 0.00031043196577229537 - VALIDATION PSNR: 35.40005111694336 - VALIDATION SSIM: 0.9190166779707671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 159/10000 [3:06:50<183:29:58, 67.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160 - VALIDATION LOSS: 0.0002694737695492222 - VALIDATION PSNR: 36.38864517211914 - VALIDATION SSIM: 0.9302303025422394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 162/10000 [3:10:15<184:31:29, 67.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162 - VALIDATION LOSS: 0.00029538580656662816 - VALIDATION PSNR: 36.070098876953125 - VALIDATION SSIM: 0.9262582060577274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 164/10000 [3:12:29<184:08:45, 67.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164 - VALIDATION LOSS: 0.00026145575611735694 - VALIDATION PSNR: 36.44545364379883 - VALIDATION SSIM: 0.9325863391139507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 166/10000 [3:14:41<182:11:12, 66.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166 - VALIDATION LOSS: 0.00024891187331377296 - VALIDATION PSNR: 36.58866882324219 - VALIDATION SSIM: 0.9346448818268777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 168/10000 [3:16:54<181:44:51, 66.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168 - VALIDATION LOSS: 0.00028515247322502546 - VALIDATION PSNR: 35.67227554321289 - VALIDATION SSIM: 0.9241216882035732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 169/10000 [3:18:03<183:56:29, 67.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170 - VALIDATION LOSS: 0.00019492914179863874 - VALIDATION PSNR: 37.219886779785156 - VALIDATION SSIM: 0.9450116080608368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 172/10000 [3:21:23<181:09:14, 66.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172 - VALIDATION LOSS: 0.0003023121762453229 - VALIDATION PSNR: 36.26837921142578 - VALIDATION SSIM: 0.9268178145405352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 174/10000 [3:23:39<183:20:07, 67.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174 - VALIDATION LOSS: 0.0002973877217300469 - VALIDATION PSNR: 35.7850456237793 - VALIDATION SSIM: 0.9248237727540731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 176/10000 [3:25:49<180:18:05, 66.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176 - VALIDATION LOSS: 0.00034867860995291267 - VALIDATION PSNR: 35.30437469482422 - VALIDATION SSIM: 0.91454977151376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 178/10000 [3:28:07<183:54:08, 67.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178 - VALIDATION LOSS: 0.000286972128378693 - VALIDATION PSNR: 35.799659729003906 - VALIDATION SSIM: 0.9261088892021179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 179/10000 [3:29:11<180:53:11, 66.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180 - VALIDATION LOSS: 0.00027443369526736205 - VALIDATION PSNR: 36.400203704833984 - VALIDATION SSIM: 0.9297228274735212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 182/10000 [3:32:35<184:21:29, 67.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182 - VALIDATION LOSS: 0.00035158868558937684 - VALIDATION PSNR: 35.001548767089844 - VALIDATION SSIM: 0.9138487049567252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 184/10000 [3:34:45<180:48:41, 66.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184 - VALIDATION LOSS: 0.0002520295975045883 - VALIDATION PSNR: 36.45884323120117 - VALIDATION SSIM: 0.9341832568040639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 186/10000 [3:37:00<182:07:49, 66.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186 - VALIDATION LOSS: 0.00029419652673823293 - VALIDATION PSNR: 35.777835845947266 - VALIDATION SSIM: 0.9250544037533998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 188/10000 [3:39:10<180:11:28, 66.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188 - VALIDATION LOSS: 0.0002715908867685357 - VALIDATION PSNR: 35.93291091918945 - VALIDATION SSIM: 0.928843917667806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 189/10000 [3:40:19<182:19:37, 66.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190 - VALIDATION LOSS: 0.00032606338936602697 - VALIDATION PSNR: 35.10631561279297 - VALIDATION SSIM: 0.9176880382221342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 192/10000 [3:43:40<182:08:01, 66.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192 - VALIDATION LOSS: 0.00024160092470992822 - VALIDATION PSNR: 36.464111328125 - VALIDATION SSIM: 0.9355003487617076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 194/10000 [3:45:54<181:50:59, 66.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194 - VALIDATION LOSS: 0.0002790745857055299 - VALIDATION PSNR: 35.84130859375 - VALIDATION SSIM: 0.9275471413393318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 196/10000 [3:48:03<179:38:14, 65.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196 - VALIDATION LOSS: 0.00027364871675672475 - VALIDATION PSNR: 36.544795989990234 - VALIDATION SSIM: 0.9313261407248378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 198/10000 [3:50:18<181:13:26, 66.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198 - VALIDATION LOSS: 0.0002934743133664597 - VALIDATION PSNR: 35.7060661315918 - VALIDATION SSIM: 0.9238618588876724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 199/10000 [3:51:22<178:54:21, 65.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200 - VALIDATION LOSS: 0.00036478156471275724 - VALIDATION PSNR: 34.66748046875 - VALIDATION SSIM: 0.90987455339095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 202/10000 [3:54:45<181:24:41, 66.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202 - VALIDATION LOSS: 0.0002964882314699935 - VALIDATION PSNR: 35.962215423583984 - VALIDATION SSIM: 0.9259514474279136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 204/10000 [3:56:59<182:34:59, 67.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 204 - VALIDATION LOSS: 0.00028318175736785633 - VALIDATION PSNR: 35.89763641357422 - VALIDATION SSIM: 0.9268292911542355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 206/10000 [3:59:11<180:30:53, 66.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 206 - VALIDATION LOSS: 0.00031411071722686756 - VALIDATION PSNR: 35.175682067871094 - VALIDATION SSIM: 0.9195810060505867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 208/10000 [4:01:26<182:14:12, 67.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208 - VALIDATION LOSS: 0.0002825392730301246 - VALIDATION PSNR: 35.88070297241211 - VALIDATION SSIM: 0.9263142667081355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 209/10000 [4:02:33<182:52:33, 67.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210 - VALIDATION LOSS: 0.0003208733414794551 - VALIDATION PSNR: 35.283756256103516 - VALIDATION SSIM: 0.9188420100540222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 212/10000 [4:05:52<181:55:55, 66.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 212 - VALIDATION LOSS: 0.00036683038706541993 - VALIDATION PSNR: 34.86371612548828 - VALIDATION SSIM: 0.9099643606356977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 214/10000 [4:08:04<179:54:50, 66.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214 - VALIDATION LOSS: 0.00029069105767121073 - VALIDATION PSNR: 35.67029571533203 - VALIDATION SSIM: 0.9238623330842257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 216/10000 [4:10:19<182:11:33, 67.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216 - VALIDATION LOSS: 0.00035213758656027494 - VALIDATION PSNR: 35.328243255615234 - VALIDATION SSIM: 0.9149887891363502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 218/10000 [4:12:29<178:38:16, 65.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218 - VALIDATION LOSS: 0.0003116064763162285 - VALIDATION PSNR: 35.36986541748047 - VALIDATION SSIM: 0.9195555667069554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 219/10000 [4:13:38<181:16:52, 66.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220 - VALIDATION LOSS: 0.00036297169026511256 - VALIDATION PSNR: 34.77337646484375 - VALIDATION SSIM: 0.9095520766729713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 222/10000 [4:16:56<178:40:48, 65.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222 - VALIDATION LOSS: 0.00033085439281421714 - VALIDATION PSNR: 34.86854934692383 - VALIDATION SSIM: 0.9154157181285918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 224/10000 [4:19:15<184:07:11, 67.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224 - VALIDATION LOSS: 0.0003851678811770398 - VALIDATION PSNR: 34.77357482910156 - VALIDATION SSIM: 0.9066855047324002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 226/10000 [4:21:22<178:01:49, 65.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226 - VALIDATION LOSS: 0.00021680699683201965 - VALIDATION PSNR: 36.7559928894043 - VALIDATION SSIM: 0.9391128912281096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 228/10000 [4:23:40<183:05:43, 67.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 228 - VALIDATION LOSS: 0.00024628059327369556 - VALIDATION PSNR: 36.37434768676758 - VALIDATION SSIM: 0.9313689734283387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 229/10000 [4:24:45<181:05:20, 66.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230 - VALIDATION LOSS: 0.00027362506170902634 - VALIDATION PSNR: 35.94867706298828 - VALIDATION SSIM: 0.9285044610626996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 232/10000 [4:28:09<183:37:53, 67.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232 - VALIDATION LOSS: 0.000264236916336813 - VALIDATION PSNR: 36.64875793457031 - VALIDATION SSIM: 0.9316752725005149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 234/10000 [4:30:19<180:10:02, 66.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234 - VALIDATION LOSS: 0.00036179366361466236 - VALIDATION PSNR: 35.21176528930664 - VALIDATION SSIM: 0.9121333028935492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 236/10000 [4:32:37<183:24:02, 67.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236 - VALIDATION LOSS: 0.00029359376640059054 - VALIDATION PSNR: 35.638851165771484 - VALIDATION SSIM: 0.9243041349476278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 238/10000 [4:34:54<184:22:38, 67.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238 - VALIDATION LOSS: 0.0003333763770569931 - VALIDATION PSNR: 35.67246627807617 - VALIDATION SSIM: 0.9195459636522233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 239/10000 [4:35:58<181:06:53, 66.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240 - VALIDATION LOSS: 0.00036813282440562034 - VALIDATION PSNR: 35.1348876953125 - VALIDATION SSIM: 0.9117472208134533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 242/10000 [4:39:22<183:27:04, 67.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242 - VALIDATION LOSS: 0.00036942904444003943 - VALIDATION PSNR: 34.87533187866211 - VALIDATION SSIM: 0.9083314280927777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 244/10000 [4:41:31<179:15:30, 66.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 244 - VALIDATION LOSS: 0.00030009218789928127 - VALIDATION PSNR: 36.0730094909668 - VALIDATION SSIM: 0.9239983661218285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 246/10000 [4:43:49<182:53:02, 67.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 246 - VALIDATION LOSS: 0.00029161613383621443 - VALIDATION PSNR: 35.682525634765625 - VALIDATION SSIM: 0.9244437668302208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 248/10000 [4:46:00<180:09:11, 66.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 248 - VALIDATION LOSS: 0.00028319407647359185 - VALIDATION PSNR: 35.677696228027344 - VALIDATION SSIM: 0.9252815439525545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 249/10000 [4:47:09<182:09:15, 67.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250 - VALIDATION LOSS: 0.00034875919300247915 - VALIDATION PSNR: 34.65412139892578 - VALIDATION SSIM: 0.9123527431230547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 252/10000 [4:50:28<180:49:51, 66.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 252 - VALIDATION LOSS: 0.00030589326343033463 - VALIDATION PSNR: 35.669189453125 - VALIDATION SSIM: 0.9219303118260502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 254/10000 [4:52:38<178:25:57, 65.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 254 - VALIDATION LOSS: 0.00028151731294201454 - VALIDATION PSNR: 36.1456413269043 - VALIDATION SSIM: 0.9279932082232236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 256/10000 [4:54:56<182:29:18, 67.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 256 - VALIDATION LOSS: 0.00028035600917064585 - VALIDATION PSNR: 36.72664260864258 - VALIDATION SSIM: 0.9305701383580715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 258/10000 [4:57:06<179:51:09, 66.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 258 - VALIDATION LOSS: 0.00031594229221809655 - VALIDATION PSNR: 35.10581588745117 - VALIDATION SSIM: 0.9184106435637771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 259/10000 [4:58:16<182:52:15, 67.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 260 - VALIDATION LOSS: 0.0003010830860148417 - VALIDATION PSNR: 35.83244705200195 - VALIDATION SSIM: 0.9230903165376783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 262/10000 [5:01:39<182:10:18, 67.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 262 - VALIDATION LOSS: 0.00036459519287745934 - VALIDATION PSNR: 34.68967056274414 - VALIDATION SSIM: 0.9098358403179198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 264/10000 [5:03:52<180:20:15, 66.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 264 - VALIDATION LOSS: 0.0003356430252097198 - VALIDATION PSNR: 35.34543991088867 - VALIDATION SSIM: 0.9164926865060925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 266/10000 [5:06:06<181:21:41, 67.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 266 - VALIDATION LOSS: 0.00032929301414696965 - VALIDATION PSNR: 35.280433654785156 - VALIDATION SSIM: 0.9169970019387305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 268/10000 [5:08:19<179:52:09, 66.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 268 - VALIDATION LOSS: 0.00026458745560375974 - VALIDATION PSNR: 36.08882522583008 - VALIDATION SSIM: 0.9296759120440782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 269/10000 [5:09:25<179:13:04, 66.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270 - VALIDATION LOSS: 0.0003118315744359279 - VALIDATION PSNR: 35.22855758666992 - VALIDATION SSIM: 0.9200015018681288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 272/10000 [5:12:48<180:19:15, 66.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 272 - VALIDATION LOSS: 0.00030378371047845576 - VALIDATION PSNR: 35.77657699584961 - VALIDATION SSIM: 0.922428287843585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 274/10000 [5:15:02<181:38:36, 67.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 274 - VALIDATION LOSS: 0.00029949019335617777 - VALIDATION PSNR: 35.56055450439453 - VALIDATION SSIM: 0.922325068249464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 276/10000 [5:17:16<180:47:29, 66.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276 - VALIDATION LOSS: 0.00029611906393256504 - VALIDATION PSNR: 35.46913146972656 - VALIDATION SSIM: 0.9222652174130379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 278/10000 [5:19:33<182:58:24, 67.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278 - VALIDATION LOSS: 0.00025011565958266146 - VALIDATION PSNR: 36.29338836669922 - VALIDATION SSIM: 0.9326839519882202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 279/10000 [5:20:40<182:49:54, 67.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280 - VALIDATION LOSS: 0.00035907120764022693 - VALIDATION PSNR: 34.953704833984375 - VALIDATION SSIM: 0.9121282201841026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 282/10000 [5:24:05<184:46:58, 68.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 282 - VALIDATION LOSS: 0.0003399142988200765 - VALIDATION PSNR: 35.2580451965332 - VALIDATION SSIM: 0.9160443183009923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 284/10000 [5:26:15<179:20:36, 66.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284 - VALIDATION LOSS: 0.00035362361450097524 - VALIDATION PSNR: 34.78614044189453 - VALIDATION SSIM: 0.9109451564477979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 286/10000 [5:28:33<183:23:33, 67.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286 - VALIDATION LOSS: 0.0002630924736877205 - VALIDATION PSNR: 36.34474182128906 - VALIDATION SSIM: 0.9309860425941348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 288/10000 [5:30:43<178:53:44, 66.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288 - VALIDATION LOSS: 0.0003333433123771101 - VALIDATION PSNR: 34.92708969116211 - VALIDATION SSIM: 0.9146633686380385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 289/10000 [5:31:52<181:01:24, 67.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290 - VALIDATION LOSS: 0.0004067187473992817 - VALIDATION PSNR: 34.32199478149414 - VALIDATION SSIM: 0.902222355234787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 292/10000 [5:35:12<179:26:38, 66.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 292 - VALIDATION LOSS: 0.0002822849801304983 - VALIDATION PSNR: 35.78861999511719 - VALIDATION SSIM: 0.9262097134944797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 294/10000 [5:37:31<183:19:36, 68.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 294 - VALIDATION LOSS: 0.000267428681581805 - VALIDATION PSNR: 36.44463348388672 - VALIDATION SSIM: 0.9310924164261818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 296/10000 [5:39:40<179:02:27, 66.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296 - VALIDATION LOSS: 0.00036858440944342874 - VALIDATION PSNR: 34.861995697021484 - VALIDATION SSIM: 0.9102322366385982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 298/10000 [5:41:59<182:33:14, 67.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298 - VALIDATION LOSS: 0.00031470633621211164 - VALIDATION PSNR: 35.20939636230469 - VALIDATION SSIM: 0.9198216558849812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 299/10000 [5:43:04<180:17:48, 66.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300 - VALIDATION LOSS: 0.0003168524490320124 - VALIDATION PSNR: 36.01068878173828 - VALIDATION SSIM: 0.92207514126648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 302/10000 [5:46:27<181:52:47, 67.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 302 - VALIDATION LOSS: 0.00020059000326000387 - VALIDATION PSNR: 37.3159294128418 - VALIDATION SSIM: 0.9447886064318419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 304/10000 [5:48:41<181:20:39, 67.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304 - VALIDATION LOSS: 0.00031128250520851 - VALIDATION PSNR: 35.54544448852539 - VALIDATION SSIM: 0.920008974990487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 306/10000 [5:50:56<181:35:48, 67.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 306 - VALIDATION LOSS: 0.0002584232006483944 - VALIDATION PSNR: 36.15325164794922 - VALIDATION SSIM: 0.9314689606826008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 308/10000 [5:53:09<180:47:30, 67.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 308 - VALIDATION LOSS: 0.0003163663459417876 - VALIDATION PSNR: 35.10554504394531 - VALIDATION SSIM: 0.9192226920357496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 309/10000 [5:54:19<183:02:24, 68.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 310 - VALIDATION LOSS: 0.0003111279656877741 - VALIDATION PSNR: 36.06949234008789 - VALIDATION SSIM: 0.9230974881803692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 312/10000 [5:57:43<183:40:39, 68.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 312 - VALIDATION LOSS: 0.0003063157892029267 - VALIDATION PSNR: 35.78925704956055 - VALIDATION SSIM: 0.9218193131660521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 314/10000 [5:59:54<179:39:36, 66.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 314 - VALIDATION LOSS: 0.00028628524341911543 - VALIDATION PSNR: 36.08013153076172 - VALIDATION SSIM: 0.9272073215476722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 316/10000 [6:02:12<182:17:29, 67.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 316 - VALIDATION LOSS: 0.0002860404674720485 - VALIDATION PSNR: 35.88433837890625 - VALIDATION SSIM: 0.9261549570622891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 318/10000 [6:04:22<178:31:16, 66.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 318 - VALIDATION LOSS: 0.0003292380843049614 - VALIDATION PSNR: 35.75611877441406 - VALIDATION SSIM: 0.9196263131128103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 319/10000 [6:05:32<181:13:01, 67.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 320 - VALIDATION LOSS: 0.0003833877053693868 - VALIDATION PSNR: 34.39378356933594 - VALIDATION SSIM: 0.9050351282667518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 322/10000 [6:08:50<178:38:03, 66.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 322 - VALIDATION LOSS: 0.0003269564695074223 - VALIDATION PSNR: 35.52947998046875 - VALIDATION SSIM: 0.9180052292878627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 324/10000 [6:11:06<180:34:39, 67.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 324 - VALIDATION LOSS: 0.0002837726588040823 - VALIDATION PSNR: 35.836952209472656 - VALIDATION SSIM: 0.926407300871104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 326/10000 [6:13:22<181:46:41, 67.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 326 - VALIDATION LOSS: 0.00032182926588575356 - VALIDATION PSNR: 34.99773025512695 - VALIDATION SSIM: 0.9173120824667216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 328/10000 [6:15:33<178:40:46, 66.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 328 - VALIDATION LOSS: 0.00038305046837194823 - VALIDATION PSNR: 34.44379425048828 - VALIDATION SSIM: 0.9060647207965702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 329/10000 [6:16:41<179:20:03, 66.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 330 - VALIDATION LOSS: 0.0002789246846077731 - VALIDATION PSNR: 35.75346374511719 - VALIDATION SSIM: 0.9278768568938374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 332/10000 [6:20:00<177:21:01, 66.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 332 - VALIDATION LOSS: 0.00028816280064347666 - VALIDATION PSNR: 36.24591827392578 - VALIDATION SSIM: 0.9274474269187898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 334/10000 [6:22:21<183:52:48, 68.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334 - VALIDATION LOSS: 0.00036209350946592167 - VALIDATION PSNR: 35.1313591003418 - VALIDATION SSIM: 0.9121992681185155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 336/10000 [6:24:36<182:48:49, 68.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336 - VALIDATION LOSS: 0.0003404253839107696 - VALIDATION PSNR: 34.99803161621094 - VALIDATION SSIM: 0.9145178802606762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 338/10000 [6:26:55<184:17:17, 68.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 338 - VALIDATION LOSS: 0.00033933422491827514 - VALIDATION PSNR: 35.226829528808594 - VALIDATION SSIM: 0.9158319172499254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 339/10000 [6:28:02<182:26:44, 67.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 340 - VALIDATION LOSS: 0.00035500552166922716 - VALIDATION PSNR: 34.98568344116211 - VALIDATION SSIM: 0.9117821680172981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 342/10000 [6:31:30<183:26:47, 68.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 342 - VALIDATION LOSS: 0.00036986489885748597 - VALIDATION PSNR: 35.09318542480469 - VALIDATION SSIM: 0.9109006434108018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 344/10000 [6:33:50<185:54:25, 69.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 344 - VALIDATION LOSS: 0.00029688537961192196 - VALIDATION PSNR: 36.10093307495117 - VALIDATION SSIM: 0.926054184999287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 346/10000 [6:36:03<182:10:40, 67.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 346 - VALIDATION LOSS: 0.0002865320329874521 - VALIDATION PSNR: 36.176998138427734 - VALIDATION SSIM: 0.9271213128800839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 348/10000 [6:38:22<183:41:35, 68.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 348 - VALIDATION LOSS: 0.0003101384500041604 - VALIDATION PSNR: 35.458160400390625 - VALIDATION SSIM: 0.9213855432092846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 349/10000 [6:39:31<183:38:35, 68.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350 - VALIDATION LOSS: 0.0003353826023158035 - VALIDATION PSNR: 35.340763092041016 - VALIDATION SSIM: 0.9164963974298537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 352/10000 [6:43:03<187:00:18, 69.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 352 - VALIDATION LOSS: 0.00035099336673738435 - VALIDATION PSNR: 35.14740753173828 - VALIDATION SSIM: 0.9127686008268745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 354/10000 [6:45:22<186:01:08, 69.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354 - VALIDATION LOSS: 0.00030607601365773007 - VALIDATION PSNR: 35.45933532714844 - VALIDATION SSIM: 0.9202018550044299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 356/10000 [6:47:41<185:55:15, 69.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 356 - VALIDATION LOSS: 0.0003178999922965886 - VALIDATION PSNR: 35.547584533691406 - VALIDATION SSIM: 0.9188956957210302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 358/10000 [6:50:04<189:18:19, 70.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 358 - VALIDATION LOSS: 0.0003399076304049231 - VALIDATION PSNR: 35.074249267578125 - VALIDATION SSIM: 0.9148462395936995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 359/10000 [6:51:14<188:18:41, 70.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360 - VALIDATION LOSS: 0.00028202015528222546 - VALIDATION PSNR: 36.222938537597656 - VALIDATION SSIM: 0.927976135694325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 362/10000 [6:54:49<190:03:23, 70.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 362 - VALIDATION LOSS: 0.0002650203532539308 - VALIDATION PSNR: 36.09346008300781 - VALIDATION SSIM: 0.9295093246584833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 364/10000 [6:57:13<191:24:19, 71.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 364 - VALIDATION LOSS: 0.00036496916982287075 - VALIDATION PSNR: 34.82459259033203 - VALIDATION SSIM: 0.9103722999065146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 366/10000 [6:59:34<189:18:15, 70.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 366 - VALIDATION LOSS: 0.00030326830528792925 - VALIDATION PSNR: 35.56913757324219 - VALIDATION SSIM: 0.9228832676136495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 368/10000 [7:01:58<190:33:52, 71.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 368 - VALIDATION LOSS: 0.0003961091861128807 - VALIDATION PSNR: 34.302223205566406 - VALIDATION SSIM: 0.9034333898619189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 369/10000 [7:03:09<190:13:44, 71.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 370 - VALIDATION LOSS: 0.0003786295637837611 - VALIDATION PSNR: 34.76189422607422 - VALIDATION SSIM: 0.9085719345287457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 372/10000 [7:06:41<189:52:24, 71.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 372 - VALIDATION LOSS: 0.00031507014500675723 - VALIDATION PSNR: 35.24254608154297 - VALIDATION SSIM: 0.9190383468151391\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "pdhg = start_training(get_config())\n",
    "\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "### Inference\n",
    "\n",
    "Demo the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CODE TO INFER AND SHOW SOME RESULTS HERE\n",
    "\n",
    "\n",
    "\n",
    "# def simple_plot(input_image_tensor_5D, subplot_index, image_name, clean_image_tensor_5D, folder_name, num_rows=2, num_cols=3):\n",
    "#     plot_image_tensor_2D = input_image_tensor_5D.squeeze(0).squeeze(0).squeeze(-1)\n",
    "#     clean_image_tensor_2D = clean_image_tensor_5D.squeeze(0).squeeze(0).squeeze(-1)\n",
    "#     psnr_value = PSNR(clean_image_tensor_2D, plot_image_tensor_2D)\n",
    "#     ssim_value = SSIM(clean_image_tensor_2D, plot_image_tensor_2D)\n",
    "#     plt.subplot(num_rows, num_cols, subplot_index)\n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(plot_image_tensor_2D.to(\"cpu\").detach().numpy(), cmap='gray')\n",
    "#     plt.title(f\"{image_name} PSNR: {psnr_value:.2f} dB\\n{image_name} SSIM: {ssim_value:.2f}\", fontsize=10)\n",
    "#     # Write the image to a file\n",
    "#     save_image(plot_image_tensor_2D, f\"{image_name}\", folder_name)\n",
    "\n",
    "# def get_image_tensor_5D(image):\n",
    "#     image = image.convert(\"L\")\n",
    "#     image_numpy = np.asarray(image)\n",
    "#     image_tensor_4D = convert_to_tensor_4D(image_numpy)\n",
    "#     image_tensor_5D = image_tensor_4D.unsqueeze(0).to(DEVICE)\n",
    "#     return image_tensor_5D\n",
    "\n",
    "# def denoise(pdhg: DynamicImageStaticPrimalDualNN, noisy_image_tensor_5D):\n",
    "#     pdhg.eval()\n",
    "#     with torch.no_grad():\n",
    "#         best_lambda_map = pdhg.get_lambda_cnn(noisy_image_tensor_5D)\n",
    "#     x_denoised_lambda_map_best_tensor_5D = reconstruct_with_PDHG(noisy_image_tensor_5D, best_lambda_map, pdhg.T)\n",
    "#     # x_denoised_lambda_map_best_tensor_5D = torch.clamp(x_denoised_lambda_map_best_tensor_5D, 0, 1)\n",
    "#     with torch.no_grad():\n",
    "#         torch.cuda.empty_cache()\n",
    "#     return best_lambda_map, x_denoised_lambda_map_best_tensor_5D\n",
    "\n",
    "\n",
    "# def brute_force_lambda(noisy_image_tensor_5D, clean_image_tensor_5D, T, min_value=0.01, max_value=0.1, num_values=10):\n",
    "#     # TODO: Brute-force single lambda\n",
    "#     best_psnr = 0\n",
    "#     best_lambda = 0\n",
    "#     lambas = list(np.linspace(min_value, max_value, num_values))\n",
    "#     psnr_values = []\n",
    "#     for lambda_value in lambas:\n",
    "#         with torch.no_grad():\n",
    "#             x_denoised_single_lambda_tensor_5D = reconstruct_with_PDHG(noisy_image_tensor_5D, lambda_value, T)\n",
    "#         psnr_value = PSNR(clean_image_tensor_5D, x_denoised_single_lambda_tensor_5D)\n",
    "#         psnr_value = psnr_value.item()\n",
    "#         # Convert to float\n",
    "#         psnr_value = np.float64(psnr_value)\n",
    "#         if psnr_value > best_psnr:\n",
    "#             best_psnr = psnr_value\n",
    "#             best_lambda = lambda_value\n",
    "#         psnr_values.append(psnr_value)\n",
    "\n",
    "#     # Plot the PSNR values\n",
    "#     plt.plot(lambas, psnr_values)\n",
    "#     plt.xlabel(\"Lambda\")\n",
    "#     plt.ylabel(\"PSNR\")\n",
    "#     plt.title(\"PSNR vs Lambda\")\n",
    "#     plt.show()\n",
    "    \n",
    "#     return best_lambda\n",
    "\n",
    "\n",
    "# def test_denoise(pdhg: DynamicImageStaticPrimalDualNN=None, model_name=\"\", best_lambda=None):\n",
    "#     \"\"\"\n",
    "#     Testing denoising with pre-trained parameters.\n",
    "#     \"\"\"\n",
    "#     clean_image = Image.open(f\"testcases/chest_xray_clean.png\")\n",
    "#     noisy_image = Image.open(f\"testcases/chest_xray_noisy.png\")\n",
    "#     clean_image_tensor_5D = get_image_tensor_5D(clean_image)\n",
    "#     noisy_image_tensor_5D = get_image_tensor_5D(noisy_image)\n",
    "\n",
    "#     if best_lambda is None:\n",
    "#         best_lambda = brute_force_lambda(noisy_image_tensor_5D, clean_image_tensor_5D, T=pdhg.T, min_value=0.01, max_value=1, num_values=100)\n",
    "\n",
    "#     print(f\"Best lambda: {best_lambda}\")\n",
    "\n",
    "#     k_w, k_h = 256, 256\n",
    "\n",
    "#     folder_name = f\"./tmp/images/model_{model_name}-kernel_{k_w}-best_lambda_{str(best_lambda).replace('.', '_')}-time_{datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}\"\n",
    "#     os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "#     plt.figure(figsize=(15, 6)) # Set the size of the plot\n",
    "\n",
    "#     simple_plot(clean_image_tensor_5D, 1, \"clean\", clean_image_tensor_5D, folder_name)\n",
    "#     simple_plot(noisy_image_tensor_5D, 2, \"noisy\", clean_image_tensor_5D, folder_name)\n",
    "\n",
    "#     x_denoised_single_lambda_tensor_5D = reconstruct_with_PDHG(noisy_image_tensor_5D, best_lambda, T=pdhg.T)\n",
    "    \n",
    "#     best_lambda_map, x_denoised_lambda_map_tensor_5D = denoise(pdhg, noisy_image_tensor_5D)\n",
    "\n",
    "#     # Clip to [0, 1]. The calculations may make it slightly below 0 and above 1\n",
    "#     x_denoised_single_lambda_tensor_5D = torch.clamp(x_denoised_single_lambda_tensor_5D, 0, 1)\n",
    "#     x_denoised_lambda_map_tensor_5D = torch.clamp(x_denoised_lambda_map_tensor_5D, 0, 1)\n",
    "\n",
    "#     simple_plot(x_denoised_single_lambda_tensor_5D, 3, f\"single_lambda_best_{str(best_lambda).replace('.', '_')}\", clean_image_tensor_5D, folder_name)\n",
    "#     simple_plot(x_denoised_lambda_map_tensor_5D, 4, \"lambda_map_best_using_function\", clean_image_tensor_5D, folder_name)\n",
    "\n",
    "#     lambda_map_1 = best_lambda_map[:, 0:1, :, :, :]\n",
    "#     lambda_map_2 = best_lambda_map[:, 1:2, :, :, :]\n",
    "#     lambda_map_3 = best_lambda_map[:, 2:3, :, :, :]\n",
    "\n",
    "#     lambda_map_1 = torch.clamp(lambda_map_1, 0, 1)\n",
    "#     lambda_map_2 = torch.clamp(lambda_map_2, 0, 1)\n",
    "#     lambda_map_3 = torch.clamp(lambda_map_3, 0, 1)\n",
    "\n",
    "#     simple_plot(lambda_map_1, 5, \"lambda_map_1\", clean_image_tensor_5D, folder_name)\n",
    "#     simple_plot(lambda_map_3, 6, \"lambda_map_3\", clean_image_tensor_5D, folder_name)\n",
    "\n",
    "#     plt.savefig(f\"{folder_name}/results.png\")\n",
    "\n",
    "#     plt.show();\n",
    "\n",
    "#     with open(f\"{folder_name}/log.txt\", \"w\") as f:\n",
    "#         f.write(f\"Best lambda: {best_lambda}\\n\")\n",
    "#         f.write(f\"PSNR (single lambda): {PSNR(clean_image_tensor_5D.squeeze(0).squeeze(0).squeeze(-1), x_denoised_single_lambda_tensor_5D.squeeze(0).squeeze(0).squeeze(-1))}\\n\")\n",
    "#         f.write(f\"PSNR (lambda map): {PSNR(clean_image_tensor_5D.squeeze(0).squeeze(0).squeeze(-1), x_denoised_lambda_map_tensor_5D.squeeze(0).squeeze(0).squeeze(-1))}\\n\")\n",
    "#         f.write(f\"Config: {get_config()}\\n\")\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "# model_dir = \"./tmp_2/model-2024_06_05_23_51_27\"\n",
    "# epoch = 4000\n",
    "# pdhg = torch.load(f\"{model_dir}/model_epoch_{epoch}.pt\")\n",
    "\n",
    "# test_denoise(\n",
    "#     pdhg=pdhg,\n",
    "#     model_name=f\"chest_xray_demo-epoch_{epoch}\",\n",
    "#     best_lambda=0.08\n",
    "# )\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def temp_test():"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Create a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_video(model_name, start_epoch=20, end_epoch=10_000, step=20):\n",
    "#     clean_image_path = \"./test_cases/turtle_clean/turtle clean.png\"\n",
    "#     noisy_image_path = \"./test_cases/turtle_noisy/turtle noisy.png\"\n",
    "#     clean_image_tensor_5D = get_image_tensor_5D(clean_image_path)\n",
    "#     noisy_image_tensor_5D = get_image_tensor_5D(noisy_image_path)\n",
    "#     clean_image_tensor_2D = clean_image_tensor_5D.squeeze(0).squeeze(0).squeeze(-1)\n",
    "#     noisy_image_tensor_2D = noisy_image_tensor_5D.squeeze(0).squeeze(0).squeeze(-1)\n",
    "\n",
    "#     psnr_noisy = PSNR(noisy_image_tensor_2D, clean_image_tensor_2D)\n",
    "#     ssim_noisy = SSIM(noisy_image_tensor_2D, clean_image_tensor_2D)\n",
    "\n",
    "\n",
    "\n",
    "#     frames_folder = f\"./tmp/{model_name}\"\n",
    "#     model_folder=f\"./tmp_2/{model_name}\"\n",
    "#     os.makedirs(frames_folder, exist_ok=True)\n",
    "#     os.makedirs(f\"{frames_folder}/denoised\", exist_ok=True)\n",
    "#     os.makedirs(f\"{frames_folder}/lambda_map_1\", exist_ok=True)\n",
    "#     os.makedirs(f\"{frames_folder}/lambda_map_2\", exist_ok=True)\n",
    "#     os.makedirs(f\"{frames_folder}/lambda_map_3\", exist_ok=True)\n",
    "\n",
    "#     with open(f\"./tmp/{model_name}/metrics.csv\", \"w\") as f:\n",
    "#         f.write(f\"Image, PSNR, SSIM\\n\")\n",
    "#         f.write(f\"Noisy, {psnr_noisy:.2f}, {ssim_noisy:.2f}\\n\")\n",
    "\n",
    "#         for epoch in range(start_epoch, end_epoch + 1, step):\n",
    "#             model_name = f\"model_epoch_{epoch}\"\n",
    "#             pdhg = torch.load(f\"{model_folder}/{model_name}.pt\")\n",
    "#             best_lambda_map, x_denoised_lambda_map_best_tensor_5D = denoise(pdhg, noisy_image_tensor_5D)\n",
    "#             x_denoised_lambda_map_best_tensor_5D = torch.clamp(x_denoised_lambda_map_best_tensor_5D, 0, 1)\n",
    "\n",
    "#             x_denoised_lambda_map_best_tensor_2D = x_denoised_lambda_map_best_tensor_5D.squeeze(0).squeeze(0).squeeze(-1)\n",
    "#             psnr_denoised = PSNR(x_denoised_lambda_map_best_tensor_2D, clean_image_tensor_2D)\n",
    "#             ssim_denoised = SSIM(x_denoised_lambda_map_best_tensor_2D, clean_image_tensor_2D)\n",
    "#             f.write(f\"{epoch}, {psnr_denoised:.2f}, {ssim_denoised:.2f}\\n\")\n",
    "\n",
    "#             denoised_image_to_save = Image.fromarray((x_denoised_lambda_map_best_tensor_2D.to(\"cpu\").detach().numpy() * 255).astype(np.uint8))\n",
    "#             denoised_image_to_save.save(f\"{frames_folder}/denoised/{epoch}.png\")\n",
    "\n",
    "#             lambda_map_1 = best_lambda_map[:, 0:1, :, :, :]\n",
    "#             lambda_map_2 = best_lambda_map[:, 1:2, :, :, :]\n",
    "#             lambda_map_3 = best_lambda_map[:, 2:3, :, :, :]\n",
    "#             lambda_map_1 = torch.clamp(lambda_map_1, 0, 1)\n",
    "#             lambda_map_2 = torch.clamp(lambda_map_2, 0, 1)\n",
    "#             lambda_map_3 = torch.clamp(lambda_map_3, 0, 1)\n",
    "\n",
    "#             lambda_map_1_to_save = Image.fromarray((lambda_map_1.squeeze(0).squeeze(0).squeeze(-1).to(\"cpu\").detach().numpy() * 255).astype(np.uint8))\n",
    "#             lambda_map_1_to_save.save(f\"{frames_folder}/lambda_map_1/{epoch}.png\")\n",
    "\n",
    "#             lambda_map_2_to_save = Image.fromarray((lambda_map_2.squeeze(0).squeeze(0).squeeze(-1).to(\"cpu\").detach().numpy() * 255).astype(np.uint8))\n",
    "#             lambda_map_2_to_save.save(f\"{frames_folder}/lambda_map_2/{epoch}.png\")\n",
    "\n",
    "#             lambda_map_3_to_save = Image.fromarray((lambda_map_3.squeeze(0).squeeze(0).squeeze(-1).to(\"cpu\").detach().numpy() * 255).astype(np.uint8))\n",
    "#             lambda_map_3_to_save.save(f\"{frames_folder}/lambda_map_3/{epoch}.png\")\n",
    "        \n",
    "\n",
    "#     # # Create the video\n",
    "#     # frames = []\n",
    "#     # for epoch in range(start_epoch, end_epoch + 1, step):\n",
    "#     #     frames.append(cv2.imread(f\"{frames_folder}/frame_{epoch}.png\"))\n",
    "#     # height, width, layers = frames[0].shape\n",
    "#     # size = (width, height)\n",
    "#     # out = cv2.VideoWriter(f\"{frames_folder}/video.avi\", cv2.VideoWriter_fourcc(*'DIVX'), 1, size)\n",
    "#     # for i in range(len(frames)):\n",
    "#     #     out.write(frames[i])\n",
    "#     # out.release()\n",
    "\n",
    "# create_video(\"model_turtle_2024_06_04_04_19_21\", start_epoch=20, end_epoch=10_000, step=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_revisualise():\n",
    "\n",
    "#     def vis(image_folder, image_name):\n",
    "#         image_path = f\"{image_folder}/{image_name}.png\"\n",
    "#         image = Image.open(image_path)\n",
    "#         plt.imshow(image, cmap='gray')\n",
    "#         plt.show();\n",
    "\n",
    "#     image_folder = \"tmp/PRESENT/presentation-img_turtle-best_lambda_0_07-kernel_256-model_-trained_on_-time_2024_06_04_22_59_31-epoch_100_000\"\n",
    "#     image_names = [\n",
    "#         \"lambda_map_3\",\n",
    "#         \"single_lambda_best_0_06000000000000001\",\n",
    "#         \"clean\",\n",
    "#     ]\n",
    "\n",
    "#     for image_name in image_names:\n",
    "#         vis(image_folder, image_name)\n",
    "\n",
    "# test_revisualise()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
