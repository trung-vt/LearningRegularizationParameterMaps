{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_time_importing_torch = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing torch ...\n",
      "Importing torch took 3.886222839355469e-05 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# NOTE: Importing torch the first time will always take a long time!\n",
    "if first_time_importing_torch:\n",
    "    print(f\"Importing torch ...\")\n",
    "    import_torch_start_time = time.time() \n",
    "import torch\n",
    "if first_time_importing_torch:\n",
    "    import_torch_end_time = time.time()\n",
    "    print(f\"Importing torch took {import_torch_end_time - import_torch_start_time} seconds\")\n",
    "    first_time_importing_torch = False\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print details helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_details(x, name):\n",
    "    print(f\"{name}:\")\n",
    "    print(x)\n",
    "    print(f\"  shape: {x.shape}\")\n",
    "    # print(f\"  dtype: {x.dtype}\")\n",
    "    # print(f\"  device: {x.device}\")\n",
    "    # print(f\"  is_complex: {x.is_complex()}\")\n",
    "    # print(f\"  is_floating_point: {x.is_floating_point()}\")\n",
    "    # print(f\"  is_contiguous: {x.is_contiguous()}\")\n",
    "    # print(f\"  is_pinned: {x.is_pinned()}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradOperators(torch.nn.Module):\n",
    "    @staticmethod\n",
    "    def diff_kernel(ndim, mode):\n",
    "        if mode == \"doublecentral\":\n",
    "            kern = torch.tensor((-1, 0, 1))\n",
    "        elif mode == \"central\":\n",
    "            kern = torch.tensor((-1, 0, 1)) / 2\n",
    "        elif mode == \"forward\":\n",
    "            kern = torch.tensor((0, -1, 1))\n",
    "        elif mode == \"backward\":\n",
    "            kern = torch.tensor((-1, 1, 0))\n",
    "        else:\n",
    "            raise ValueError(f\"mode should be one of (central, forward, backward, doublecentral), not {mode}\")\n",
    "        kernel = torch.zeros(ndim, 1, *(ndim * (3,)))\n",
    "        for i in range(ndim):\n",
    "            idx = tuple([i, 0, *(i * (1,)), slice(None), *((ndim - i - 1) * (1,))])\n",
    "            kernel[idx] = kern\n",
    "        return kernel\n",
    "\n",
    "    def __init__(self, dim:int=2, mode:str=\"doublecentral\", padmode:str = \"circular\"):\n",
    "        \"\"\"\n",
    "        An Operator for finite Differences / Gradients\n",
    "        Implements the forward as apply_G and the adjoint as apply_GH.\n",
    "        \n",
    "        Args:\n",
    "            dim (int, optional): Dimension. Defaults to 2.\n",
    "            mode (str, optional): one of doublecentral, central, forward or backward. Defaults to \"doublecentral\".\n",
    "            padmode (str, optional): one of constant, replicate, circular or refelct. Defaults to \"circular\".\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"kernel\", self.diff_kernel(dim, mode), persistent=False)\n",
    "        self._dim = dim\n",
    "        self._conv = (torch.nn.functional.conv1d, torch.nn.functional.conv2d, torch.nn.functional.conv3d)[dim - 1]\n",
    "        self._convT = (torch.nn.functional.conv_transpose1d, torch.nn.functional.conv_transpose2d, torch.nn.functional.conv_transpose3d)[dim - 1]\n",
    "        self._pad = partial(torch.nn.functional.pad, pad=2 * dim * (1,), mode=padmode)\n",
    "        if mode == 'central':\n",
    "            self._norm = (self.dim) ** (1 / 2)\n",
    "        else:\n",
    "            self._norm = (self.dim * 4) ** (1 / 2)\n",
    "\n",
    "    @property\n",
    "    def dim(self):\n",
    "        return self._dim\n",
    "    \n",
    "    def apply_G(self, x):\n",
    "        \"\"\"\n",
    "        Forward\n",
    "        \"\"\"\n",
    "        if x.is_complex():\n",
    "            xr = torch.view_as_real(x).moveaxis(-1, 0)\n",
    "        else:\n",
    "            xr = x\n",
    "        xr = xr.reshape(-1, 1, *x.shape[-self.dim :])\n",
    "        xp = self._pad(xr)\n",
    "        y = self._conv(xp, weight=self.kernel, bias=None, padding=0)\n",
    "        if x.is_complex():\n",
    "            y = y.reshape(2, *x.shape[: -self.dim], self.dim, *x.shape[-self.dim :])\n",
    "            y = torch.view_as_complex(y.moveaxis(0, -1).contiguous())\n",
    "        else:\n",
    "            y = y.reshape(*x.shape[0 : -self.dim], self.dim, *x.shape[-self.dim :])\n",
    "        return y\n",
    "\n",
    "    def apply_GH(self, x):\n",
    "        \"\"\"\n",
    "        Adjoint\n",
    "        \"\"\"\n",
    "        if x.is_complex():\n",
    "            xr = torch.view_as_real(x).moveaxis(-1, 0)\n",
    "        else:\n",
    "            xr = x\n",
    "        xr = xr.reshape(-1, self.dim, *x.shape[-self.dim :])\n",
    "        print_details(xr, \"xr\")\n",
    "\n",
    "        xp = self._pad(xr)\n",
    "        y = self._convT(xp, weight=self.kernel, bias=None, padding=2)\n",
    "        if x.is_complex():\n",
    "            y = y.reshape(2, *x.shape[: -self.dim - 1], *x.shape[-self.dim :])\n",
    "            y = torch.view_as_complex(y.moveaxis(0, -1).contiguous())\n",
    "        else:\n",
    "            y = y.reshape(*x.shape[: -self.dim - 1], *x.shape[-self.dim :])\n",
    "        return y\n",
    "    \n",
    "  \n",
    "    def apply_GHG(self, x):\n",
    "        if x.is_complex():\n",
    "            xr = torch.view_as_real(x).moveaxis(-1, 0)\n",
    "        else:\n",
    "            xr = x\n",
    "        xr = xr.reshape(-1, 1, *x.shape[-self.dim :])\n",
    "        xp = self._pad(xr)\n",
    "        tmp = self._conv(xp, weight=self.kernel, bias=None, padding=0)\n",
    "        tmp = self._pad(tmp)\n",
    "        y = self._convT(tmp, weight=self.kernel, bias=None, padding=2)\n",
    "        if x.is_complex():\n",
    "            y = y.reshape(2, *x.shape)\n",
    "            y = torch.view_as_complex(y.moveaxis(0, -1).contiguous())\n",
    "        else:\n",
    "            y = y.reshape(*x.shape)\n",
    "        return y\n",
    "\n",
    "    def forward(self, x, direction=1):\n",
    "        if direction>0:\n",
    "            return self.apply_G(x)\n",
    "        elif direction<0:\n",
    "            return self.apply_GH(x)\n",
    "        else:\n",
    "            return self.apply_GHG(x)\n",
    "\n",
    "\n",
    "    @property\n",
    "    def normGHG(self):\n",
    "        return self._norm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradOps test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_apply_G_2D():\n",
    "    grad_ops = GradOperators(dim=2, mode=\"forward\")\n",
    "    print_details(grad_ops.kernel, \"G.kernel\")\n",
    "\n",
    "    x = torch.tensor([[[1, 2], [3, 4]]], dtype=torch.float32)\n",
    "    print_details(x, \"x\")\n",
    "\n",
    "    # x_padde_circular = G._pad(x, mode=\"circular\")\n",
    "    # print_details(x_padde_circular, \"x_padde_circular\")\n",
    "\n",
    "    # x_padded_constant = G._pad(x, mode=\"constant\")\n",
    "    # print_details(x_padded_constant, \"x_padded_constant\")\n",
    "    \n",
    "    y = grad_ops.apply_G(x)\n",
    "    print_details(y, \"y\")\n",
    "\n",
    "    z = grad_ops.apply_GH(y)\n",
    "    print_details(z, \"z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G.kernel:\n",
      "tensor([[[[ 0.,  0.,  0.],\n",
      "          [ 0., -1.,  0.],\n",
      "          [ 0.,  1.,  0.]]],\n",
      "\n",
      "\n",
      "        [[[ 0.,  0.,  0.],\n",
      "          [ 0., -1.,  1.],\n",
      "          [ 0.,  0.,  0.]]]])\n",
      "  shape: torch.Size([2, 1, 3, 3])\n",
      "\n",
      "x:\n",
      "tensor([[[1., 2.],\n",
      "         [3., 4.]]])\n",
      "  shape: torch.Size([1, 2, 2])\n",
      "\n",
      "y:\n",
      "tensor([[[[ 2.,  2.],\n",
      "          [-2., -2.]],\n",
      "\n",
      "         [[ 1., -1.],\n",
      "          [ 1., -1.]]]])\n",
      "  shape: torch.Size([1, 2, 2, 2])\n",
      "\n",
      "xr:\n",
      "tensor([[[[ 2.,  2.],\n",
      "          [-2., -2.]],\n",
      "\n",
      "         [[ 1., -1.],\n",
      "          [ 1., -1.]]]])\n",
      "  shape: torch.Size([1, 2, 2, 2])\n",
      "\n",
      "z:\n",
      "tensor([[[-6., -2.],\n",
      "         [ 2.,  6.]]])\n",
      "  shape: torch.Size([1, 2, 2])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_apply_G_2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_apply_G_3D():\n",
    "    G = GradOperators(dim=3, mode=\"forward\")\n",
    "    print_details(G.kernel, \"G.kernel\")\n",
    "\n",
    "    x = torch.tensor([[[[1], [2]], [[3], [4]]]], dtype=torch.float32)\n",
    "    print_details(x, \"x\")\n",
    "\n",
    "    x_padde_circular = G._pad(x, mode=\"circular\")\n",
    "    print_details(x_padde_circular, \"x_padde_circular\")\n",
    "\n",
    "    x_padded_constant = G._pad(x, mode=\"constant\")\n",
    "    print_details(x_padded_constant, \"x_padded_constant\")\n",
    "    \n",
    "    y = G.apply_G(x)\n",
    "    print_details(y, \"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G.kernel:\n",
      "tensor([[[[[ 0.,  0.,  0.],\n",
      "           [ 0.,  0.,  0.],\n",
      "           [ 0.,  0.,  0.]],\n",
      "\n",
      "          [[ 0.,  0.,  0.],\n",
      "           [ 0., -1.,  0.],\n",
      "           [ 0.,  0.,  0.]],\n",
      "\n",
      "          [[ 0.,  0.,  0.],\n",
      "           [ 0.,  1.,  0.],\n",
      "           [ 0.,  0.,  0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.,  0.,  0.],\n",
      "           [ 0.,  0.,  0.],\n",
      "           [ 0.,  0.,  0.]],\n",
      "\n",
      "          [[ 0.,  0.,  0.],\n",
      "           [ 0., -1.,  0.],\n",
      "           [ 0.,  1.,  0.]],\n",
      "\n",
      "          [[ 0.,  0.,  0.],\n",
      "           [ 0.,  0.,  0.],\n",
      "           [ 0.,  0.,  0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.,  0.,  0.],\n",
      "           [ 0.,  0.,  0.],\n",
      "           [ 0.,  0.,  0.]],\n",
      "\n",
      "          [[ 0.,  0.,  0.],\n",
      "           [ 0., -1.,  1.],\n",
      "           [ 0.,  0.,  0.]],\n",
      "\n",
      "          [[ 0.,  0.,  0.],\n",
      "           [ 0.,  0.,  0.],\n",
      "           [ 0.,  0.,  0.]]]]])\n",
      "  shape: torch.Size([3, 1, 3, 3, 3])\n",
      "\n",
      "x:\n",
      "tensor([[[[1.],\n",
      "          [2.]],\n",
      "\n",
      "         [[3.],\n",
      "          [4.]]]])\n",
      "  shape: torch.Size([1, 2, 2, 1])\n",
      "\n",
      "x_padde_circular:\n",
      "tensor([[[[4., 4., 4.],\n",
      "          [3., 3., 3.],\n",
      "          [4., 4., 4.],\n",
      "          [3., 3., 3.]],\n",
      "\n",
      "         [[2., 2., 2.],\n",
      "          [1., 1., 1.],\n",
      "          [2., 2., 2.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[4., 4., 4.],\n",
      "          [3., 3., 3.],\n",
      "          [4., 4., 4.],\n",
      "          [3., 3., 3.]],\n",
      "\n",
      "         [[2., 2., 2.],\n",
      "          [1., 1., 1.],\n",
      "          [2., 2., 2.],\n",
      "          [1., 1., 1.]]]])\n",
      "  shape: torch.Size([1, 4, 4, 3])\n",
      "\n",
      "x_padded_constant:\n",
      "tensor([[[[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 2., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 3., 0.],\n",
      "          [0., 4., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]]])\n",
      "  shape: torch.Size([1, 4, 4, 3])\n",
      "\n",
      "y:\n",
      "tensor([[[[[ 2.],\n",
      "           [ 2.]],\n",
      "\n",
      "          [[-2.],\n",
      "           [-2.]]],\n",
      "\n",
      "\n",
      "         [[[ 1.],\n",
      "           [-1.]],\n",
      "\n",
      "          [[ 1.],\n",
      "           [-1.]]],\n",
      "\n",
      "\n",
      "         [[[ 0.],\n",
      "           [ 0.]],\n",
      "\n",
      "          [[ 0.],\n",
      "           [ 0.]]]]])\n",
      "  shape: torch.Size([1, 3, 2, 2, 1])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_apply_G_3D()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primal Dual NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClipAct(nn.Module):\n",
    "    def forward(self, x, threshold):\n",
    "        return clipact(x, threshold)\n",
    "\n",
    "\n",
    "def clipact(x, threshold):\n",
    "    is_complex = x.is_complex()\n",
    "    if is_complex:\n",
    "        x = torch.view_as_real(x)\n",
    "        threshold = threshold.unsqueeze(-1)\n",
    "    x = torch.clamp(x, -threshold, threshold)\n",
    "    if is_complex:\n",
    "        x = torch.view_as_complex(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicImagePrimalDualNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        T=128,\n",
    "        cnn_block=None,\n",
    "        mode=\"lambda_cnn\",\n",
    "        up_bound=0,\n",
    "        phase=\"training\",\n",
    "    ):\n",
    "        super(DynamicImagePrimalDualNN, self).__init__()\n",
    "\n",
    "        # gradient operators and clipping function\n",
    "        dim = 3\n",
    "        self.GradOps = GradOperators(dim, mode=\"forward\", padmode=\"circular\")\n",
    "\n",
    "        # operator norms\n",
    "        self.op_norm_AHA = torch.sqrt(torch.tensor(1.0))\n",
    "        self.op_norm_GHG = torch.sqrt(torch.tensor(12.0))\n",
    "        # operator norm of K = [A, \\nabla]\n",
    "        # https://iopscience.iop.org/article/10.1088/0031-9155/57/10/3065/pdf,\n",
    "        # see page 3083\n",
    "        self.L = torch.sqrt(self.op_norm_AHA**2 + self.op_norm_GHG**2)\n",
    "\n",
    "        # function for projecting\n",
    "        self.ClipAct = ClipAct()\n",
    "\n",
    "        if mode == \"lambda_xyt\":\n",
    "            # one single lambda for x,y and t\n",
    "            self.lambda_reg = nn.Parameter(torch.tensor([-1.5]), requires_grad=True)\n",
    "\n",
    "        elif mode == \"lambda_xy_t\":\n",
    "            # one (shared) lambda for x,y and one lambda for t\n",
    "            self.lambda_reg = nn.Parameter(\n",
    "                torch.tensor([-4.5, -1.5]), requires_grad=True\n",
    "            )\n",
    "\n",
    "        elif mode == \"lambda_cnn\":\n",
    "            # the CNN-block to estimate the lambda regularization map\n",
    "            # must be a CNN yielding a two-channeld output, i.e.\n",
    "            # one map for lambda_cnn_xy and one map for lambda_cnn_t\n",
    "            self.cnn = cnn_block    # NOTE: This is actually the UNET!!! (At least in this project)\n",
    "            self.up_bound = torch.tensor(up_bound)\n",
    "\n",
    "        # number of terations\n",
    "        self.T = T\n",
    "        self.mode = mode\n",
    "\n",
    "        # constants depending on the operators\n",
    "        self.tau = nn.Parameter(\n",
    "            torch.tensor(10.0), requires_grad=True\n",
    "        )  # starting value approximately  1/L\n",
    "        self.sigma = nn.Parameter(\n",
    "            torch.tensor(10.0), requires_grad=True\n",
    "        )  # starting value approximately  1/L\n",
    "\n",
    "        # theta should be in \\in [0,1]\n",
    "        self.theta = nn.Parameter(\n",
    "            torch.tensor(10.0), requires_grad=True\n",
    "        )  # starting value approximately  1\n",
    "\n",
    "        # distinguish between training and test phase;\n",
    "        # during training, the input is padded using \"reflect\" padding, because\n",
    "        # patches are used by reducing the number of temporal points;\n",
    "        # while testing, \"reflect\" padding is used in x,y- direction, while\n",
    "        # circular padding is used in t-direction\n",
    "        self.phase = phase\n",
    "\n",
    "    def get_lambda_cnn(self, x):\n",
    "        # padding\n",
    "        # arbitrarily chosen, maybe better to choose it depending on the\n",
    "        # receptive field of the CNN or so;\n",
    "        # seems to be important in order not to create \"holes\" in the\n",
    "        # lambda_maps in t-direction\n",
    "        npad_xy = 4\n",
    "        npad_t = 8\n",
    "        pad = (npad_t, npad_t, npad_xy, npad_xy, npad_xy, npad_xy)\n",
    "\n",
    "        if self.phase == \"training\":\n",
    "            x = F.pad(x, pad, mode=\"reflect\")\n",
    "\n",
    "        elif self.phase == \"testing\":\n",
    "            pad_refl = (0, 0, npad_xy, npad_xy, npad_xy, npad_xy)\n",
    "            pad_circ = (npad_t, npad_t, 0, 0, 0, 0)\n",
    "\n",
    "            x = F.pad(x, pad_refl, mode=\"reflect\")\n",
    "            x = F.pad(x, pad_circ, mode=\"circular\")\n",
    "\n",
    "        # estimate parameter map\n",
    "        lambda_cnn = self.cnn(x) # NOTE: The cnn is actually the UNET block!!! (At least in this project)\n",
    "\n",
    "        # crop\n",
    "        neg_pad = tuple([-pad[k] for k in range(len(pad))])\n",
    "        lambda_cnn = F.pad(lambda_cnn, neg_pad)\n",
    "\n",
    "        # double spatial map and stack\n",
    "        lambda_cnn = torch.cat((lambda_cnn[:, 0, ...].unsqueeze(1), lambda_cnn), dim=1)\n",
    "\n",
    "        # constrain map to be striclty positive; further, bound it from below\n",
    "        if self.up_bound > 0:\n",
    "            # constrain map to be striclty positive; further, bound it from below\n",
    "            lambda_cnn = self.up_bound * self.op_norm_AHA * torch.sigmoid(lambda_cnn)\n",
    "        else:\n",
    "            lambda_cnn = 0.1 * self.op_norm_AHA * F.softplus(lambda_cnn)\n",
    "\n",
    "        return lambda_cnn\n",
    "\n",
    "    def forward(self, x, lambda_map=None):\n",
    "        # initial reconstruction\n",
    "        mb, _, Nx, Ny, Nt = x.shape\n",
    "        device = x.device\n",
    "\n",
    "        # starting values\n",
    "        xbar = x.clone()\n",
    "        x0 = x.clone()\n",
    "        xnoisy = x.clone()\n",
    "\n",
    "        # dual variable\n",
    "        p = x.clone()\n",
    "        q = torch.zeros(mb, 3, Nx, Ny, Nt, dtype=x.dtype).to(device)\n",
    "\n",
    "        print(\"BEFORE LOOP\")\n",
    "        print_details(q, \"q\")\n",
    "\n",
    "        # sigma, tau, theta\n",
    "        sigma = (1 / self.L) * torch.sigmoid(self.sigma)  # \\in (0,1/L)\n",
    "        tau = (1 / self.L) * torch.sigmoid(self.tau)  # \\in (0,1/L)\n",
    "        theta = torch.sigmoid(self.theta)  # \\in (0,1)\n",
    "\n",
    "        # distinguish between the different cases\n",
    "        if self.mode == \"lambda_xyt\":\n",
    "            lambda_reg = F.softplus(self.lambda_reg)  # \\in (0,\\infty)\n",
    "\n",
    "        elif self.mode == \"lambda_xy_t\":\n",
    "            # get xy- and t-lambda\n",
    "            lambda_reg_xy = torch.stack(2 * [self.lambda_reg[0]])\n",
    "            lambda_reg_t = self.lambda_reg[1].unsqueeze(0)\n",
    "\n",
    "            # conatentate xy -and t-lambda\n",
    "            lambda_reg = (\n",
    "                torch.cat([lambda_reg_xy, lambda_reg_t])\n",
    "                .unsqueeze(0)\n",
    "                .unsqueeze(-1)\n",
    "                .unsqueeze(-1)\n",
    "                .unsqueeze(-1)\n",
    "            )\n",
    "            lambda_reg = F.softplus(lambda_reg)\n",
    "\n",
    "        elif self.mode == \"lambda_cnn\":\n",
    "            if lambda_map is None:\n",
    "                # estimate lambda reg from the image\n",
    "                lambda_reg = self.get_lambda_cnn(x)\n",
    "            else:\n",
    "                lambda_reg = lambda_map\n",
    "\n",
    "        print_details(self.L, \"L\")\n",
    "        # Assert the L is sqrt(1 * 12)\n",
    "        assert torch.allclose(self.L, torch.sqrt(torch.tensor(1.0 + 12.0)))\n",
    "        print_details(sigma, \"sigma\")\n",
    "        # Assert sigma is 1/L * sigmoid(10.0)\n",
    "        assert torch.allclose(sigma, 1/self.L * torch.sigmoid(torch.tensor(10.0)))\n",
    "\n",
    "        # Algorithm 2 - Unrolled PDHG algorithm (page 18)\n",
    "        # TODO: In the paper, L is one of the inputs but not used anywhere in the pseudo code???\n",
    "        for kT in range(self.T):\n",
    "            print(f\"Step {kT+1}/{self.T}\")\n",
    "\n",
    "            # update p\n",
    "            p =  (p + sigma * (xbar - xnoisy) ) / (1. + sigma)\n",
    "\n",
    "            # update q\n",
    "            print_details(xbar, \"xbar\")\n",
    "            grad = self.GradOps.apply_G(xbar)\n",
    "            print_details(grad, \"grad\")\n",
    "            q = self.ClipAct(q + sigma * grad, lambda_reg)\n",
    "\n",
    "            x1 = x0 - tau * p - tau * self.GradOps.apply_GH(q)\n",
    "\n",
    "            if kT != self.T - 1:\n",
    "                # update xbar\n",
    "                xbar = x1 + theta * (x1 - x0)\n",
    "                x0 = x1\n",
    "            \n",
    "            print_details(x1, \"x1\")\n",
    "\n",
    "        return x1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primal Dual NN test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_primitive_dual_nn():\n",
    "    T = 2\n",
    "    mode = \"lambda_cnn\"\n",
    "    up_bound = 0\n",
    "    phase = \"training\"\n",
    "    cnn_block = None\n",
    "    primal_dual_nn = DynamicImagePrimalDualNN(T, cnn_block, mode, up_bound, phase)\n",
    "    print(primal_dual_nn)\n",
    "    print()\n",
    "\n",
    "    # x = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
    "    x = torch.tensor([[1, 1], [1, 1]], dtype=torch.float32)\n",
    "    # Add \"time\" dimension. Assume the order (height, width, time)\n",
    "    x = x.unsqueeze(-1)\n",
    "    # Add \"channel\" dimension. Assume the order (channel, height, width, time)\n",
    "    x = x.unsqueeze(0)\n",
    "    # Add \"batch\" dimension. Assume the order (batch, channel, height, width, time)\n",
    "    x = x.unsqueeze(0)\n",
    "    print_details(x, \"x\")\n",
    "\n",
    "    lambda_scalar = torch.tensor([0.05], dtype=torch.float32)\n",
    "\n",
    "    y = primal_dual_nn(x, lambda_scalar)\n",
    "    print_details(y, \"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DynamicImagePrimalDualNN(\n",
      "  (GradOps): GradOperators()\n",
      "  (ClipAct): ClipAct()\n",
      ")\n",
      "\n",
      "x:\n",
      "tensor([[[[[1.],\n",
      "           [1.]],\n",
      "\n",
      "          [[1.],\n",
      "           [1.]]]]])\n",
      "  shape: torch.Size([1, 1, 2, 2, 1])\n",
      "\n",
      "BEFORE LOOP\n",
      "q:\n",
      "tensor([[[[[0.],\n",
      "           [0.]],\n",
      "\n",
      "          [[0.],\n",
      "           [0.]]],\n",
      "\n",
      "\n",
      "         [[[0.],\n",
      "           [0.]],\n",
      "\n",
      "          [[0.],\n",
      "           [0.]]],\n",
      "\n",
      "\n",
      "         [[[0.],\n",
      "           [0.]],\n",
      "\n",
      "          [[0.],\n",
      "           [0.]]]]])\n",
      "  shape: torch.Size([1, 3, 2, 2, 1])\n",
      "\n",
      "L:\n",
      "tensor(3.6056)\n",
      "  shape: torch.Size([])\n",
      "\n",
      "sigma:\n",
      "tensor(0.2773, grad_fn=<MulBackward0>)\n",
      "  shape: torch.Size([])\n",
      "\n",
      "Step 1/2\n",
      "xbar:\n",
      "tensor([[[[[1.],\n",
      "           [1.]],\n",
      "\n",
      "          [[1.],\n",
      "           [1.]]]]])\n",
      "  shape: torch.Size([1, 1, 2, 2, 1])\n",
      "\n",
      "grad:\n",
      "tensor([[[[[[0.],\n",
      "            [0.]],\n",
      "\n",
      "           [[0.],\n",
      "            [0.]]],\n",
      "\n",
      "\n",
      "          [[[0.],\n",
      "            [0.]],\n",
      "\n",
      "           [[0.],\n",
      "            [0.]]],\n",
      "\n",
      "\n",
      "          [[[0.],\n",
      "            [0.]],\n",
      "\n",
      "           [[0.],\n",
      "            [0.]]]]]])\n",
      "  shape: torch.Size([1, 1, 3, 2, 2, 1])\n",
      "\n",
      "x1:\n",
      "tensor([[[[[0.7829],\n",
      "           [0.7829]],\n",
      "\n",
      "          [[0.7829],\n",
      "           [0.7829]]]]], grad_fn=<SubBackward0>)\n",
      "  shape: torch.Size([1, 1, 2, 2, 1])\n",
      "\n",
      "Step 2/2\n",
      "xbar:\n",
      "tensor([[[[[0.5658],\n",
      "           [0.5658]],\n",
      "\n",
      "          [[0.5658],\n",
      "           [0.5658]]]]], grad_fn=<AddBackward0>)\n",
      "  shape: torch.Size([1, 1, 2, 2, 1])\n",
      "\n",
      "grad:\n",
      "tensor([[[[[[0.],\n",
      "            [0.]],\n",
      "\n",
      "           [[0.],\n",
      "            [0.]]],\n",
      "\n",
      "\n",
      "          [[[0.],\n",
      "            [0.]],\n",
      "\n",
      "           [[0.],\n",
      "            [0.]]],\n",
      "\n",
      "\n",
      "          [[[0.],\n",
      "            [0.]],\n",
      "\n",
      "           [[0.],\n",
      "            [0.]]]]]], grad_fn=<ViewBackward0>)\n",
      "  shape: torch.Size([1, 1, 3, 2, 2, 1])\n",
      "\n",
      "x1:\n",
      "tensor([[[[[0.6390],\n",
      "           [0.6390]],\n",
      "\n",
      "          [[0.6390],\n",
      "           [0.6390]]]]], grad_fn=<SubBackward0>)\n",
      "  shape: torch.Size([1, 1, 2, 2, 1])\n",
      "\n",
      "y:\n",
      "tensor([[[[[0.6390],\n",
      "           [0.6390]],\n",
      "\n",
      "          [[0.6390],\n",
      "           [0.6390]]]]], grad_fn=<SubBackward0>)\n",
      "  shape: torch.Size([1, 1, 2, 2, 1])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_primitive_dual_nn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
