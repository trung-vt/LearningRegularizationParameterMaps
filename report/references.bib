@ARTICLE{ssim,
  author={Zhou Wang and Bovik, A.C. and Sheikh, H.R. and Simoncelli, E.P.},
  journal={IEEE Transactions on Image Processing}, 
  title={Image quality assessment: from error visibility to structural similarity}, 
  year={2004},
  volume={13},
  number={4},
  pages={600-612},
  keywords={Image quality;Humans;Transform coding;Visual system;Visual perception;Data mining;Layout;Quality assessment;Degradation;Indexes},
  doi={10.1109/TIP.2003.819861}}


@misc{RGB-to-greyscale-formula-ITU-R_BT601,
  author = {{International Telecommunication Union}},
  title = {{Recommendation ITU-R BT.601-7: Studio encoding parameters of digital television for standard 4:3 and wide screen 16:9 aspect ratios}},
  year = {2011},
  howpublished = {\url{https://www.itu.int/rec/R-REC-BT.601-7-201103-I/en}},
  note = {Accessed: 2024-06-27}
}

@InProceedings{recovering_piecewise_smooth_multichannel_images,
author="Bredies, Kristian",
editor="Bruhn, Andr{\'e}s
and Pock, Thomas
and Tai, Xue-Cheng",
title="Recovering Piecewise Smooth Multichannel Images by Minimization of Convex Functionals with Total Generalized Variation Penalty",
booktitle="Efficient Algorithms for Global Optimization Methods in Computer Vision",
year="2014",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="44--77",
abstract="We study and extend the recently introduced total generalized variation (TGV) functional for multichannel images. This functional has already been established to constitute a well-suited convex model for piecewise smooth scalar images. It comprises exactly the functions of bounded variation but is, unlike purely total-variation based functionals, also aware of higher-order smoothness. For the multichannel version which is developed in this paper, basic properties and existence of minimizers for associated variational problems regularized with second-order TGV is shown. Furthermore, we address the design of numerical solution methods for the minimization of functionals with TGV{\$}{\$}^2{\$}{\$}penalty and present, in particular, a class of primal-dual algorithms. Finally, the concrete realization for various image processing problems, such as image denoising, deblurring, zooming, dequantization and compressive imaging, are discussed and numerical experiments are presented.",
isbn="978-3-642-54774-4"
}



@article{tgv-bredies-2010,
author = {Bredies, Kristian and Kunisch, Karl and Pock, Thomas},
title = {Total Generalized Variation},
journal = {SIAM Journal on Imaging Sciences},
volume = {3},
number = {3},
pages = {492-526},
year = {2010},
doi = {10.1137/090769521},

URL = { 
    
        https://doi.org/10.1137/090769521
    
    

},
eprint = { 
    
        https://doi.org/10.1137/090769521
    
    

}
,
    abstract = { The novel concept of total generalized variation of a function u is introduced, and some of its essential properties are proved. Differently from the bounded variation seminorm, the new concept involves higher-order derivatives of u. Numerical examples illustrate the high quality of this functional as a regularization term for mathematical imaging problems. In particular this functional selectively regularizes on different regularity levels and, as a side effect, does not lead to a staircasing effect. }
}

@ARTICLE{726791,

  author={Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},

  journal={Proceedings of the IEEE}, 

  title={Gradient-based learning applied to document recognition}, 

  year={1998},

  volume={86},

  number={11},

  pages={2278-2324},

  keywords={Neural networks;Pattern recognition;Machine learning;Optical character recognition software;Character recognition;Feature extraction;Multi-layer neural network;Optical computing;Hidden Markov models;Principal component analysis},
    url={https://www.researchgate.net/publication/2985446_Gradient-Based_Learning_Applied_to_Document_Recognition},

  doi={10.1109/5.726791}
}

@article{sidky_2012,
  doi = {10.1088/0031-9155/57/10/3065},
  url = {https://dx.doi.org/10.1088/0031-9155/57/10/3065},
  year = {2012},
  month = {apr},
  publisher = {IOP Publishing},
  volume = {57},
  number = {10},
  pages = {3065},
  author = {Emil Y Sidky and Jakob H Jørgensen and Xiaochuan Pan},
  title = {Convex optimization problem prototyping for image reconstruction in computed tomography with the Chambolle–Pock algorithm},
  journal = {Physics in Medicine & Biology},
  abstract = {The primal–dual optimization algorithm developed in Chambolle and Pock (CP) (2011 J. Math. Imag. Vis. 40 1–26) is applied to various convex optimization problems of interest in computed tomography (CT) image reconstruction. This algorithm allows for rapid prototyping of optimization problems for the purpose of designing iterative image reconstruction algorithms for CT. The primal–dual algorithm is briefly summarized in this paper, and its potential for prototyping is demonstrated by explicitly deriving CP algorithm instances for many optimization problems relevant to CT. An example application modeling breast CT with low-intensity x-ray illumination is presented.}
}

@InProceedings{Adam_2024_WACV,
    author    = {Adam, Luk\'a\v{s} and \v{C}erm\'ak, Vojt\v{e}ch and Papafitsoros, Kostas and Picek, Lukas},
    title     = {SeaTurtleID2022: A Long-Span Dataset for Reliable Sea Turtle Re-Identification},
    booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
    month     = {January},
    year      = {2024},
    pages     = {7146-7156},
    url       = {https://www.kaggle.com/datasets/wildlifedatasets/seaturtleid2022},
}


@article{chambolle_pock_2011,
  author = {Chambolle, Antonin and Pock, Thomas},
  title = {A First-Order Primal-Dual Algorithm for Convex Problems with Applications to Imaging},
  year = {2011},
  issue_date = {May       2011},
  publisher = {Kluwer Academic Publishers},
  address = {USA},
  volume = {40},
  number = {1},
  issn = {0924-9907},
  url = {https://doi.org/10.1007/s10851-010-0251-1},
  doi = {10.1007/s10851-010-0251-1},
  abstract = {In this paper we study a first-order primal-dual algorithm for non-smooth convex optimization problems with known saddle-point structure. We prove convergence to a saddle-point with rate  O (1/  N ) in finite dimensions for the complete class of problems. We further show accelerations of the proposed algorithm to yield improved rates on problems with some degree of smoothness. In particular we show that we can achieve  O (1/  N  2) convergence on problems, where the primal or the dual objective is uniformly convex, and we can show linear convergence, i.e.  O (     N  ) for some   (0,1), on smooth problems. The wide applicability of the proposed algorithm is demonstrated on several imaging problems such as image denoising, image deconvolution, image inpainting, motion estimation and multi-label image segmentation.},
  journal = {J. Math. Imaging Vis.},
  month = {may},
  pages = {120–145},
  numpages = {26},
  keywords = {Convex optimization, Dual approaches, Image, Inverse problems, Reconstruction, Total variation}
}


@misc{dyn_img_pdhg_code,
  author={David Shote},
  title={PDHG Algorithm Implementation for Dynamic Image Denoising},
  year={2024},
  month={January},
  day={25},
  url={https://github.com/koflera/LearningRegularizationParameterMaps/blob/7537667e81adf3bdebbab8ebdc98fd631b586c03/networks/dyn_img_primal_dual_nn.py}
}

@misc{cnn_vis,
    author={Maucher},
    title={Animations of Convolution and Deconvolution},
    url={https://hannibunny.github.io/mlbook/neuralnetworks/convolutionDemos.html}
}

@misc{kofler2023learning,
      title={Learning Regularization Parameter-Maps for Variational Image Reconstruction using Deep Neural Networks and Algorithm Unrolling}, 
      author={Andreas Kofler and Fabian Altekrüger and Fatima Antarou Ba and Christoph Kolbitsch and Evangelos Papoutsellis and David Schote and Clemens Sirotenko and Felix Frederik Zimmermann and Kostas Papafitsoros},
      year={2023},
      eprint={2301.05888},
      archivePrefix={arXiv},
      primaryClass={math.OC},
        url = {https://github.com/koflera/LearningRegularizationParameterMaps}
}


@InProceedings{SIDD_2018_CVPR,
					author = {Abdelhamed, Abdelrahman and Lin, Stephen and Brown, Michael S.},
					title = {A High-Quality Denoising Dataset for Smartphone Cameras},
					booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
					month = {June},
					year = {2018},
                    url = {https://abdokamel.github.io/sidd/}
				}


@misc{ronneberger2015unet,
      title={U-Net: Convolutional Networks for Biomedical Image Segmentation}, 
      author={Olaf Ronneberger and Philipp Fischer and Thomas Brox},
      year={2015},
      eprint={1505.04597},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{colab,
    title={Google Colab Notebook - Image Denoising with U-Net and PDHG method},
    author={Thanh Trung Vu},
    year={2024},
    url={https://colab.research.google.com/drive/1gj9HsRt2yNq-YZjyHyb72qky_RJXBRIK?usp=sharing}
}


@misc{kaggle,
    title={Kaggle Notebook - Image Denoising with U-Net and PDHG method},
    author={Thanh Trung Vu},
    year={2024},
    url={https://www.kaggle.com/code/trungvt24/notebookecbef14db1}
}




@misc{taylor_former,
    url={https://arxiv.org/abs/2308.14036}

}

@misc{wandb,
title = {Experiment Tracking with Weights and Biases},
year = {2020},
note = {Software available from wandb.com},
url={https://www.wandb.com/},
author = {Biewald, Lukas},
}

@misc{sd_unet,
    title={SD-UNet: Stripping Down U-Net for Segmentation of Biomedical Images on Platforms with Low Computational Budgets},
    url={https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7167802/}
}

@misc{unet_pyimagesearch_guide,
    title={UNET Implementation Tutorial by Pyimagesearch - Clear},
    url={https://pyimagesearch.com/2022/02/21/u-net-image-segmentation-in-keras/}
}

@misc{unet_pytorch_github,
    title={UNET Pytorch Implementation Github},
    url={https://github.com/milesial/Pytorch-UNet}
}

@misc{thomas_pock_TV,
    url={https://www.youtube.com/watch?v=rwM6ObUWjnk}
}

@inproceedings{fast_approx_sparse_coding,
    author = {Gregor, Karol and LeCun, Yann},
    title = {Learning fast approximations of sparse coding},
    year = {2010},
    isbn = {9781605589077},
    publisher = {Omnipress},
    address = {Madison, WI, USA},
    abstract = {In Sparse Coding (SC), input vectors are reconstructed using a sparse linear combination of basis vectors. SC has become a popular method for extracting features from data. For a given input, SC minimizes a quadratic reconstruction error with an L1 penalty term on the code. The process is often too slow for applications such as real-time pattern recognition. We proposed two versions of a very fast algorithm that produces approximate estimates of the sparse code that can be used to compute good visual features, or to initialize exact iterative algorithms. The main idea is to train a non-linear, feed-forward predictor with a specific architecture and a fixed depth to produce the best possible approximation of the sparse code. A version of the method, which can be seen as a trainable version of Li and Osher's coordinate descent method, is shown to produce approximate solutions with 10 times less computation than Li and Os-her's for the same approximation error. Unlike previous proposals for sparse code predictors, the system allows a kind of approximate "explaining away" to take place during inference. The resulting predictor is differentiable and can be included into globally-trained recognition systems.},
    booktitle = {Proceedings of the 27th International Conference on International Conference on Machine Learning},
    pages = {399–406},
    numpages = {8},
    location = {Haifa, Israel},
    series = {ICML'10}
}

@ARTICLE{nn_inverse_problems,
  author={Lucas, Alice and Iliadis, Michael and Molina, Rafael and Katsaggelos, Aggelos K.},
  journal={IEEE Signal Processing Magazine}, 
  title={Using Deep Neural Networks for Inverse Problems in Imaging: Beyond Analytical Methods}, 
  year={2018},
  volume={35},
  number={1},
  pages={20-36},
  keywords={Inverse problems;Visual systems;Machine learning;Biological neural networks;Analytical models;Image reconstruction;Neural networks},
  doi={10.1109/MSP.2017.2760358}
}


@article{Guo_2019,
   title={Adaptive Transform Domain Image Super-Resolution via Orthogonally Regularized Deep Networks},
   volume={28},
   ISSN={1941-0042},
   url={http://dx.doi.org/10.1109/TIP.2019.2913500},
   DOI={10.1109/tip.2019.2913500},
   number={9},
   journal={IEEE Transactions on Image Processing},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Guo, Tiantong and Seyed Mousavi, Hojjat and Monga, Vishal},
   year={2019},
   month=sep, pages={4685–4700} }


@ARTICLE{algo_unrolling,
  author={Monga, Vishal and Li, Yuelong and Eldar, Yonina C.},
  journal={IEEE Signal Processing Magazine}, 
  title={Algorithm Unrolling: Interpretable, Efficient Deep Learning for Signal and Image Processing}, 
  year={2021},
  volume={38},
  number={2},
  pages={18-44},
  keywords={Training data;Systematics;Neural networks;Signal processing algorithms;Performance gain;Network architecture;Deep learning;Machine learning},
  doi={10.1109/MSP.2020.3016905}}


@misc{mot,
    url = {https://motchallenge.net/}
}

@misc{unet,
    author = {Olaf Ronneberger, Philipp Fischer, Thomas Brox},
    url = {https://doi.org/10.48550/arXiv.1505.04597}
}

@ARTICLE{Lecun_CNN,
  author={Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  journal={Proceedings of the IEEE}, 
  title={Gradient-based learning applied to document recognition}, 
  year={1998},
  volume={86},
  number={11},
  pages={2278-2324},
  keywords={Neural networks;Pattern recognition;Machine learning;Optical character recognition software;Character recognition;Feature extraction;Multi-layer neural network;Optical computing;Hidden Markov models;Principal component analysis},
  doi={10.1109/5.726791},
  url={https://ieeexplore.ieee.org/document/726791}
}



@article{papafitsoros_2015, 
    title={Novel higher order regularisation methods for image reconstruction},
    url={https://www.repository.cam.ac.uk/handle/1810/246692}, 
    DOI={10.17863/CAM.15981}, 
    publisher={Apollo - University of Cambridge Repository}, 
    author={Papafitsoros, Konstantinos}, 
    year={2015}, 
    keywords={Higher order total variation, Functions of bounded Hessian, Total generalised variation, Denoising, Deblurring, Inpainting, Staircasing effect, Split Bregman, Exact TGV solutions, Non-local Hessian, Characterisation of higher order Sobolev and BV spaces} 
}

@Inbook{Gilboa2018,
author="Gilboa, Guy",
title="Variational Methods in Image Processing",
bookTitle="Nonlinear Eigenproblems in Image Processing and Computer Vision",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="15--37",
abstract="A short review is given on the rationale for using cost functions and optimization methods for modeling image processing and computer vision problems. Classical examples of various costs and functionals are given, illustrating this highly effective algorithmic approach. We examine different mathematical models Sects. (2.1, 2.2 and 2.5), as well as image processing tasks Sects. (2.3, 2.4).",
isbn="978-3-319-75847-3",
doi="10.1007/978-3-319-75847-3_2",
url="https://doi.org/10.1007/978-3-319-75847-3_2"
}

@Inbook{var_methods_imaging,
    url={https://link.springer.com/book/10.1007/978-0-387-69277-7}
}

@misc{papafitsoros_2013,
    url={https://arxiv.org/pdf/1202.6341.pdf}
}

@misc{jpeg_decompress,
    url={https://link.springer.com/article/10.1007/s10851-005-6467-9}

}


@misc{image_recovery,
    url={https://link.springer.com/article/10.1007/s002110050258}
}

@misc{benning_et_al,
    url={https://link.springer.com/article/10.1007/s10915-012-9650-3}
}

@misc{benning_thesis,
    name={M. Benning},
    title={Singular regularization of inverse problems. Bregman distances
and applications to variational frameworks with singular regularization en-
ergies, Ph.D. thesis, University of M ̈unster}, 
    year={2011}
}



@misc{kostas_tv_unet,
    url={https://arxiv.org/pdf/2301.05888.pdf}
}


@misc{kaggle-diabetes,
  author = {{National Institute of Diabetes and Digestive and
Kidney Diseases}},
  title = {Diabetes Data Set},
  url = {https://www.kaggle.com/datasets/mathchi/diabetes-data-set/data},
  note = {Donor of database: Vincent Sigillito (vgs@aplcen.apl.jhu.edu). Date received: 9 May 1990. Accessed on January 24, 2024}
}

@misc{BenningPerra2023,
  author = {Martin Benning and Nicola Perra},
  title = {Lecture Notes},
  note = {Originally developed by Martin Benning. Adapted and modified by Nicola Perra},
  year = {2023},
  month = {September},
  day = {8},
}

@misc{F1score,
  title = {F1 Score},
  howpublished = {\url{https://en.wikipedia.org/wiki/F1_score}},
  note={Accessed on January 24, 2024}
}

@article{Domingos2012,
  author = {Pedro Domingos},
  title = {A Few Useful Things to Know About Machine Learning},
}

@misc{sklearn_svm,
  title={{Support Vector Machines — scikit-learn 1.4.0 documentation}},
  howpublished={\url{https://scikit-learn.org/stable/modules/svm.html}},
  note={Accessed on January 24, 2024}
}

@misc{sklearn-logisticregression,
  title = {{Logistic Regression — scikit-learn 1.4.0 documentation}},
  howpublished={\url{https://scikit-learn.org/stable/modules/linear_model.html}},
  note = {Accessed on January 24, 2024},
}

@misc{numpy-website,
  title = {{NumPy}},
  howpublished={\url{https://numpy.org/}},
  note = {Accessed on \today},
}


@article{RUDIN1992259,
title = {Nonlinear total variation based noise removal algorithms},
journal = {Physica D: Nonlinear Phenomena},
volume = {60},
number = {1},
pages = {259-268},
year = {1992},
issn = {0167-2789},
doi = {https://doi.org/10.1016/0167-2789(92)90242-F},
url = {https://www.sciencedirect.com/science/article/pii/016727899290242F},
author = {Leonid I. Rudin and Stanley Osher and Emad Fatemi},
abstract = {A constrained optimization type of numerical algorithm for removing noise from images is presented. The total variation of the image is minimized subject to constraints involving the statistics of the noise. The constraints are imposed using Lanrange multipliers. The solution is obtained using the gradient-projection method. This amounts to solving a time dependent partial differential equation on a manifold determined by the constraints. As t → ∞ the solution converges to a steady state which is the denoised image. The numerical algorithm is simple and relatively fast. The results appear to be state-of-the-art for very noisy images. The method is noninvasive, yielding sharp edges in the image. The technique could be interpreted as a first step of moving each level set of the image normal to itself with velocity equal to the curvature of the level set divided by the magnitude of the gradient of the image, and a second step which projects the image back onto the constraint set.}
}

@incollection{PyTorch,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
} 

@article{Sidky2012,
doi = {10.1088/0031-9155/57/10/3065},
url = {https://dx.doi.org/10.1088/0031-9155/57/10/3065},
year = {2012},
month = {apr},
publisher = {IOP Publishing},
volume = {57},
number = {10},
pages = {3065},
author = {Emil Y Sidky and Jakob H Jørgensen and Xiaochuan Pan},
title = {Convex optimization problem prototyping for image reconstruction in computed tomography with the Chambolle–Pock algorithm},
journal = {Physics in Medicine & Biology},
abstract = {The primal–dual optimization algorithm developed in Chambolle and Pock (CP) (2011 J. Math. Imag. Vis. 40 1–26) is applied to various convex optimization problems of interest in computed tomography (CT) image reconstruction. This algorithm allows for rapid prototyping of optimization problems for the purpose of designing iterative image reconstruction algorithms for CT. The primal–dual algorithm is briefly summarized in this paper, and its potential for prototyping is demonstrated by explicitly deriving CP algorithm instances for many optimization problems relevant to CT. An example application modeling breast CT with low-intensity x-ray illumination is presented.}
}

@misc{kermany2018large,
  author = {Daniel Kermany and Kang Zhang and Michael Goldbaum},
  title = {Large Dataset of Labeled Optical Coherence Tomography (OCT) and Chest X-Ray Images},
  year = {2018},
  publisher = {Mendeley Data},
  version = {V3},
  doi = {10.17632/rscbjbr9sj.3}
}