@misc{understand_unet,
    url={https://towardsdatascience.com/understanding-u-net-61276b10f360}

}

@ARTICLE{726791,

  author={Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},

  journal={Proceedings of the IEEE}, 

  title={Gradient-based learning applied to document recognition}, 

  year={1998},

  volume={86},

  number={11},

  pages={2278-2324},

  keywords={Neural networks;Pattern recognition;Machine learning;Optical character recognition software;Character recognition;Feature extraction;Multi-layer neural network;Optical computing;Hidden Markov models;Principal component analysis},
    url={https://www.researchgate.net/publication/2985446_Gradient-Based_Learning_Applied_to_Document_Recognition},

  doi={10.1109/5.726791}}

@misc{cnn_vis,
    author={Maucher},
    title={Animations of Convolution and Deconvolution},
    url={https://hannibunny.github.io/mlbook/neuralnetworks/convolutionDemos.html}
}

@misc{kofler2023learning,
      title={Learning Regularization Parameter-Maps for Variational Image Reconstruction using Deep Neural Networks and Algorithm Unrolling}, 
      author={Andreas Kofler and Fabian Altekrüger and Fatima Antarou Ba and Christoph Kolbitsch and Evangelos Papoutsellis and David Schote and Clemens Sirotenko and Felix Frederik Zimmermann and Kostas Papafitsoros},
      year={2023},
      eprint={2301.05888},
      archivePrefix={arXiv},
      primaryClass={math.OC},
        url = {https://github.com/koflera/LearningRegularizationParameterMaps}
}


@InProceedings{SIDD_2018_CVPR,
					author = {Abdelhamed, Abdelrahman and Lin, Stephen and Brown, Michael S.},
					title = {A High-Quality Denoising Dataset for Smartphone Cameras},
					booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
					month = {June},
					year = {2018},
                    url = {https://abdokamel.github.io/sidd/}
				}


@misc{ronneberger2015unet,
      title={U-Net: Convolutional Networks for Biomedical Image Segmentation}, 
      author={Olaf Ronneberger and Philipp Fischer and Thomas Brox},
      year={2015},
      eprint={1505.04597},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{colab,
    title={Google Colab Notebook - Image Denoising with U-Net and PDHG method},
    author={Thanh Trung Vu},
    year={2024},
    url={https://colab.research.google.com/drive/1gj9HsRt2yNq-YZjyHyb72qky_RJXBRIK?usp=sharing}
}


@misc{kaggle,
    title={Kaggle Notebook - Image Denoising with U-Net and PDHG method},
    author={Thanh Trung Vu},
    year={2024},
    url={https://www.kaggle.com/code/trungvt24/notebookecbef14db1}
}




@misc{taylor_former,
    url={https://arxiv.org/abs/2308.14036}

}

@misc{wandb,
title = {Experiment Tracking with Weights and Biases},
year = {2020},
note = {Software available from wandb.com},
url={https://www.wandb.com/},
author = {Biewald, Lukas},
}

@misc{sd_unet,
    title={SD-UNet: Stripping Down U-Net for Segmentation of Biomedical Images on Platforms with Low Computational Budgets},
    url={https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7167802/}
}

@misc{unet_pyimagesearch_guide,
    title={UNET Implementation Tutorial by Pyimagesearch - Clear},
    url={https://pyimagesearch.com/2022/02/21/u-net-image-segmentation-in-keras/}
}

@misc{unet_pytorch_github,
    title={UNET Pytorch Implementation Github},
    url={https://github.com/milesial/Pytorch-UNet}
}

@misc{thomas_pock_TV,
    url={https://www.youtube.com/watch?v=rwM6ObUWjnk}
}

@inproceedings{fast_approx_sparse_coding,
    author = {Gregor, Karol and LeCun, Yann},
    title = {Learning fast approximations of sparse coding},
    year = {2010},
    isbn = {9781605589077},
    publisher = {Omnipress},
    address = {Madison, WI, USA},
    abstract = {In Sparse Coding (SC), input vectors are reconstructed using a sparse linear combination of basis vectors. SC has become a popular method for extracting features from data. For a given input, SC minimizes a quadratic reconstruction error with an L1 penalty term on the code. The process is often too slow for applications such as real-time pattern recognition. We proposed two versions of a very fast algorithm that produces approximate estimates of the sparse code that can be used to compute good visual features, or to initialize exact iterative algorithms. The main idea is to train a non-linear, feed-forward predictor with a specific architecture and a fixed depth to produce the best possible approximation of the sparse code. A version of the method, which can be seen as a trainable version of Li and Osher's coordinate descent method, is shown to produce approximate solutions with 10 times less computation than Li and Os-her's for the same approximation error. Unlike previous proposals for sparse code predictors, the system allows a kind of approximate "explaining away" to take place during inference. The resulting predictor is differentiable and can be included into globally-trained recognition systems.},
    booktitle = {Proceedings of the 27th International Conference on International Conference on Machine Learning},
    pages = {399–406},
    numpages = {8},
    location = {Haifa, Israel},
    series = {ICML'10}
}

@ARTICLE{nn_inverse_problems,
  author={Lucas, Alice and Iliadis, Michael and Molina, Rafael and Katsaggelos, Aggelos K.},
  journal={IEEE Signal Processing Magazine}, 
  title={Using Deep Neural Networks for Inverse Problems in Imaging: Beyond Analytical Methods}, 
  year={2018},
  volume={35},
  number={1},
  pages={20-36},
  keywords={Inverse problems;Visual systems;Machine learning;Biological neural networks;Analytical models;Image reconstruction;Neural networks},
  doi={10.1109/MSP.2017.2760358}
}


@article{Guo_2019,
   title={Adaptive Transform Domain Image Super-Resolution via Orthogonally Regularized Deep Networks},
   volume={28},
   ISSN={1941-0042},
   url={http://dx.doi.org/10.1109/TIP.2019.2913500},
   DOI={10.1109/tip.2019.2913500},
   number={9},
   journal={IEEE Transactions on Image Processing},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Guo, Tiantong and Seyed Mousavi, Hojjat and Monga, Vishal},
   year={2019},
   month=sep, pages={4685–4700} }


@ARTICLE{algo_unrolling,
  author={Monga, Vishal and Li, Yuelong and Eldar, Yonina C.},
  journal={IEEE Signal Processing Magazine}, 
  title={Algorithm Unrolling: Interpretable, Efficient Deep Learning for Signal and Image Processing}, 
  year={2021},
  volume={38},
  number={2},
  pages={18-44},
  keywords={Training data;Systematics;Neural networks;Signal processing algorithms;Performance gain;Network architecture;Deep learning;Machine learning},
  doi={10.1109/MSP.2020.3016905}}


@misc{mot,
    url = {https://motchallenge.net/}
}

@misc{unet,
    author = {Olaf Ronneberger, Philipp Fischer, Thomas Brox},
    url = {https://doi.org/10.48550/arXiv.1505.04597}
}

@ARTICLE{Lecun_CNN,
  author={Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  journal={Proceedings of the IEEE}, 
  title={Gradient-based learning applied to document recognition}, 
  year={1998},
  volume={86},
  number={11},
  pages={2278-2324},
  keywords={Neural networks;Pattern recognition;Machine learning;Optical character recognition software;Character recognition;Feature extraction;Multi-layer neural network;Optical computing;Hidden Markov models;Principal component analysis},
  doi={10.1109/5.726791},
  url={https://ieeexplore.ieee.org/document/726791}
}



@article{papafitsoros_2015, 
    title={Novel higher order regularisation methods for image reconstruction},
    url={https://www.repository.cam.ac.uk/handle/1810/246692}, 
    DOI={10.17863/CAM.15981}, 
    publisher={Apollo - University of Cambridge Repository}, 
    author={Papafitsoros, Konstantinos}, 
    year={2015}, 
    keywords={Higher order total variation, Functions of bounded Hessian, Total generalised variation, Denoising, Deblurring, Inpainting, Staircasing effect, Split Bregman, Exact TGV solutions, Non-local Hessian, Characterisation of higher order Sobolev and BV spaces} 
}

@Inbook{Gilboa2018,
author="Gilboa, Guy",
title="Variational Methods in Image Processing",
bookTitle="Nonlinear Eigenproblems in Image Processing and Computer Vision",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="15--37",
abstract="A short review is given on the rationale for using cost functions and optimization methods for modeling image processing and computer vision problems. Classical examples of various costs and functionals are given, illustrating this highly effective algorithmic approach. We examine different mathematical models Sects. (2.1, 2.2 and 2.5), as well as image processing tasks Sects. (2.3, 2.4).",
isbn="978-3-319-75847-3",
doi="10.1007/978-3-319-75847-3_2",
url="https://doi.org/10.1007/978-3-319-75847-3_2"
}

@Inbook{var_methods_imaging,
    url={https://link.springer.com/book/10.1007/978-0-387-69277-7}
}

@misc{papafitsoros_2013,
    url={https://arxiv.org/pdf/1202.6341.pdf}
}

@misc{jpeg_decompress,
    url={https://link.springer.com/article/10.1007/s10851-005-6467-9}

}


@misc{image_recovery,
    url={https://link.springer.com/article/10.1007/s002110050258}
}

@misc{benning_et_al,
    url={https://link.springer.com/article/10.1007/s10915-012-9650-3}
}

@misc{benning_thesis,
    name={M. Benning},
    title={Singular regularization of inverse problems. Bregman distances
and applications to variational frameworks with singular regularization en-
ergies, Ph.D. thesis, University of M ̈unster}, 
    year={2011}
}



@misc{kostas_tv_unet,
    url={https://arxiv.org/pdf/2301.05888.pdf}
}


@misc{kaggle-diabetes,
  author = {{National Institute of Diabetes and Digestive and
Kidney Diseases}},
  title = {Diabetes Data Set},
  url = {https://www.kaggle.com/datasets/mathchi/diabetes-data-set/data},
  note = {Donor of database: Vincent Sigillito (vgs@aplcen.apl.jhu.edu). Date received: 9 May 1990. Accessed on January 24, 2024}
}

@misc{BenningPerra2023,
  author = {Martin Benning and Nicola Perra},
  title = {Lecture Notes},
  note = {Originally developed by Martin Benning. Adapted and modified by Nicola Perra},
  year = {2023},
  month = {September},
  day = {8},
}

@misc{F1score,
  title = {F1 Score},
  howpublished = {\url{https://en.wikipedia.org/wiki/F1_score}},
  note={Accessed on January 24, 2024}
}

@article{Domingos2012,
  author = {Pedro Domingos},
  title = {A Few Useful Things to Know About Machine Learning},
}

@misc{sklearn_svm,
  title={{Support Vector Machines — scikit-learn 1.4.0 documentation}},
  howpublished={\url{https://scikit-learn.org/stable/modules/svm.html}},
  note={Accessed on January 24, 2024}
}

@misc{sklearn-logisticregression,
  title = {{Logistic Regression — scikit-learn 1.4.0 documentation}},
  howpublished={\url{https://scikit-learn.org/stable/modules/linear_model.html}},
  note = {Accessed on January 24, 2024},
}

@misc{numpy-website,
  title = {{NumPy}},
  howpublished={\url{https://numpy.org/}},
  note = {Accessed on \today},
}


