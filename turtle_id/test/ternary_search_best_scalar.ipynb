{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PDHG()\n",
    "\n",
    "img_np = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Function to suppress stdout and stderr\n",
    "class SuppressOutput:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        self._original_stderr = sys.stderr\n",
    "        self._original_stdout_fd = sys.stdout.fileno()\n",
    "        self._original_stderr_fd = sys.stderr.fileno()\n",
    "\n",
    "        self._null_fd = os.open(os.devnull, os.O_RDWR)\n",
    "        os.dup2(self._null_fd, self._original_stdout_fd)\n",
    "        os.dup2(self._null_fd, self._original_stderr_fd)\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        os.dup2(self._original_stdout_fd, self._original_stdout_fd)\n",
    "        os.dup2(self._original_stderr_fd, self._original_stderr_fd)\n",
    "        os.close(self._null_fd)\n",
    "        sys.stdout = self._original_stdout\n",
    "        sys.stderr = self._original_stderr\n",
    "\n",
    "\n",
    "# import io\n",
    "# import contextlib\n",
    "# import sys\n",
    "\n",
    "# class DummyFile(io.StringIO):\n",
    "#     def write(self, *args, **kwargs):\n",
    "#         pass\n",
    "\n",
    "# @contextlib.contextmanager\n",
    "# def suppress_output():\n",
    "#     save_stdout = sys.stdout\n",
    "#     save_stderr = sys.stderr\n",
    "#     sys.stdout = DummyFile()\n",
    "#     sys.stderr = DummyFile()\n",
    "#     try:\n",
    "#         yield\n",
    "#     finally:\n",
    "#         sys.stdout = save_stdout\n",
    "#         sys.stderr = save_stderr\n",
    "\n",
    "# import img2pdf\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "\n",
    "import logging\n",
    "\n",
    "# Suppress img2pdf DEBUG logs\n",
    "logging.getLogger(\"img2pdf\").propagate = False\n",
    "# logging.getLogger(\"img2pdf\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"img2pdf\").setLevel(logging.ERROR)\n",
    "\n",
    "logging.getLogger(\"multiprocessing\").propagate = False\n",
    "# logging.getLogger(\"multiprocessing\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"multiprocessing\").setLevel(logging.ERROR)\n",
    "\n",
    "from data.transform import convert_to_tensor_4D, convert_to_PIL\n",
    "from networks.pdhg import PDHG\n",
    "\n",
    "class ResultGenerator:\n",
    "    def __init__(self, min_lambda, max_lambda, num_lambdas, cmp_func, saving_denoised:bool, in_path:str, out_path:str, file_paths:dict, returning_denoised_PILs:bool=False):\n",
    "        self.model = PDHG()\n",
    "        self.lambdas = np.linspace(min_lambda, max_lambda, num_lambdas)\n",
    "        \n",
    "        self.cmp_func = cmp_func\n",
    "        self.saving_denoised = saving_denoised\n",
    "        \n",
    "        self.out_path = out_path\n",
    "        \n",
    "        self.returning_denoised_PILs = returning_denoised_PILs\n",
    "        \n",
    "        sigmas = list(file_paths.keys())[1:]\n",
    "        original_file_paths = file_paths[0]\n",
    "        self.sample_collection = []\n",
    "        \n",
    "        for sigma in sigmas:\n",
    "            noisy_file_paths = file_paths[sigma]\n",
    "            assert len(noisy_file_paths) == len(original_file_paths), f\"len(noisy_file_paths) != len(original_file_paths)\\nlen(noisy_file_paths): {len(noisy_file_paths)}, len(original_file_paths): {len(original_file_paths)}\"\n",
    "            for i in tqdm(range(len(noisy_file_paths))):\n",
    "                noisy_file_path = noisy_file_paths[i]\n",
    "                clean_file_path = original_file_paths[i % len(original_file_paths)]\n",
    "                noisy_4d = convert_to_tensor_4D(np.array(Image.open(in_path + \"/\" + noisy_file_path)))\n",
    "                clean_4d = convert_to_tensor_4D(np.array(Image.open(in_path + \"/\" + clean_file_path)))\n",
    "                self.sample_collection.append((noisy_4d, clean_4d, noisy_file_path))\n",
    "                \n",
    "        self.lambda_col = \"lambda\"\n",
    "            \n",
    "    def get_denoised_folder(self, noisy_path):\n",
    "        extension = noisy_path.split(\".\")[-1]\n",
    "        denoised_folder = self.out_path + \"/\" + noisy_path.replace(f\".{extension}\", \"\")\n",
    "        if self.saving_denoised:\n",
    "            os.makedirs(denoised_folder, exist_ok=True)\n",
    "        return denoised_folder, extension\n",
    "        \n",
    "    def get_denoised_filename(self, denoised_folder, _lambda):\n",
    "        _lambda = float(_lambda)\n",
    "        # Change to string with exactly 3 decimal places and replace '.' with '_'\n",
    "        _lambda = f\"{_lambda:.3f}\".replace('.', '_')\n",
    "        denoised_filename = f\"{denoised_folder}/lambda_{_lambda}\"\n",
    "        return denoised_filename\n",
    "\n",
    "\n",
    "    def get_denoised_PIL(self, noisy_4d, clean_4d, denoised_folder, extension, _lambda):\n",
    "        denoised_filename = self.get_denoised_filename(denoised_folder, _lambda)\n",
    "        results_file = f\"{denoised_filename}.csv\"\n",
    "        \n",
    "        if os.path.exists(results_file) and not self.returning_denoised_PILs:\n",
    "            cmp_results = pd.read_csv(results_file)\n",
    "            return None, cmp_results\n",
    "\n",
    "        denoised_file = f\"{denoised_filename}.{extension}\"\n",
    "        denoised_PIL = None        \n",
    "        \n",
    "        if os.path.exists(denoised_file):\n",
    "            denoised_PIL:Image = Image.open(denoised_file)\n",
    "            denoised_4d:torch.tensor = convert_to_tensor_4D(denoised_PIL)\n",
    "        else:\n",
    "            denoised_5d:torch.tensor = self.model(noisy_4d.unsqueeze(0), _lambda)\n",
    "            assert len(denoised_5d.shape) == 5, f\"Model output has unexpected shape {denoised_5d.shape}. Expected 5D tensor.\"\n",
    "            denoised_4d:torch.tensor = denoised_5d.squeeze(0).cpu()\n",
    "            \n",
    "            if self.saving_denoised:\n",
    "                if not os.path.exists(denoised_file):\n",
    "                    denoised_PIL:Image = convert_to_PIL(denoised_4d)\n",
    "                    denoised_PIL.save(denoised_file)\n",
    "            \n",
    "            del denoised_5d # Explicitly free up memory\n",
    "\n",
    "        if os.path.exists(results_file) and not self.returning_denoised_PILs:\n",
    "            cmp_results = pd.read_csv(results_file)\n",
    "        else:\n",
    "            cmp_results = self.cmp_func(denoised_4d, clean_4d)\n",
    "            cmp_results[self.lambda_col] = [_lambda]\n",
    "            cmp_results.to_csv(results_file, index=False) # Remove index column  \n",
    "\n",
    "                \n",
    "            # # Optional: Save as PDF\n",
    "            # denoised_pdf = f\"{denoised_filename}.pdf\"\n",
    "            # if not os.path.exists(denoised_pdf):\n",
    "            #     # with suppress_output():\n",
    "            #     with SuppressOutput():\n",
    "            #         pdf_bytes = img2pdf.convert(denoised_file)\n",
    "            #         with open(denoised_pdf, \"wb\") as f:\n",
    "            #             f.write(pdf_bytes)\n",
    "\n",
    "        del denoised_4d # Explicitly free up memory\n",
    "        if not self.returning_denoised_PILs:\n",
    "            denoised_PIL = None\n",
    "        return denoised_PIL, cmp_results\n",
    "            \n",
    "        \n",
    "    def brute_force_scalar_reg(self, sample):\n",
    "        noisy_4d, clean_4d, noisy_path = sample\n",
    "        assert noisy_4d.shape == clean_4d.shape, f\"Noisy and clean images have different sizes!\\nnoisy.shape: {noisy_4d.shape}, clean.shape: {clean_4d.shape}\"\n",
    "\n",
    "        df = pd.DataFrame(columns=[self.lambda_col, \"MSE\", \"PSNR\", \"SSIM\"])\n",
    "        \n",
    "        denoised_PILs = []\n",
    "        denoised_folder, extension = self.get_denoised_folder(noisy_path)\n",
    "        extension = \"PNG\" # lossless format\n",
    "        \n",
    "        L = 0.0\n",
    "        R = 1.0\n",
    "        best_results = pd.DataFrame(columns=[self.lambda_col, \"MSE\", \"PSNR\", \"SSIM\"])\n",
    "        best_results.PSNR = 0\n",
    "        best_lambda = None\n",
    "        # 0.5, 0.25, 0.125, 0.0625, 0.03125, \n",
    "        # 0.015625, 0.0078125, 0.00390625, 0.001953125, 0.0009765625\n",
    "        for i in range(5):\n",
    "            _lambda = (L + R) / 2\n",
    "        \n",
    "        # for _lambda in self.lambdas:\n",
    "            denoised_PIL, cmp_results = self.get_denoised_PIL(noisy_4d, clean_4d, denoised_folder, extension, _lambda)\n",
    "            # if self.returning_denoised_PILs:\n",
    "            #     denoised_PILs.append(denoised_PIL)\n",
    "            \n",
    "            # df = pd.concat([df, cmp_results], ignore_index=True)\n",
    "            if cmp_results.PSNR > best_results.PSNR:\n",
    "                best_results = cmp_results\n",
    "                best_lambda = _lambda\n",
    "        \n",
    "        # df.to_csv(f\"{denoised_folder}/results.csv\", index=False) # Remove index column, only 4 columns are kept: lambda, MSE, PSNR, SSIM\n",
    "        del noisy_4d, clean_4d # Explicitly free up memory\n",
    "        # return df, denoised_PILs\n",
    "        \n",
    "        return best_lambda, best_PSNR\n",
    "        \n",
    "        \n",
    "    def process_samples(self, num_threads:int=1):\n",
    "        # # Don't use too many threads, the computation is also done on the GPU which doesn't have a lot of memory?\n",
    "        # # https://stackoverflow.com/questions/2846653/how-do-i-use-threading-in-python\n",
    "        # pool = ThreadPool(num_threads)\n",
    "        # print(f\"Multiprocessing {len(self.sample_collection)} samples in {num_threads} threads\")\n",
    "        # results = pool.map(self.brute_force_scalar_reg, self.sample_collection)\n",
    "        \n",
    "        results = []\n",
    "        for i in tqdm(range(len(self.sample_collection))):\n",
    "            sample = self.sample_collection[i]\n",
    "            result = self.brute_force_scalar_reg(sample)\n",
    "            results.append(result)\n",
    "        \n",
    "        return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_generator = ResultGenerator(\n",
    "    min_lambda=0.0,\n",
    "    max_lambda=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ternary_search(arr, target, left, right):\n",
    "    if right >= left:\n",
    "        mid_1 = left + (right - left) // 3\n",
    "        mid_2 = right - (right - left) // 3\n",
    "\n",
    "        if arr[mid_1] == target:\n",
    "            return mid_1\n",
    "        if arr[mid_2] == target:\n",
    "            return mid_2\n",
    "\n",
    "        if target < arr[mid_1]:\n",
    "            return ternary_search(arr, target, left, mid_1 - 1)\n",
    "        elif target > arr[mid_2]:\n",
    "            return ternary_search(arr, target, mid_2 + 1, right)\n",
    "        else:\n",
    "            return ternary_search(arr, target, mid_1 + 1, mid_2 - 1)\n",
    "\n",
    "    return -1"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
