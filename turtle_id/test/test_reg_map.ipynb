{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import img2pdf\n",
    "\n",
    "print(\"Importing torch ...\")\n",
    "begin = time.time()\n",
    "import torch\n",
    "print(\"Imported torch in {:.2f} seconds\".format(time.time() - begin))\n",
    "\n",
    "print(\"Importing torchvision ...\")\n",
    "begin = time.time()\n",
    "from torchvision import transforms\n",
    "print(\"Imported torchvision in {:.2f} seconds\".format(time.time() - begin))\n",
    "\n",
    "# from networks.static_img_primal_dual_nn import StaticImgPrimalDualNN\n",
    "from metrics import metrics\n",
    "from data.turtle_data_loading import get_file_paths, TurtleDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_device = \"cuda\"\n",
    "torch.set_default_device(default_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle_id_test_config import data_path, upper_level\n",
    "\n",
    "from turtle_id_test_config import test_reg_map_path, test_scalar_reg_path\n",
    "\n",
    "model_path=f\"{upper_level}/models/model-turtle_id_2022-2024_06_21_14_31_50/model_epoch_30.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100 # 0 for all\n",
    "size = 256\n",
    "sigmas = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths:dict = get_file_paths(data_path, \"test\", num_samples, sigmas, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_paths is a dict with keys the sigmas and values the list of file paths\n",
    "# Check that every list has the same length\n",
    "for key in file_paths.keys():\n",
    "    assert len(file_paths[key]) == num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TurtleDataset(data_path, file_paths, default_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(test_dataset) == num_samples * len(sigmas), f\"len(test_dataset)={len(test_dataset)} != {num_samples} * {len(sigmas)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(model_path)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_npy(tensor, path):\n",
    "    np.save(path, tensor.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_reg_map(file, i):\n",
    "    result_path = f\"{test_reg_map_path}/{file}\"\n",
    "    \n",
    "    # if os.path.exists(result_path):\n",
    "    #     # print(f\"Path {result_path} already exists. Skipping ...\")\n",
    "    #     return\n",
    "    \n",
    "    os.makedirs(result_path, exist_ok=True)\n",
    "    noisy_4d, clean_4d = test_dataset[i]\n",
    "    noisy_5d = noisy_4d.unsqueeze(0)\n",
    "    clean_5d = clean_4d.unsqueeze(0)\n",
    "    reg_map = model.cnn(noisy_5d)\n",
    "    # # reg_map = model.cnn(noisy_4d)\n",
    "    # print(f\"Shape of noisy image: {noisy_5d.shape}\")\n",
    "    # denoised_5d = model(noisy_5d, reg_map)\n",
    "    # # denoised_5d = model(noisy_4d, reg_map)\n",
    "    \n",
    "    denoised_5d = model(noisy_5d)\n",
    "    denoised_4d = denoised_5d.squeeze(0)\n",
    "    \n",
    "    mse, psnr, ssim = metrics.compare(clean_4d, denoised_4d)\n",
    "    with open(f\"{result_path}/metrics.csv\", \"w\") as f:\n",
    "        f.write(f\"MSE,PSNR,SSIM\\n{mse},{psnr},{ssim}\")\n",
    "    # print(f\"MSE: {mse}, PSNR: {psnr}, SSIM: {ssim}\")\n",
    "    \n",
    "    reg_map_path = f\"{result_path}/reg_map.npy\"\n",
    "    save_npy(reg_map, reg_map_path)\n",
    "    denoised_path = f\"{result_path}/denoised.npy\"\n",
    "    save_npy(denoised_5d, denoised_path)\n",
    "    denoised_PIL = transforms.ToPILImage()(denoised_5d.squeeze(-1).squeeze(0).squeeze(0).detach().cpu())\n",
    "    denoised_PIL.save(f\"{result_path}/denoised.png\")\n",
    "    \n",
    "    noisy_PIL = transforms.ToPILImage()(noisy_5d.squeeze(-1).squeeze(0).squeeze(0).detach().cpu())\n",
    "    noisy_PIL.save(f\"{result_path}/noisy.png\")\n",
    "    \n",
    "    clean_PIL = transforms.ToPILImage()(clean_5d.squeeze(-1).squeeze(0).squeeze(0).detach().cpu())\n",
    "    clean_PIL.save(f\"{result_path}/clean.png\")\n",
    "    \n",
    "    denoised_pdf = f\"{result_path}/denoised.pdf\"\n",
    "    with open(denoised_pdf, \"wb\") as f:\n",
    "        f.write(img2pdf.convert(f\"{result_path}/denoised.png\"))\n",
    "        \n",
    "    noisy_pdf = f\"{result_path}/noisy.pdf\"\n",
    "    with open(noisy_pdf, \"wb\") as f:\n",
    "        f.write(img2pdf.convert(f\"{result_path}/noisy.png\"))\n",
    "        \n",
    "    clean_pdf = f\"{result_path}/clean.pdf\"\n",
    "    with open(clean_pdf, \"wb\") as f:\n",
    "        f.write(img2pdf.convert(f\"{result_path}/clean.png\"))\n",
    "    \n",
    "    # plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # plt.subplot(1, 3, 1)\n",
    "    # plt.imshow(noisy_PIL, cmap=\"gray\")\n",
    "    \n",
    "    # plt.subplot(1, 3, 2)\n",
    "    # plt.imshow(denoised_PIL, cmap=\"gray\")\n",
    "    \n",
    "    # plt.subplot(1, 3, 3)\n",
    "    # plt.imshow(clean_PIL, cmap=\"gray\")\n",
    "    \n",
    "    # plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_scalar_reg(file):\n",
    "    scalar_reg_path = f\"{test_scalar_reg_path}/{file}\"\n",
    "    \n",
    "    results_csv = f\"{scalar_reg_path}/results.csv\"\n",
    "    \n",
    "    df_results = pd.read_csv(results_csv)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_reg_map():\n",
    "    for i in tqdm(range(len(test_dataset))):\n",
    "        \n",
    "        sample_id = i % num_samples\n",
    "        sigma = sigmas[i // num_samples]\n",
    "        file = file_paths[sigma][sample_id]\n",
    "        extension = file.split(\".\")[-1]\n",
    "        file = file.replace(f\".{extension}\", \"\")\n",
    "        \n",
    "        \n",
    "        infer_reg_map(file, i)\n",
    "        \n",
    "        # check_scalar_reg(file)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_reg_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_to_scalar_reg():\n",
    "    for i in tqdm(range(len(test_dataset))):\n",
    "        \n",
    "        sample_id = i % num_samples\n",
    "        sigma = sigmas[i // num_samples]\n",
    "        file = file_paths[sigma][sample_id]\n",
    "        extension = file.split(\".\")[-1]\n",
    "        file = file.replace(f\".{extension}\", \"\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
