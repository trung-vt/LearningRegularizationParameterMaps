{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new version 2 of turtle_data_generate.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 14:30:16,746 - DEBUG - Popen(['git', 'version'], cwd=/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/turtle_id, stdin=None, shell=False, universal_newlines=False)\n",
      "2024-06-21 14:30:16,748 - DEBUG - Popen(['git', 'version'], cwd=/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/turtle_id, stdin=None, shell=False, universal_newlines=False)\n",
      "2024-06-21 14:30:16,873 - DEBUG - Trying paths: ['/root/.docker/config.json', '/root/.dockercfg']\n",
      "2024-06-21 14:30:16,874 - DEBUG - No config file found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new version 2 of train.py\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from data.turtle_data_loading import get_datasets\n",
    "from scripts import train\n",
    "from scripts.train import start_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    turtle_data_path = \"../data/turtle_id_2022/turtles-data/data\"\n",
    "    \n",
    "    config = {\n",
    "        \"project\": \"turtle_id_2022\",\n",
    "        \"dataset\": turtle_data_path,\n",
    "        \"train_data_path\": f\"{turtle_data_path}/train.txt\",\n",
    "        \"val_data_path\": f\"{turtle_data_path}/val.txt\",\n",
    "        \"test_data_path\": f\"{turtle_data_path}/test.txt\",\n",
    "        \"train_num_samples\": 1000,\n",
    "        \"val_num_samples\": 100,\n",
    "        \"test_num_samples\": 100,\n",
    "        \"data_gen_num_threads\": 16,\n",
    "\n",
    "        \"resize_square\": 256,\n",
    "        \"sigmas\": \"[0.05, 0.1, 0.15, 0.2, 0.25, 0.3]\",\n",
    "        \"batch_size\": 1,\n",
    "        \"random_seed\": 42,\n",
    "\n",
    "        \"architecture\": \"UNET-PDHG\",\n",
    "        \"in_channels\": 1,\n",
    "        \"out_channels\": 2,\n",
    "        \"init_filters\": 32,\n",
    "        \"n_blocks\": 3,\n",
    "        \"activation\": \"LeakyReLU\",\n",
    "        \"downsampling_kernel\": (2, 2, 1),\n",
    "        \"downsampling_mode\": \"max_pool\",\n",
    "        \"upsampling_kernel\": (2, 2, 1),\n",
    "        \"upsampling_mode\": \"linear_interpolation\",\n",
    "\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"loss_function\": \"MSELoss\",\n",
    "\n",
    "        # \"up_bound\": 0.5,\n",
    "        \"up_bound\": 0,\n",
    "        # \"T\": 256, # Higher T, NET does not have to try as hard? Less overfitting?\n",
    "        \"T\": 128,\n",
    "\n",
    "        \"epochs\": 1000,\n",
    "        \"device\": \"cuda:0\",\n",
    "\n",
    "        \"wandb_mode\": \"online\",\n",
    "        \"save_epoch_wandb\": 10,\n",
    "        \"save_epoch_local\": 2,\n",
    "        \"save_dir\": \"tmp_2\",\n",
    "    }\n",
    "    \n",
    "    torch.set_default_device(config[\"device\"])\n",
    "    \n",
    "    # datasets = get_datasets(config, data_path=config[\"dataset\"], size=config[\"resize_square\"])\n",
    "    \n",
    "    start_training(\n",
    "        config=config,\n",
    "        get_datasets=get_datasets,\n",
    "        pretrained_model_path=None,\n",
    "        is_state_dict=False, \n",
    "        start_epoch=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 16 threads\n",
      "Using skimage.util.random_noise to add noise to images\n",
      "Multiprocessing 438 subfolders in 16 threads\n",
      "Processed 8729 images\n",
      "Loading images from images_crop_resize_256_greyscale_noisy_0_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [00:06, 81.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [00:06, 76.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [00:06, 76.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [00:06, 75.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [00:06, 76.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 75.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 75.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 78.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 76.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 75.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 80.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 85.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 82.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 85.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 76.78it/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find turtle_id_2022.\n",
      "2024-06-21 14:31:54,114 - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "2024-06-21 14:31:54,459 - DEBUG - https://api.wandb.ai:443 \"POST /graphql HTTP/11\" 200 None\n",
      "2024-06-21 14:31:54,693 - DEBUG - https://api.wandb.ai:443 \"POST /graphql HTTP/11\" 200 None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtrung-vuthanh24\u001b[0m (\u001b[33mwof\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "2024-06-21 14:31:54,782 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps, stdin=<valid stream>, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/turtle_id/wandb/run-20240621_143154-r0aw8i40</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wof/turtle_id_2022/runs/r0aw8i40' target=\"_blank\">confused-hill-13</a></strong> to <a href='https://wandb.ai/wof/turtle_id_2022' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wof/turtle_id_2022' target=\"_blank\">https://wandb.ai/wof/turtle_id_2022</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wof/turtle_id_2022/runs/r0aw8i40' target=\"_blank\">https://wandb.ai/wof/turtle_id_2022/runs/r0aw8i40</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1000 [39:44<330:16:07, 1191.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - VALIDATION LOSS: 0.0020440783732337876 - VALIDATION PSNR: 27.918588638305664 - VALIDATION SSIM: 0.7335967843461686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1000 [1:19:19<328:56:43, 1188.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - VALIDATION LOSS: 0.0019322163843899034 - VALIDATION PSNR: 28.189929962158203 - VALIDATION SSIM: 0.7544981821879453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/1000 [1:59:14<329:12:27, 1192.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - VALIDATION LOSS: 0.0018762206711689941 - VALIDATION PSNR: 28.333581924438477 - VALIDATION SSIM: 0.7643892122465815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1000 [2:38:39<327:07:37, 1187.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - VALIDATION LOSS: 0.0018489837782108224 - VALIDATION PSNR: 28.404985427856445 - VALIDATION SSIM: 0.7683610974758913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1000 [2:58:23<326:27:02, 1185.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - VALIDATION LOSS: 0.0018211240977980196 - VALIDATION PSNR: 28.486568450927734 - VALIDATION SSIM: 0.7695121669349715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 17:50:09,662 - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "2024-06-21 17:50:10,039 - DEBUG - https://api.wandb.ai:443 \"POST /graphql HTTP/11\" 200 None\n",
      "  1%|          | 12/1000 [3:57:27<324:11:41, 1181.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 - VALIDATION LOSS: 0.0018118879540124908 - VALIDATION PSNR: 28.501455307006836 - VALIDATION SSIM: 0.7720041855481732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 14/1000 [4:36:31<322:16:13, 1176.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 - VALIDATION LOSS: 0.0017952839573845266 - VALIDATION PSNR: 28.557003021240234 - VALIDATION SSIM: 0.7726623033328148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 16/1000 [5:15:39<321:14:43, 1175.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 - VALIDATION LOSS: 0.0017855813796049916 - VALIDATION PSNR: 28.579097747802734 - VALIDATION SSIM: 0.7735040602810365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 18/1000 [5:54:39<319:46:12, 1172.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 - VALIDATION LOSS: 0.0017775850167381577 - VALIDATION PSNR: 28.607131958007812 - VALIDATION SSIM: 0.7735222663773993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 19/1000 [6:14:07<319:05:49, 1171.00s/it]2024-06-21 21:05:41,697 - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 - VALIDATION LOSS: 0.0017786117244977505 - VALIDATION PSNR: 28.60462188720703 - VALIDATION SSIM: 0.7737732263766015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 21:05:42,043 - DEBUG - https://api.wandb.ai:443 \"POST /graphql HTTP/11\" 200 None\n",
      "  2%|▏         | 22/1000 [7:12:39<317:52:15, 1170.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 - VALIDATION LOSS: 0.0017711936490377412 - VALIDATION PSNR: 28.61444664001465 - VALIDATION SSIM: 0.775860961656603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 24/1000 [7:51:36<317:05:41, 1169.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 - VALIDATION LOSS: 0.001764713935146574 - VALIDATION PSNR: 28.640825271606445 - VALIDATION SSIM: 0.7754303034524264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1000 [8:30:39<316:38:29, 1170.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 - VALIDATION LOSS: 0.00177094060217496 - VALIDATION PSNR: 28.629344940185547 - VALIDATION SSIM: 0.774588865185192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 28/1000 [9:09:42<316:15:00, 1171.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 - VALIDATION LOSS: 0.0017686192205292172 - VALIDATION PSNR: 28.636402130126953 - VALIDATION SSIM: 0.7742175606581683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 29/1000 [9:29:16<316:10:07, 1172.20s/it]2024-06-22 00:20:43,174 - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 - VALIDATION LOSS: 0.001771825362171512 - VALIDATION PSNR: 28.62888526916504 - VALIDATION SSIM: 0.7754844560158554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-22 00:20:43,533 - DEBUG - https://api.wandb.ai:443 \"POST /graphql HTTP/11\" 200 None\n",
      "  3%|▎         | 32/1000 [10:27:51<315:05:17, 1171.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 - VALIDATION LOSS: 0.0017736635900218972 - VALIDATION PSNR: 28.625505447387695 - VALIDATION SSIM: 0.7739329597732032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 34/1000 [11:06:58<314:40:48, 1172.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 - VALIDATION LOSS: 0.001785165685461834 - VALIDATION PSNR: 28.605592727661133 - VALIDATION SSIM: 0.7729266319015153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 36/1000 [11:46:06<314:08:41, 1173.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 - VALIDATION LOSS: 0.0017875487401615828 - VALIDATION PSNR: 28.59086799621582 - VALIDATION SSIM: 0.7722514964963103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 37/1000 [12:19:15<320:40:34, 1198.79s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 54\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_default_device(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# datasets = get_datasets(config, data_path=config[\"dataset\"], size=config[\"resize_square\"])\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m \u001b[43mstart_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_datasets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_datasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m     60\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/scripts/train.py:200\u001b[0m, in \u001b[0;36mstart_training\u001b[0;34m(config, get_datasets, pretrained_model_path, is_state_dict, start_epoch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# Model training\u001b[39;00m\n\u001b[1;32m    199\u001b[0m pdhg\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 200\u001b[0m train_loss, train_psnr, train_ssim \u001b[38;5;241m=\u001b[39m \u001b[43mperform_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_loader_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpdhg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m# Optional: Use wandb to log training progress\u001b[39;00m\n\u001b[1;32m    204\u001b[0m wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_loss, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_PSNR\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_psnr, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_SSIM\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_ssim})\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/scripts/train.py:79\u001b[0m, in \u001b[0;36mperform_epoch\u001b[0;34m(data_loader, model, loss_func, optimizer, perform_iter)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# for sample in tqdm(data_loader): # tqdm helps show a nice progress bar\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[0;32m---> 79\u001b[0m     loss_value, psnr, ssim \u001b[38;5;241m=\u001b[39m \u001b[43mperform_iter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_value\n\u001b[1;32m     83\u001b[0m     running_psnr \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m psnr\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/scripts/train.py:45\u001b[0m, in \u001b[0;36mtrain_iter\u001b[0;34m(sample, model, loss_func, optimizer)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_iter\u001b[39m(sample, model, loss_func, optimizer):\n\u001b[1;32m     43\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Zero your gradients for every batch! TODO: Why?\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     loss, psnr, ssim \u001b[38;5;241m=\u001b[39m \u001b[43mcommon_iter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m!=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem():\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/scripts/train.py:20\u001b[0m, in \u001b[0;36mcommon_iter\u001b[0;34m(sample, model, loss_func, stage)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcommon_iter\u001b[39m(sample, model, loss_func, stage:\u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     19\u001b[0m     noisy_5d, clean_5d \u001b[38;5;241m=\u001b[39m sample\n\u001b[0;32m---> 20\u001b[0m     denoised_5d \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_5d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_func(denoised_5d, clean_5d)\n\u001b[1;32m     23\u001b[0m     denoised_2d \u001b[38;5;241m=\u001b[39m denoised_5d\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/venv_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/venv_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/networks/static_img_primal_dual_nn.py:136\u001b[0m, in \u001b[0;36mStaticImagePrimalDualNN.forward\u001b[0;34m(self, x, lambda_map)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# if lambda_reg_container is not None:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m#     assert type(lambda_reg_container) == list, f\"lambda_reg_container should be a list, not {type(lambda_reg_container)}\"\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m#     lambda_reg_container.append(lambda_reg) # For comparison\u001b[39;00m\n\u001b[1;32m    135\u001b[0m x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 136\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpdhg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m lambda_reg, x \u001b[38;5;66;03m# Explicitly free up (GPU) memory to be safe\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x1\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/venv_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/venv_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/networks/pdhg.py:106\u001b[0m, in \u001b[0;36mPDHG.forward\u001b[0;34m(self, x_5D, lambda_reg, T)\u001b[0m\n\u001b[1;32m    104\u001b[0m         x0 \u001b[38;5;241m=\u001b[39m x1\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 106\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Explicitly free up (GPU) memory to be safe\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m x_5D\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/venv_2/lib/python3.10/site-packages/torch/cuda/memory.py:162\u001b[0m, in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Release all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m`nvidia-smi`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 162\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
