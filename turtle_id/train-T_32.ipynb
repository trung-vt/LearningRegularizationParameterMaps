{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 01:22:54,429 - DEBUG - Popen(['git', 'version'], cwd=/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/turtle_id, stdin=None, shell=False, universal_newlines=False)\n",
      "2024-06-21 01:22:54,430 - DEBUG - Popen(['git', 'version'], cwd=/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/turtle_id, stdin=None, shell=False, universal_newlines=False)\n",
      "2024-06-21 01:22:54,510 - DEBUG - Trying paths: ['/root/.docker/config.json', '/root/.dockercfg']\n",
      "2024-06-21 01:22:54,511 - DEBUG - No config file found\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from data.turtle_data_loading import get_datasets\n",
    "from scripts.train import start_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    turtle_data_path = \"../data/turtle_id_2022/turtles-data/data\"\n",
    "    \n",
    "    config = {\n",
    "        \"project\": \"turtle_id_2022\",\n",
    "        \"dataset\": turtle_data_path,\n",
    "        \"train_data_path\": f\"{turtle_data_path}/train.txt\",\n",
    "        \"val_data_path\": f\"{turtle_data_path}/val.txt\",\n",
    "        \"test_data_path\": f\"{turtle_data_path}/test.txt\",\n",
    "        \"train_num_samples\": 100,\n",
    "        \"val_num_samples\": 10,\n",
    "        \"test_num_samples\": 10,\n",
    "        \"data_gen_num_threads\": 16,\n",
    "\n",
    "        \"resize_square\": 256,\n",
    "        \"sigmas\": \"[0.05, 0.1, 0.15, 0.2, 0.25, 0.3]\",\n",
    "        \"batch_size\": 1,\n",
    "        \"random_seed\": 42,\n",
    "\n",
    "        \"architecture\": \"UNET-PDHG\",\n",
    "        \"in_channels\": 1,\n",
    "        \"out_channels\": 2,\n",
    "        \"init_filters\": 32,\n",
    "        \"n_blocks\": 3,\n",
    "        \"activation\": \"LeakyReLU\",\n",
    "        \"downsampling_kernel\": (2, 2, 1),\n",
    "        \"downsampling_mode\": \"max_pool\",\n",
    "        \"upsampling_kernel\": (2, 2, 1),\n",
    "        \"upsampling_mode\": \"linear_interpolation\",\n",
    "\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"loss_function\": \"MSELoss\",\n",
    "\n",
    "        # \"up_bound\": 0.5,\n",
    "        \"up_bound\": 0,\n",
    "        # \"T\": 256, # Higher T, NET does not have to try as hard? Less overfitting?\n",
    "        \"T\": 32,\n",
    "        # \"T\": 16,\n",
    "\n",
    "        \"epochs\": 10_000,\n",
    "        \"device\": \"cuda:0\",\n",
    "\n",
    "        \"wandb_mode\": \"online\",\n",
    "        \"save_epoch_wandb\": 100,\n",
    "        \"save_epoch_local\": 10,\n",
    "        \"save_dir\": \"tmp_2\",\n",
    "    }\n",
    "    \n",
    "    torch.set_default_device(config[\"device\"])\n",
    "    \n",
    "    # datasets = get_datasets(config, data_path=config[\"dataset\"], size=config[\"resize_square\"])\n",
    "    \n",
    "    start_training(\n",
    "        config=config,\n",
    "        get_datasets=get_datasets,\n",
    "        pretrained_model_path=None,\n",
    "        is_state_dict=False, \n",
    "        start_epoch=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 16 threads\n",
      "Using skimage.util.random_noise to add noise to images\n",
      "Multiprocessing 438 subfolders in 16 threads\n",
      "Processed 8729 images\n",
      "Loading images from images_crop_resize_256_greyscale_noisy_0_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 110.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 114.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 110.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 111.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 108.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 106.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 108.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 104.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 107.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 106.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 137.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 142.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 133.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 131.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 137.42it/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find turtle_id_2022.\n",
      "2024-06-21 01:23:59,080 - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "2024-06-21 01:23:59,530 - DEBUG - https://api.wandb.ai:443 \"POST /graphql HTTP/11\" 200 None\n",
      "2024-06-21 01:24:00,233 - DEBUG - https://api.wandb.ai:443 \"POST /graphql HTTP/11\" 200 None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtrung-vuthanh24\u001b[0m (\u001b[33mwof\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "2024-06-21 01:24:00,316 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps, stdin=<valid stream>, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/turtle_id/wandb/run-20240621_012400-k2adxzlo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wof/turtle_id_2022/runs/k2adxzlo' target=\"_blank\">super-tree-10</a></strong> to <a href='https://wandb.ai/wof/turtle_id_2022' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wof/turtle_id_2022' target=\"_blank\">https://wandb.ai/wof/turtle_id_2022</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wof/turtle_id_2022/runs/k2adxzlo' target=\"_blank\">https://wandb.ai/wof/turtle_id_2022/runs/k2adxzlo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/10000 [11:10<185:41:09, 66.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - VALIDATION LOSS: 0.0018184709816705434 - VALIDATION PSNR: 28.492582321166992 - VALIDATION SSIM: 0.7292076847639417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 20/10000 [22:15<184:15:52, 66.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 - VALIDATION LOSS: 0.0017482295399531723 - VALIDATION PSNR: 28.72223663330078 - VALIDATION SSIM: 0.751300351004276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 30/10000 [33:16<183:24:13, 66.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 - VALIDATION LOSS: 0.001708752135746181 - VALIDATION PSNR: 28.80251121520996 - VALIDATION SSIM: 0.7566256114799352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 40/10000 [44:19<184:07:57, 66.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 - VALIDATION LOSS: 0.001695567240822129 - VALIDATION PSNR: 28.860536575317383 - VALIDATION SSIM: 0.7579975012782526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 50/10000 [55:26<184:18:20, 66.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 - VALIDATION LOSS: 0.0016989702306455 - VALIDATION PSNR: 28.842967987060547 - VALIDATION SSIM: 0.7592446847598738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 60/10000 [1:06:38<186:46:47, 67.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 - VALIDATION LOSS: 0.0017028874129755422 - VALIDATION PSNR: 28.83587074279785 - VALIDATION SSIM: 0.7573991328745069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 70/10000 [1:17:55<187:24:35, 67.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 - VALIDATION LOSS: 0.0017115565063431858 - VALIDATION PSNR: 28.817710876464844 - VALIDATION SSIM: 0.7558101742594505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 80/10000 [1:29:23<188:20:48, 68.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 - VALIDATION LOSS: 0.001721747845876962 - VALIDATION PSNR: 28.791221618652344 - VALIDATION SSIM: 0.7544017129658979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 90/10000 [1:40:50<190:04:32, 69.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 - VALIDATION LOSS: 0.0017342265846673399 - VALIDATION PSNR: 28.753604888916016 - VALIDATION SSIM: 0.7519485217655787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 90/10000 [1:41:11<185:41:40, 67.46s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 55\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_default_device(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# datasets = get_datasets(config, data_path=config[\"dataset\"], size=config[\"resize_square\"])\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m \u001b[43mstart_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_datasets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_datasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m     61\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/scripts/train.py:254\u001b[0m, in \u001b[0;36mstart_training\u001b[0;34m(config, get_datasets, pretrained_model_path, is_state_dict, start_epoch)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# Model training\u001b[39;00m\n\u001b[1;32m    253\u001b[0m pdhg\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 254\u001b[0m training_loss, training_psnr, training_ssim \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdhg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# training_loss, training_psnr, training_ssim = train_iteration(optimizer, pdhg, loss_function, sample=(noisy_image_data, clean_image_data))\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# print(f\"Epoch {epoch+1} - TRAINING LOSS: {training_loss} - TRAINING PSNR: {training_psnr} - TRAINING SSIM: {training_ssim}\")\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Optional: Use wandb to log training progress\u001b[39;00m\n\u001b[1;32m    259\u001b[0m wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: training_loss})\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/scripts/train.py:33\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, optimizer, loss_func)\u001b[0m\n\u001b[1;32m     30\u001b[0m noisy_image_5d, clean_image_5d \u001b[38;5;241m=\u001b[39m sample\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# print(f\"noisy_image_5d.size(): {noisy_image_5d.size()}\")\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# print(f\"clean_image_5d.size(): {clean_image_5d.size()}\")\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m denoised_image_5d \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_image_5d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# print(f\"denoised_image_5d.size(): {denoised_image_5d.size()}\")\u001b[39;00m\n\u001b[1;32m     35\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(denoised_image_5d, clean_image_5d)\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/venv_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/venv_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/networks/static_img_primal_dual_nn.py:136\u001b[0m, in \u001b[0;36mStaticImagePrimalDualNN.forward\u001b[0;34m(self, x, lambda_map)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# if lambda_reg_container is not None:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m#     assert type(lambda_reg_container) == list, f\"lambda_reg_container should be a list, not {type(lambda_reg_container)}\"\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m#     lambda_reg_container.append(lambda_reg) # For comparison\u001b[39;00m\n\u001b[1;32m    135\u001b[0m x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 136\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpdhg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m lambda_reg, x \u001b[38;5;66;03m# Explicitly free up (GPU) memory to be safe\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x1\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/venv_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/venv_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/networks/pdhg.py:99\u001b[0m, in \u001b[0;36mPDHG.forward\u001b[0;34m(self, x_5D, lambda_reg, T)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# update q\u001b[39;00m\n\u001b[1;32m     97\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mClipAct(q \u001b[38;5;241m+\u001b[39m sigma \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mGradOps\u001b[38;5;241m.\u001b[39mapply_G(xbar), lambda_reg)\n\u001b[0;32m---> 99\u001b[0m x1 \u001b[38;5;241m=\u001b[39m x0 \u001b[38;5;241m-\u001b[39m tau \u001b[38;5;241m*\u001b[39m p \u001b[38;5;241m-\u001b[39m tau \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGradOps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_GH\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kT \u001b[38;5;241m!=\u001b[39m T \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;66;03m# update xbar\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     xbar \u001b[38;5;241m=\u001b[39m x1 \u001b[38;5;241m+\u001b[39m theta \u001b[38;5;241m*\u001b[39m (x1 \u001b[38;5;241m-\u001b[39m x0)\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/networks/grad_ops.py:80\u001b[0m, in \u001b[0;36mGradOperators.apply_GH\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     78\u001b[0m xr \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim, \u001b[38;5;241m*\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim :])\n\u001b[1;32m     79\u001b[0m xp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pad(xr)\n\u001b[0;32m---> 80\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mis_complex():\n\u001b[1;32m     82\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m*\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[: \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m*\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim :])\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/venv_2/lib/python3.10/site-packages/torch/utils/_device.py:78\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
