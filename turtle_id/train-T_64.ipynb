{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 03:06:17,312 - DEBUG - Popen(['git', 'version'], cwd=/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/turtle_id, stdin=None, shell=False, universal_newlines=False)\n",
      "2024-06-21 03:06:17,314 - DEBUG - Popen(['git', 'version'], cwd=/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/turtle_id, stdin=None, shell=False, universal_newlines=False)\n",
      "2024-06-21 03:06:17,393 - DEBUG - Trying paths: ['/root/.docker/config.json', '/root/.dockercfg']\n",
      "2024-06-21 03:06:17,394 - DEBUG - No config file found\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from data.turtle_data_loading import get_datasets\n",
    "from scripts.train import start_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    turtle_data_path = \"../data/turtle_id_2022/turtles-data/data\"\n",
    "    \n",
    "    config = {\n",
    "        \"project\": \"turtle_id_2022\",\n",
    "        \"dataset\": turtle_data_path,\n",
    "        \"train_data_path\": f\"{turtle_data_path}/train.txt\",\n",
    "        \"val_data_path\": f\"{turtle_data_path}/val.txt\",\n",
    "        \"test_data_path\": f\"{turtle_data_path}/test.txt\",\n",
    "        \"train_num_samples\": 100,\n",
    "        \"val_num_samples\": 10,\n",
    "        \"test_num_samples\": 10,\n",
    "        \"data_gen_num_threads\": 16,\n",
    "\n",
    "        \"resize_square\": 256,\n",
    "        \"sigmas\": \"[0.05, 0.1, 0.15, 0.2, 0.25, 0.3]\",\n",
    "        \"batch_size\": 1,\n",
    "        \"random_seed\": 42,\n",
    "\n",
    "        \"architecture\": \"UNET-PDHG\",\n",
    "        \"in_channels\": 1,\n",
    "        \"out_channels\": 2,\n",
    "        \"init_filters\": 32,\n",
    "        \"n_blocks\": 3,\n",
    "        \"activation\": \"LeakyReLU\",\n",
    "        \"downsampling_kernel\": (2, 2, 1),\n",
    "        \"downsampling_mode\": \"max_pool\",\n",
    "        \"upsampling_kernel\": (2, 2, 1),\n",
    "        \"upsampling_mode\": \"linear_interpolation\",\n",
    "\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"loss_function\": \"MSELoss\",\n",
    "\n",
    "        # \"up_bound\": 0.5,\n",
    "        \"up_bound\": 0,\n",
    "        # \"T\": 256, # Higher T, NET does not have to try as hard? Less overfitting?\n",
    "        \"T\": 64,\n",
    "        # \"T\": 16,\n",
    "\n",
    "        \"epochs\": 10_000,\n",
    "        \"device\": \"cuda:0\",\n",
    "\n",
    "        \"wandb_mode\": \"online\",\n",
    "        \"save_epoch_wandb\": 100,\n",
    "        \"save_epoch_local\": 10,\n",
    "        \"save_dir\": \"tmp_2\",\n",
    "    }\n",
    "    \n",
    "    torch.set_default_device(config[\"device\"])\n",
    "    \n",
    "    # datasets = get_datasets(config, data_path=config[\"dataset\"], size=config[\"resize_square\"])\n",
    "    \n",
    "    start_training(\n",
    "        config=config,\n",
    "        get_datasets=get_datasets,\n",
    "        pretrained_model_path=None,\n",
    "        is_state_dict=False, \n",
    "        start_epoch=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 16 threads\n",
      "Using skimage.util.random_noise to add noise to images\n",
      "Multiprocessing 438 subfolders in 16 threads\n",
      "Processed 8729 images\n",
      "Loading images from images_crop_resize_256_greyscale_noisy_0_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 109.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 113.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 109.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 103.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 107.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 105.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 103.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 105.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 106.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 108.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 124.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 121.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 130.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 124.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from images_crop_resize_256_greyscale_noisy_0_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 101.25it/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find turtle_id_2022.\n",
      "2024-06-21 03:07:24,403 - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "2024-06-21 03:07:25,416 - DEBUG - https://api.wandb.ai:443 \"POST /graphql HTTP/11\" 200 None\n",
      "2024-06-21 03:07:25,641 - DEBUG - https://api.wandb.ai:443 \"POST /graphql HTTP/11\" 200 None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtrung-vuthanh24\u001b[0m (\u001b[33mwof\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "2024-06-21 03:07:25,716 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps, stdin=<valid stream>, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/turtle_id/wandb/run-20240621_030725-txjt6sy7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wof/turtle_id_2022/runs/txjt6sy7' target=\"_blank\">warm-sound-11</a></strong> to <a href='https://wandb.ai/wof/turtle_id_2022' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wof/turtle_id_2022' target=\"_blank\">https://wandb.ai/wof/turtle_id_2022</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wof/turtle_id_2022/runs/txjt6sy7' target=\"_blank\">https://wandb.ai/wof/turtle_id_2022/runs/txjt6sy7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/10000 [23:08<382:01:39, 137.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - VALIDATION LOSS: 0.0018488853558665142 - VALIDATION PSNR: 28.37339973449707 - VALIDATION SSIM: 0.71384956154389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 20/10000 [45:48<376:19:17, 135.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 - VALIDATION LOSS: 0.001774622891098261 - VALIDATION PSNR: 28.66484260559082 - VALIDATION SSIM: 0.7492838973667567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 30/10000 [1:08:44<380:41:50, 137.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 - VALIDATION LOSS: 0.001685265704873018 - VALIDATION PSNR: 28.889488220214844 - VALIDATION SSIM: 0.7599924945352836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 40/10000 [1:31:30<379:16:21, 137.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 - VALIDATION LOSS: 0.0016695717573747971 - VALIDATION PSNR: 28.944869995117188 - VALIDATION SSIM: 0.7613794928863089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 50/10000 [1:54:43<394:04:12, 142.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 - VALIDATION LOSS: 0.0016676117101451383 - VALIDATION PSNR: 28.952341079711914 - VALIDATION SSIM: 0.7633606648398906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 60/10000 [2:18:15<387:00:21, 140.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 - VALIDATION LOSS: 0.0016747977581690065 - VALIDATION PSNR: 28.943145751953125 - VALIDATION SSIM: 0.7619945786630192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 70/10000 [2:42:24<406:47:38, 147.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 - VALIDATION LOSS: 0.0016959940874949097 - VALIDATION PSNR: 28.888601303100586 - VALIDATION SSIM: 0.7588129835830033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 71/10000 [2:44:49<384:08:50, 139.28s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 55\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_default_device(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# datasets = get_datasets(config, data_path=config[\"dataset\"], size=config[\"resize_square\"])\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m \u001b[43mstart_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_datasets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_datasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m     61\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/scripts/train.py:254\u001b[0m, in \u001b[0;36mstart_training\u001b[0;34m(config, get_datasets, pretrained_model_path, is_state_dict, start_epoch)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/scripts/train.py:33\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, optimizer, loss_func)\u001b[0m\n\u001b[1;32m     30\u001b[0m wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_iter_SSIM\u001b[39m\u001b[38;5;124m\"\u001b[39m: ssim})\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Free up memory\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m denoised_5d \u001b[38;5;66;03m# Delete output of model\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m denoised_2d \u001b[38;5;66;03m# Delete auxiliary variable\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m clean_2d \u001b[38;5;66;03m# Delete auxiliary variable\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/venv_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/venv_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/networks/static_img_primal_dual_nn.py:136\u001b[0m, in \u001b[0;36mStaticImagePrimalDualNN.forward\u001b[0;34m(self, x, lambda_map)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# if lambda_reg_container is not None:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m#     assert type(lambda_reg_container) == list, f\"lambda_reg_container should be a list, not {type(lambda_reg_container)}\"\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m#     lambda_reg_container.append(lambda_reg) # For comparison\u001b[39;00m\n\u001b[1;32m    135\u001b[0m x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 136\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpdhg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m lambda_reg, x \u001b[38;5;66;03m# Explicitly free up (GPU) memory to be safe\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x1\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/venv_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/venv_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/networks/pdhg.py:106\u001b[0m, in \u001b[0;36mPDHG.forward\u001b[0;34m(self, x_5D, lambda_reg, T)\u001b[0m\n\u001b[1;32m    104\u001b[0m         x0 \u001b[38;5;241m=\u001b[39m x1\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 106\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Explicitly free up (GPU) memory to be safe\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m x_5D\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/venv_2/lib/python3.10/site-packages/torch/cuda/memory.py:162\u001b[0m, in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Release all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m`nvidia-smi`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 162\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
