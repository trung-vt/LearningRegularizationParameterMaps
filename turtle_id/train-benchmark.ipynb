{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import importlib\n",
    "import doctest\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestResults(failed=0, attempted=0)\n",
      "TestResults(failed=0, attempted=0)\n",
      "Using new version 2 of train.py\n",
      "TestResults(failed=0, attempted=0)\n"
     ]
    }
   ],
   "source": [
    "from data import turtle_data_loading\n",
    "importlib.reload(turtle_data_loading)\n",
    "turtle_data_loading_doctest_result = doctest.testmod(turtle_data_loading)\n",
    "print(turtle_data_loading_doctest_result)\n",
    "from data.turtle_data_loading import get_datasets\n",
    "\n",
    "from data import get_data_loaders\n",
    "importlib.reload(get_data_loaders)\n",
    "get_data_loaders_doctest_result = doctest.testmod(get_data_loaders)\n",
    "print(get_data_loaders_doctest_result)\n",
    "from data.get_data_loaders import get_data_loaders\n",
    "\n",
    "from scripts import train\n",
    "importlib.reload(train)\n",
    "from scripts.train import start_training\n",
    "\n",
    "from networks import unet_3d\n",
    "importlib.reload(unet_3d)\n",
    "unet_3d_doctest_result = doctest.testmod(unet_3d)\n",
    "print(unet_3d_doctest_result)\n",
    "from networks.unet_3d import UNet3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_benchmark_tv_model():\n",
    "    \n",
    "    turtle_data_path = \"../data/turtle_id_2022/turtles-data/data\"\n",
    "    now = datetime.now()\n",
    "    \n",
    "    # Prepare to save the model\n",
    "    save_dir = \"models\"\n",
    "    model_name = f\"benchmark-TV-{now}\".replace(\" \", \"_\").replace(\":\", \"-\")\n",
    "    model_states_dir = f\"{save_dir}/{model_name}\"\n",
    "\n",
    "    os.makedirs(model_states_dir, exist_ok=True)\n",
    "    \n",
    "    config = {\n",
    "        \"model_name\": model_name,\n",
    "        \"project\": \"benchmark\",\n",
    "        \"dataset\": turtle_data_path,\n",
    "        \"train_data_path\": f\"{turtle_data_path}/train.txt\",\n",
    "        \"val_data_path\": f\"{turtle_data_path}/val.txt\",\n",
    "        \"test_data_path\": f\"{turtle_data_path}/test.txt\",\n",
    "        \"train_num_samples\": 10,\n",
    "        \"val_num_samples\": 5,\n",
    "        \"test_num_samples\": 5,\n",
    "        \"data_gen_num_threads\": 16,\n",
    "\n",
    "        \"resize_square\": 512,\n",
    "        \"sigmas\": \"[0.05, 0.1, 0.15, 0.2, 0.25, 0.3]\",\n",
    "        \"batch_size\": 1,\n",
    "        \"random_seed\": 42,\n",
    "        \"n_dim_data\": 3,\n",
    "\n",
    "        \"architecture\": \"UNET-PDHG\",\n",
    "        \"regularisation\": \"TV\",\n",
    "        \"in_channels\": 1,\n",
    "        \"out_channels\": 2,\n",
    "        \"init_filters\": 128,\n",
    "        \"n_blocks\": 3,\n",
    "        \"activation\": \"LeakyReLU\",\n",
    "        \"downsampling_kernel\": (2, 2, 1),\n",
    "        \"downsampling_mode\": \"max_pool\",\n",
    "        \"upsampling_kernel\": (2, 2, 1),\n",
    "        \"upsampling_mode\": \"linear_interpolation\",\n",
    "\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"loss_function\": \"MSELoss\",\n",
    "\n",
    "        \"up_bound\": 0,\n",
    "        # \"scale_factor\": 1,\n",
    "        # \"constraint_activation\": \"sigmoid\", # \"softplus\" or \"sigmoid\"\n",
    "        # \"scale_factor\": 0.01,\n",
    "        # \"constraint_activation\": \"softplus\",\n",
    "        # \"T\": 256, # Higher T, NET does not have to try as hard? Less overfitting?\n",
    "        \"T\": 128,\n",
    "        # \"T\": 16,\n",
    "\n",
    "        \"epochs\": 10_000,\n",
    "        \"device\": \"cuda:0\",\n",
    "        \"start_epoch\": 0,\n",
    "        \"wandb_mode\": \"online\",\n",
    "        \"save_epoch_wandb\": 100,\n",
    "        \"save_epoch_local\": 10,\n",
    "        \"save_dir\": save_dir,\n",
    "        \"model_states_dir\": model_states_dir,\n",
    "        \"pretrained_model_path\": None,\n",
    "        \"is_state_dict\": False,\n",
    "    }\n",
    "    \n",
    "    device = config[\"device\"]\n",
    "    torch.set_default_device(device)\n",
    "    \n",
    "    if config[\"pretrained_model_path\"] is None or config[\"is_state_dict\"]:\n",
    "        # Define CNN block\n",
    "        if config[\"regularisation\"] == \"TV\":\n",
    "            from networks.static_img_primal_dual_nn import StaticImagePrimalDualNN\n",
    "            # Construct primal-dual operator with nn\n",
    "            pdhg_net = StaticImagePrimalDualNN(\n",
    "                cnn_block=None, \n",
    "                device=device,\n",
    "                up_bound=config[\"up_bound\"], \n",
    "                T=config[\"T\"],\n",
    "            ).to(device)\n",
    "            if config[\"is_state_dict\"]:\n",
    "                pdhg_net.load_state_dict(torch.load(f\"{model_states_dir}/{config['pretrained_model_path']}.pt\"), device=device)\n",
    "            else:\n",
    "                unet = UNet3d(\n",
    "                    in_channels=config[\"in_channels\"],\n",
    "                    out_channels=config[\"out_channels\"],\n",
    "                    init_filters=config[\"init_filters\"],\n",
    "                    n_blocks=config[\"n_blocks\"],\n",
    "                    activation=config[\"activation\"],\n",
    "                    downsampling_kernel=config[\"downsampling_kernel\"],\n",
    "                    downsampling_mode=config[\"downsampling_mode\"],\n",
    "                    upsampling_kernel=config[\"upsampling_kernel\"],\n",
    "                    upsampling_mode=config[\"upsampling_mode\"],\n",
    "                ).to(device)\n",
    "                pdhg_net.cnn = unet\n",
    "        else:\n",
    "            raise ValueError(f\"Regularisation {config['regularisation']} not implemented.\")\n",
    "\n",
    "    else:\n",
    "        pdhg_net = torch.load(f\"{config['model_states_dir']}/{config['pretrained_model_path']}.pt\").to(device)\n",
    "\n",
    "    pdhg_net.train(True)\n",
    "    \n",
    "    datasets = get_datasets(config, device=device)\n",
    "    \n",
    "    data_loader_train, data_loader_valid, data_loader_test = get_data_loaders(config, datasets)\n",
    "\n",
    "    del data_loader_test # Not used for now\n",
    "    \n",
    "    for noisy, clean in data_loader_train:\n",
    "        print(noisy.shape)\n",
    "        print(clean.shape)\n",
    "        pdhg_net\n",
    "        break\n",
    "    \n",
    "    start_training(\n",
    "        pdhg_net=pdhg_net,\n",
    "        data_loader_train=data_loader_train,\n",
    "        data_loader_valid=data_loader_valid,\n",
    "        config=config,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original image paths in images_crop_resize_512_greyscale "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 200684.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy image paths sigma=0.05 in images_crop_resize_512_greyscale_noisy_0_05 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 249660.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy image paths sigma=0.1 in images_crop_resize_512_greyscale_noisy_0_1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 215092.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy image paths sigma=0.15 in images_crop_resize_512_greyscale_noisy_0_15 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 211833.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy image paths sigma=0.2 in images_crop_resize_512_greyscale_noisy_0_2 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 208671.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy image paths sigma=0.25 in images_crop_resize_512_greyscale_noisy_0_25 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 249660.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy image paths sigma=0.3 in images_crop_resize_512_greyscale_noisy_0_3 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 248183.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original images "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 85.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy images sigma=0.05 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 100.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy images sigma=0.1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 101.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy images sigma=0.15 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 106.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy images sigma=0.2 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 77.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy images sigma=0.25 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 83.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy images sigma=0.3 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 87.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original image paths in images_crop_resize_512_greyscale "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 81920.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy image paths sigma=0.05 in images_crop_resize_512_greyscale_noisy_0_05 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 104857.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy image paths sigma=0.1 in images_crop_resize_512_greyscale_noisy_0_1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 109798.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy image paths sigma=0.15 in images_crop_resize_512_greyscale_noisy_0_15 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 106997.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy image paths sigma=0.2 in images_crop_resize_512_greyscale_noisy_0_2 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 99391.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy image paths sigma=0.25 in images_crop_resize_512_greyscale_noisy_0_25 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 107546.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy image paths sigma=0.3 in images_crop_resize_512_greyscale_noisy_0_3 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 108100.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original images "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 92.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy images sigma=0.05 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 94.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy images sigma=0.1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 90.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy images sigma=0.15 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 91.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy images sigma=0.2 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 92.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy images sigma=0.25 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 87.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy images sigma=0.3 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 88.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original image paths in images_crop_resize_512_greyscale "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 124091.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy image paths sigma=0.05 in images_crop_resize_512_greyscale_noisy_0_05 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 99864.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy image paths sigma=0.1 in images_crop_resize_512_greyscale_noisy_0_1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 131072.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy image paths sigma=0.15 in images_crop_resize_512_greyscale_noisy_0_15 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 105916.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy image paths sigma=0.2 in images_crop_resize_512_greyscale_noisy_0_2 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 101311.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy image paths sigma=0.25 in images_crop_resize_512_greyscale_noisy_0_25 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 108660.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy image paths sigma=0.3 in images_crop_resize_512_greyscale_noisy_0_3 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 107546.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original images "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 92.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy images sigma=0.05 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 93.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy images sigma=0.1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 89.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy images sigma=0.15 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 90.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy images sigma=0.2 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 106.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy images sigma=0.25 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 101.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy images sigma=0.3 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 101.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 512, 512, 1])\n",
      "torch.Size([1, 1, 512, 512, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find benchmark.\n",
      "2024-07-01 05:37:49,458 - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "2024-07-01 05:37:49,766 - DEBUG - https://api.wandb.ai:443 \"POST /graphql HTTP/11\" 200 None\n",
      "2024-07-01 05:37:49,991 - DEBUG - https://api.wandb.ai:443 \"POST /graphql HTTP/11\" 200 None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtrung-vuthanh24\u001b[0m (\u001b[33mwof\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "2024-07-01 05:37:50,074 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps, stdin=<valid stream>, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/turtle_id/wandb/run-20240701_053750-6xzs50pk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wof/benchmark/runs/6xzs50pk' target=\"_blank\">vague-microwave-1</a></strong> to <a href='https://wandb.ai/wof/benchmark' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wof/benchmark' target=\"_blank\">https://wandb.ai/wof/benchmark</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wof/benchmark/runs/6xzs50pk' target=\"_blank\">https://wandb.ai/wof/benchmark/runs/6xzs50pk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c99200899e6044cf8cb162c444c7eae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9625e90b1854391b910eedea1c47a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f9a2e891dd40cebfe8c8c576890749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7788104a1b249408557068c7795d56f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstart_benchmark_tv_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 117\u001b[0m, in \u001b[0;36mstart_benchmark_tv_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m     pdhg_net\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m \u001b[43mstart_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpdhg_net\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpdhg_net\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_loader_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_loader_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_loader_valid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_loader_valid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/scripts/train.py:168\u001b[0m, in \u001b[0;36mstart_training\u001b[0;34m(pdhg_net, data_loader_train, data_loader_valid, config)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Model training\u001b[39;00m\n\u001b[1;32m    167\u001b[0m pdhg_net\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 168\u001b[0m train_loss, train_psnr, train_ssim \u001b[38;5;241m=\u001b[39m \u001b[43mperform_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_loader_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpdhg_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# Optional: Use wandb to log training progress\u001b[39;00m\n\u001b[1;32m    172\u001b[0m wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_loss, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_PSNR\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_psnr, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_SSIM\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_ssim})\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/scripts/train.py:80\u001b[0m, in \u001b[0;36mperform_epoch\u001b[0;34m(data_loader, model, loss_func, optimizer, perform_iter)\u001b[0m\n\u001b[1;32m     77\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_loader)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m tqdm(data_loader, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m): \u001b[38;5;66;03m# tqdm helps show a nice progress bar\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# for sample in data_loader:\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     loss_value, psnr, ssim \u001b[38;5;241m=\u001b[39m \u001b[43mperform_iter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_value\n\u001b[1;32m     84\u001b[0m     running_psnr \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m psnr\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/scripts/train.py:46\u001b[0m, in \u001b[0;36mtrain_iter\u001b[0;34m(sample, model, loss_func, optimizer)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_iter\u001b[39m(sample, model, loss_func, optimizer):\n\u001b[1;32m     44\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Zero your gradients for every batch! TODO: Why?\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m     loss, psnr, ssim \u001b[38;5;241m=\u001b[39m \u001b[43mcommon_iter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m!=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem():\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/scripts/train.py:21\u001b[0m, in \u001b[0;36mcommon_iter\u001b[0;34m(sample, model, loss_func, stage)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcommon_iter\u001b[39m(sample, model, loss_func, stage:\u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     20\u001b[0m     noisy_5d, clean_5d \u001b[38;5;241m=\u001b[39m sample\n\u001b[0;32m---> 21\u001b[0m     denoised_5d \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_5d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_func(denoised_5d, clean_5d)\n\u001b[1;32m     24\u001b[0m     denoised_2d \u001b[38;5;241m=\u001b[39m denoised_5d\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/venv_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/venv_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/networks/static_img_primal_dual_nn.py:134\u001b[0m, in \u001b[0;36mStaticImagePrimalDualNN.forward\u001b[0;34m(self, x, lambda_map)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;28mself\u001b[39m, x, lambda_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \n\u001b[1;32m    130\u001b[0m         \u001b[38;5;66;03m# lambda_reg_container=None,\u001b[39;00m\n\u001b[1;32m    131\u001b[0m ):\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lambda_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;66;03m# estimate lambda reg from the image\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m         lambda_reg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_lambda_cnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m         lambda_reg \u001b[38;5;241m=\u001b[39m lambda_map\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/networks/static_img_primal_dual_nn.py:117\u001b[0m, in \u001b[0;36mStaticImagePrimalDualNN.get_lambda_cnn\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    113\u001b[0m t_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# t_out = 0.05\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# constrain map to be striclty positive; further, bound it from below\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_bound \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# constrain map to be striclty positive; further, bound it from below\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     lambda_cnn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_bound \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mop_norm_AHA \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(lambda_cnn)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/h/GIT/DISSERTATION/LearningRegularizationParameterMaps/venv_2/lib/python3.10/site-packages/torch/utils/_device.py:78\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_benchmark_tv_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
